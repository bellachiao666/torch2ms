--- pytorch+++ mindspore@@ -17,7 +17,7 @@ 
 # classes
 
-class AcceptVideoWrapper(Module):
+class AcceptVideoWrapper(nn.Cell):
     def __init__(
         self,
         image_net: Module,
@@ -42,7 +42,7 @@ 
         if exists(proj_embed_to_dim):
             assert exists(dim_emb), '`dim_emb` must be passed in'
-            self.embed_proj = Linear(dim_emb, proj_embed_to_dim)
+            self.embed_proj = nn.Linear(in_features = dim_emb, out_features = proj_embed_to_dim)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         # time positional embedding
 
@@ -52,7 +52,7 @@ 
             dim_pos_emb = default(proj_embed_to_dim, dim_emb)
 
-            self.pos_emb = Parameter(randn(time_seq_len, dim_pos_emb) * 1e-2)
+            self.pos_emb = Parameter(ops.randn(size = time_seq_len, generator = dim_pos_emb) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         self.embed_is_channel_first = embed_is_channel_first
 
@@ -146,11 +146,12 @@         emb_dropout = 0.1
     )
 
-    videos = torch.randn(1, 3, 7, 256, 256)
+    videos = ops.randn(size = 1, generator = 3, dtype = 256)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
     # step up the difficulty and return embeddings for robotics
 
     from vit_pytorch.extractor import Extractor
+from mindspore.mint import nn, ops
     v = Extractor(v)
 
     video_acceptor = AcceptVideoWrapper(v, add_time_pos_emb = True, output_pos_add_pos_emb = 1, time_seq_len = 12, dim_emb = 1024, proj_embed_to_dim = 512)
