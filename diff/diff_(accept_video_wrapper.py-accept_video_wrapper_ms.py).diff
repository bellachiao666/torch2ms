--- pytorch+++ mindspore@@ -1,3 +1,4 @@+from mindspore.mint import nn, ops
 from contextlib import nullcontext
 
 import torch
@@ -42,7 +43,7 @@ 
         if exists(proj_embed_to_dim):
             assert exists(dim_emb), '`dim_emb` must be passed in'
-            self.embed_proj = Linear(dim_emb, proj_embed_to_dim)
+            self.embed_proj = nn.Linear(in_features = dim_emb, out_features = proj_embed_to_dim)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         # time positional embedding
 
@@ -52,7 +53,7 @@ 
             dim_pos_emb = default(proj_embed_to_dim, dim_emb)
 
-            self.pos_emb = Parameter(randn(time_seq_len, dim_pos_emb) * 1e-2)
+            self.pos_emb = Parameter(ops.randn(size = time_seq_len, generator = dim_pos_emb) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         self.embed_is_channel_first = embed_is_channel_first
 
@@ -146,7 +147,7 @@         emb_dropout = 0.1
     )
 
-    videos = torch.randn(1, 3, 7, 256, 256)
+    videos = ops.randn(size = 1, generator = 3, dtype = 256)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
     # step up the difficulty and return embeddings for robotics
 
