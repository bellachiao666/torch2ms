--- pytorch+++ mindspore@@ -4,8 +4,8 @@ 
 import torch
 from torch import nn, einsum
-import torch.nn.functional as F
 from torchvision import transforms as T
+from mindspore.mint import nn, ops
 
 from einops import rearrange, reduce, repeat
 
@@ -41,7 +41,7 @@ # tensor related helpers
 
 def log(t, eps = 1e-20):
-    return torch.log(t + eps)
+    return ops.log(input = t + eps)  # 'torch.log':没有对应的mindspore参数 'out';
 
 # loss function # (algorithm 1 in the paper)
 
@@ -72,7 +72,7 @@     student_probs = (student_logits / student_temp).softmax(dim = -1)
     teacher_probs = ((teacher_logits - centers) / teacher_temp).softmax(dim = -1)
 
-    sim_matrix = einsum('b i d, b j d -> b i j', student_latent, teacher_latent)
+    sim_matrix = ops.einsum(equation = 'b i d, b j d -> b i j', operands = student_latent)
     sim_indices = sim_matrix.max(dim = -1).indices
     sim_indices = repeat(sim_indices, 'b n -> b n k', k = teacher_probs.shape[-1])
     max_sim_teacher_probs = teacher_probs.gather(1, sim_indices)
@@ -81,7 +81,7 @@ 
 # augmentation utils
 
-class RandomApply(nn.Module):
+class RandomApply(nn.Cell):
     def __init__(self, fn, p):
         super().__init__()
         self.fn = fn
@@ -111,11 +111,11 @@ 
 # MLP class for projector and predictor
 
-class L2Norm(nn.Module):
+class L2Norm(nn.Cell):
     def forward(self, x, eps = 1e-6):
-        return F.normalize(x, dim = 1, eps = eps)
-
-class MLP(nn.Module):
+        return nn.functional.normalize(input = x, dim = 1, eps = eps)  # 'torch.nn.functional.normalize':没有对应的mindspore参数 'out';
+
+class MLP(nn.Cell):
     def __init__(self, dim, dim_out, num_layers, hidden_size = 256):
         super().__init__()
 
@@ -126,15 +126,15 @@             is_last = ind == (len(dims) - 1)
 
             layers.extend([
-                nn.Linear(layer_dim_in, layer_dim_out),
+                nn.Linear(in_features = layer_dim_in, out_features = layer_dim_out),
                 nn.GELU() if not is_last else nn.Identity()
-            ])
+            ])  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         self.net = nn.Sequential(
             *layers,
             L2Norm(),
-            nn.Linear(hidden_size, dim_out)
-        )
+            nn.Linear(in_features = hidden_size, out_features = dim_out)
+        )  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         return self.net(x)
@@ -143,7 +143,7 @@ # will manage the interception of the hidden layer output
 # and pipe it into the projecter and predictor nets
 
-class NetWrapper(nn.Module):
+class NetWrapper(nn.Cell):
     def __init__(self, net, output_dim, projection_hidden_size, projection_num_layers, layer = -2):
         super().__init__()
         self.net = net
@@ -220,7 +220,7 @@ 
 # main class
 
-class EsViTTrainer(nn.Module):
+class EsViTTrainer(nn.Cell):
     def __init__(
         self,
         net,
@@ -245,19 +245,19 @@ 
         DEFAULT_AUG = torch.nn.Sequential(
             RandomApply(
-                T.ColorJitter(0.8, 0.8, 0.8, 0.2),
+                mindspore.dataset.vision.RandomColorAdjust(brightness = 0, contrast = 0, saturation = 0, hue = 0),
                 p = 0.3
             ),
             T.RandomGrayscale(p=0.2),
             T.RandomHorizontalFlip(),
             RandomApply(
-                T.GaussianBlur((3, 3), (1.0, 2.0)),
+                mindspore.dataset.vision.GaussianBlur(kernel_size = (3, 3), sigma = (1.0, 2.0)),
                 p = 0.2
             ),
             T.Normalize(
                 mean=torch.tensor([0.485, 0.456, 0.406]),
                 std=torch.tensor([0.229, 0.224, 0.225])),
-        )
+        )  # 默认值不一致: brightness (PyTorch=0, MindSpore=(1, 1)); 默认值不一致: contrast (PyTorch=0, MindSpore=(1, 1)); 默认值不一致: saturation (PyTorch=0, MindSpore=(1, 1)); 默认值不一致: hue (PyTorch=0, MindSpore=(0, 0))
 
         self.augment1 = default(augment_fn, DEFAULT_AUG)
         self.augment2 = default(augment_fn2, DEFAULT_AUG)
@@ -272,11 +272,11 @@         self.teacher_encoder = None
         self.teacher_ema_updater = EMA(moving_average_decay)
 
-        self.register_buffer('teacher_view_centers', torch.zeros(1, num_classes_K))
-        self.register_buffer('last_teacher_view_centers',  torch.zeros(1, num_classes_K))
-
-        self.register_buffer('teacher_region_centers', torch.zeros(1, num_classes_K))
-        self.register_buffer('last_teacher_region_centers',  torch.zeros(1, num_classes_K))
+        self.register_buffer('teacher_view_centers', ops.zeros(size = 1))  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
+        self.register_buffer('last_teacher_view_centers',  ops.zeros(size = 1))  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
+
+        self.register_buffer('teacher_region_centers', ops.zeros(size = 1))  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
+        self.register_buffer('last_teacher_region_centers',  ops.zeros(size = 1))  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
 
         self.teacher_centering_ema_updater = EMA(center_moving_average_decay)
 
@@ -288,7 +288,7 @@         self.to(device)
 
         # send a mock image tensor to instantiate singleton parameters
-        self.forward(torch.randn(2, 3, image_size, image_size, device=device))
+        self.forward(ops.randn(size = 2, generator = 3, dtype = image_size))  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
     @singleton('teacher_encoder')
     def _get_teacher_encoder(self):
@@ -350,10 +350,10 @@ 
         # calculate view-level loss
 
-        teacher_view_logits_avg = torch.cat((teacher_view_proj_one, teacher_view_proj_two)).mean(dim = 0)
+        teacher_view_logits_avg = ops.cat(tensors = (teacher_view_proj_one, teacher_view_proj_two)).mean(dim = 0)  # 'torch.cat':没有对应的mindspore参数 'out';
         self.last_teacher_view_centers.copy_(teacher_view_logits_avg)
 
-        teacher_region_logits_avg = torch.cat((teacher_region_proj_one, teacher_region_proj_two)).mean(dim = (0, 1))
+        teacher_region_logits_avg = ops.cat(tensors = (teacher_region_proj_one, teacher_region_proj_two)).mean(dim = (0, 1))  # 'torch.cat':没有对应的mindspore参数 'out';
         self.last_teacher_region_centers.copy_(teacher_region_logits_avg)
 
         view_loss = (view_loss_fn_(teacher_view_proj_one, student_view_proj_two) \
