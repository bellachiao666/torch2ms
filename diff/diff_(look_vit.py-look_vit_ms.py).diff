--- pytorch+++ mindspore@@ -1,3 +1,4 @@+from mindspore.mint import nn, ops
 import torch
 from torch import nn
 import torch.nn.functional as F
@@ -21,14 +22,14 @@ 
 def posemb_sincos_2d(t, temperature = 10000):
     h, w, d, device = *t.shape[1:], t.device
-    y, x = torch.meshgrid(torch.arange(h, device = device), torch.arange(w, device = device), indexing = 'ij')
+    y, x = ops.meshgrid(tensors = ops.arange(start = h), indexing = 'ij')  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
     assert (d % 4) == 0, "feature dimension must be multiple of 4 for sincos emb"
-    omega = torch.arange(d // 4, device = device) / (d // 4 - 1)
+    omega = ops.arange(start = d // 4) / (d // 4 - 1)  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
     omega = temperature ** -omega
 
     y = y.flatten()[:, None] * omega[None, :]
     x = x.flatten()[:, None] * omega[None, :]
-    pos = torch.cat((x.sin(), x.cos(), y.sin(), y.cos()), dim = 1)
+    pos = ops.cat(tensors = (x.sin(), x.cos(), y.sin(), y.cos()), dim = 1)  # 'torch.cat':没有对应的mindspore参数 'out';
 
     return pos.float()
 
@@ -37,8 +38,8 @@ class LayerNorm(Module):
     def __init__(self, dim):
         super().__init__()
-        self.ln = nn.LayerNorm(dim, elementwise_affine = False)
-        self.gamma = nn.Parameter(torch.zeros(dim))
+        self.ln = nn.LayerNorm(normalized_shape = dim, elementwise_affine = False)  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
+        self.gamma = nn.Parameter(ops.zeros(size = dim))  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
 
     def forward(self, x):
         normed = self.ln(x)
@@ -50,12 +51,12 @@     hidden_dim = int(dim * factor)
     return nn.Sequential(
         LayerNorm(dim),
-        nn.Linear(dim, hidden_dim),
+        nn.Linear(in_features = dim, out_features = hidden_dim),
         nn.GELU(),
-        nn.Dropout(dropout),
-        nn.Linear(hidden_dim, dim),
-        nn.Dropout(dropout)
-    )
+        nn.Dropout(p = dropout),
+        nn.Linear(in_features = hidden_dim, out_features = dim),
+        nn.Dropout(p = dropout)
+    )  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
 # attention
 
@@ -83,17 +84,17 @@         self.norm_context = LayerNorm(dim) if cross_attend else nn.Identity()
 
         self.attend = nn.Softmax(dim = -1)
-        self.dropout = nn.Dropout(dropout)
-
-        self.to_q = nn.Linear(dim, inner_dim, bias = False) if not reuse_attention else None
-        self.to_k = nn.Linear(dim, inner_dim, bias = False) if not reuse_attention else None
-        self.to_v = nn.Linear(dim, inner_dim, bias = False)
+        self.dropout = nn.Dropout(p = dropout)
+
+        self.to_q = nn.Linear(in_features = dim, out_features = inner_dim, bias = False) if not reuse_attention else None  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
+        self.to_k = nn.Linear(in_features = dim, out_features = inner_dim, bias = False) if not reuse_attention else None  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
+        self.to_v = nn.Linear(in_features = dim, out_features = inner_dim, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         self.to_out = nn.Sequential(
             Rearrange('b h n d -> b n (h d)'),
-            nn.Linear(inner_dim, dim, bias = False),
-            nn.Dropout(dropout)
-        )
+            nn.Linear(in_features = inner_dim, out_features = dim, bias = False),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(
         self,
@@ -172,15 +173,15 @@ 
         self.to_patches = nn.Sequential(
             Rearrange('b c (h p1) (w p2) -> b (p1 p2 c) h w', p1 = highres_patch_size, p2 = highres_patch_size),
-            nn.Conv2d(patch_dim, dim, kernel_size, padding = kernel_size // 2),
+            nn.Conv2d(in_channels = patch_dim, out_channels = dim, kernel_size = kernel_size, padding = kernel_size // 2),
             Rearrange('b c h w -> b h w c'),
             LayerNorm(dim),
-        )
+        )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
         # absolute positions
 
         num_patches = (image_size // highres_patch_size) ** 2
-        self.pos_embedding = nn.Parameter(torch.randn(num_patches, dim))
+        self.pos_embedding = nn.Parameter(ops.randn(size = num_patches, generator = dim))  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         # lookvit blocks
 
@@ -201,7 +202,7 @@         self.norm = LayerNorm(dim)
         self.highres_norm = LayerNorm(dim)
 
-        self.to_logits = nn.Linear(dim, num_classes, bias = False)
+        self.to_logits = nn.Linear(in_features = dim, out_features = num_classes, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, img):
         assert img.shape[-2:] == (self.image_size, self.image_size)
@@ -214,11 +215,8 @@         pos_emb = posemb_sincos_2d(highres_tokens)
         highres_tokens = highres_tokens + rearrange(pos_emb, '(h w) d -> h w d', h = size)
 
-        tokens = F.interpolate(
-            rearrange(highres_tokens, 'b h w d -> b d h w'),
-            img.shape[-1] // self.patch_size,
-            mode = 'bilinear'
-        )
+        tokens = nn.functional.interpolate(
+            input = rearrange(highres_tokens, 'b h w d -> b d h w'), size = img.shape[-1] // self.patch_size, mode = 'bilinear')  # 'torch.nn.functional.interpolate':没有对应的mindspore参数 'antialias';
 
         tokens = rearrange(tokens, 'b c h w -> b (h w) c')
         highres_tokens = rearrange(highres_tokens, 'b h w c -> b (h w) c')
@@ -272,7 +270,7 @@         dropout = 0.1
     ).cuda()
 
-    img = torch.randn(2, 3, 256, 256).cuda()
+    img = ops.randn(size = 2, generator = 3, dtype = 256).cuda()  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
     pred = v(img)
 
     assert pred.shape == (2, 1000)
