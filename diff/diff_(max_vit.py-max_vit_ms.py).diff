--- pytorch+++ mindspore@@ -1,3 +1,4 @@+from mindspore.mint import nn, ops
 from functools import partial
 
 import torch
@@ -32,13 +33,13 @@         super().__init__()
         inner_dim = int(dim * mult)
         self.net = nn.Sequential(
-            nn.LayerNorm(dim),
-            nn.Linear(dim, inner_dim),
+            nn.LayerNorm(normalized_shape = dim),
+            nn.Linear(in_features = dim, out_features = inner_dim),
             nn.GELU(),
-            nn.Dropout(dropout),
-            nn.Linear(inner_dim, dim),
-            nn.Dropout(dropout)
-        )
+            nn.Dropout(p = dropout),
+            nn.Linear(in_features = inner_dim, out_features = dim),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';; 'torch.nn.Linear':没有对应的mindspore参数 'device';
     def forward(self, x):
         return self.net(x)
 
@@ -51,12 +52,12 @@ 
         self.gate = nn.Sequential(
             Reduce('b c h w -> b c', 'mean'),
-            nn.Linear(dim, hidden_dim, bias = False),
+            nn.Linear(in_features = dim, out_features = hidden_dim, bias = False),
             nn.SiLU(),
-            nn.Linear(hidden_dim, dim, bias = False),
+            nn.Linear(in_features = hidden_dim, out_features = dim, bias = False),
             nn.Sigmoid(),
             Rearrange('b c -> b c 1 1')
-        )
+        )  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         return x * self.gate(x)
@@ -100,16 +101,16 @@     stride = 2 if downsample else 1
 
     net = nn.Sequential(
-        nn.Conv2d(dim_in, hidden_dim, 1),
-        nn.BatchNorm2d(hidden_dim),
+        nn.Conv2d(in_channels = dim_in, out_channels = hidden_dim, kernel_size = 1),
+        nn.BatchNorm2d(num_features = hidden_dim),
         nn.GELU(),
-        nn.Conv2d(hidden_dim, hidden_dim, 3, stride = stride, padding = 1, groups = hidden_dim),
-        nn.BatchNorm2d(hidden_dim),
+        nn.Conv2d(in_channels = hidden_dim, out_channels = hidden_dim, kernel_size = 3, stride = stride, padding = 1, groups = hidden_dim),
+        nn.BatchNorm2d(num_features = hidden_dim),
         nn.GELU(),
         SqueezeExcitation(hidden_dim, shrinkage_rate = shrinkage_rate),
-        nn.Conv2d(hidden_dim, dim_out, 1),
-        nn.BatchNorm2d(dim_out)
-    )
+        nn.Conv2d(in_channels = hidden_dim, out_channels = dim_out, kernel_size = 1),
+        nn.BatchNorm2d(num_features = dim_out)
+    )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';; 'torch.nn.BatchNorm2d':没有对应的mindspore参数 'device';
 
     if dim_in == dim_out and not downsample:
         net = MBConvResidual(net, dropout = dropout)
@@ -132,25 +133,25 @@         self.heads = dim // dim_head
         self.scale = dim_head ** -0.5
 
-        self.norm = nn.LayerNorm(dim)
-        self.to_qkv = nn.Linear(dim, dim * 3, bias = False)
+        self.norm = nn.LayerNorm(normalized_shape = dim)  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
+        self.to_qkv = nn.Linear(in_features = dim, out_features = dim * 3, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         self.attend = nn.Sequential(
             nn.Softmax(dim = -1),
-            nn.Dropout(dropout)
+            nn.Dropout(p = dropout)
         )
 
         self.to_out = nn.Sequential(
-            nn.Linear(dim, dim, bias = False),
-            nn.Dropout(dropout)
-        )
+            nn.Linear(in_features = dim, out_features = dim, bias = False),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         # relative positional bias
 
-        self.rel_pos_bias = nn.Embedding((2 * window_size - 1) ** 2, self.heads)
-
-        pos = torch.arange(window_size)
-        grid = torch.stack(torch.meshgrid(pos, pos, indexing = 'ij'))
+        self.rel_pos_bias = nn.Embedding(num_embeddings = (2 * window_size - 1) ** 2, embedding_dim = self.heads)  # 'torch.nn.Embedding':没有对应的mindspore参数 'device';
+
+        pos = ops.arange(start = window_size)  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
+        grid = ops.stack(tensors = ops.meshgrid(tensors = pos, indexing = 'ij'))  # 'torch.stack':没有对应的mindspore参数 'out';
         grid = rearrange(grid, 'c i j -> (i j) c')
         rel_pos = rearrange(grid, 'i ... -> i 1 ...') - rearrange(grid, 'j ... -> 1 j ...')
         rel_pos += window_size - 1
@@ -181,7 +182,7 @@ 
         # sim
 
-        sim = einsum('b h i d, b h j d -> b h i j', q, k)
+        sim = ops.einsum(equation = 'b h i d, b h j d -> b h i j', operands = q)
 
         # add positional bias
 
@@ -194,7 +195,7 @@ 
         # aggregate
 
-        out = einsum('b h i j, b h j d -> b h i d', attn, v)
+        out = ops.einsum(equation = 'b h i j, b h j d -> b h i d', operands = attn)
 
         # merge heads
 
@@ -228,9 +229,9 @@         dim_conv_stem = default(dim_conv_stem, dim)
 
         self.conv_stem = nn.Sequential(
-            nn.Conv2d(channels, dim_conv_stem, 3, stride = 2, padding = 1),
-            nn.Conv2d(dim_conv_stem, dim_conv_stem, 3, padding = 1)
-        )
+            nn.Conv2d(in_channels = channels, out_channels = dim_conv_stem, kernel_size = 3, stride = 2, padding = 1),
+            nn.Conv2d(in_channels = dim_conv_stem, out_channels = dim_conv_stem, kernel_size = 3, padding = 1)
+        )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
         # variables
 
@@ -278,9 +279,9 @@ 
         self.mlp_head = nn.Sequential(
             Reduce('b d h w -> b d', 'mean'),
-            nn.LayerNorm(dims[-1]),
-            nn.Linear(dims[-1], num_classes)
-        )
+            nn.LayerNorm(normalized_shape = dims[-1]),
+            nn.Linear(in_features = dims[-1], out_features = num_classes)
+        )  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';; 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         x = self.conv_stem(x)
