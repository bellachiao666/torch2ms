--- pytorch+++ mindspore@@ -1,11 +1,11 @@ import torch
 from torch import nn
-from torch.nn import Module, ModuleList
 import torch.nn.functional as F
 import torch.nn.utils.parametrize as parametrize
 
 from einops import rearrange, reduce
 from einops.layers.torch import Rearrange
+from mindspore.mint import nn, ops
 
 # functions
 
@@ -22,11 +22,11 @@     return (numer % denom) == 0
 
 def l2norm(t, dim = -1):
-    return F.normalize(t, dim = dim, p = 2)
+    return nn.functional.normalize(input = t, p = 2, dim = dim)  # 'torch.nn.functional.normalize':没有对应的mindspore参数 'out';
 
 # for use with parametrize
 
-class L2Norm(Module):
+class L2Norm(nn.Cell):
     def __init__(self, dim = -1):
         super().__init__()
         self.dim = dim
@@ -34,7 +34,7 @@     def forward(self, t):
         return l2norm(t, dim = self.dim)
 
-class NormLinear(Module):
+class NormLinear(nn.Cell):
     def __init__(
         self,
         dim,
@@ -42,7 +42,7 @@         norm_dim_in = True
     ):
         super().__init__()
-        self.linear = nn.Linear(dim, dim_out, bias = False)
+        self.linear = nn.Linear(in_features = dim, out_features = dim_out, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         parametrize.register_parametrization(
             self.linear,
@@ -59,7 +59,7 @@ 
 # attention and feedforward
 
-class Attention(Module):
+class Attention(nn.Cell):
     def __init__(
         self,
         dim,
@@ -76,8 +76,8 @@ 
         self.dropout = dropout
 
-        self.q_scale = nn.Parameter(torch.ones(heads, 1, dim_head) * (dim_head ** 0.25))
-        self.k_scale = nn.Parameter(torch.ones(heads, 1, dim_head) * (dim_head ** 0.25))
+        self.q_scale = mindspore.Parameter(ops.ones(size = heads, dtype = dim_head) * (dim_head ** 0.25))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
+        self.k_scale = mindspore.Parameter(ops.ones(size = heads, dtype = dim_head) * (dim_head ** 0.25))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
 
         self.split_heads = Rearrange('b n (h d) -> b h n d', h = heads)
         self.merge_heads = Rearrange('b h n d -> b n (h d)')
@@ -110,7 +110,7 @@         out = self.merge_heads(out)
         return self.to_out(out)
 
-class FeedForward(Module):
+class FeedForward(nn.Cell):
     def __init__(
         self,
         dim,
@@ -122,13 +122,13 @@         dim_inner = int(dim_inner * 2 / 3)
 
         self.dim = dim
-        self.dropout = nn.Dropout(dropout)
+        self.dropout = nn.Dropout(p = dropout)
 
         self.to_hidden = NormLinear(dim, dim_inner)
         self.to_gate = NormLinear(dim, dim_inner)
 
-        self.hidden_scale = nn.Parameter(torch.ones(dim_inner))
-        self.gate_scale = nn.Parameter(torch.ones(dim_inner))
+        self.hidden_scale = mindspore.Parameter(ops.ones(size = dim_inner))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
+        self.gate_scale = mindspore.Parameter(ops.ones(size = dim_inner))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
 
         self.to_out = NormLinear(dim_inner, dim, norm_dim_in = False)
 
@@ -138,14 +138,14 @@         hidden = hidden * self.hidden_scale
         gate = gate * self.gate_scale * (self.dim ** 0.5)
 
-        hidden = F.silu(gate) * hidden
+        hidden = nn.functional.silu(input = gate) * hidden
 
         hidden = self.dropout(hidden)
         return self.to_out(hidden)
 
 # classes
 
-class nViT(Module):
+class nViT(nn.Cell):
     """ https://arxiv.org/abs/2410.01131 """
 
     def __init__(
@@ -177,7 +177,7 @@         self.channels = channels
         self.patch_size = patch_size
 
-        self.to_patch_embedding = nn.Sequential(
+        self.to_patch_embedding = nn.SequentialCell(
             Rearrange('b c (h p1) (w p2) -> b (h w) (c p1 p2)', p1 = patch_size, p2 = patch_size),
             NormLinear(patch_dim, dim, norm_dim_in = False),
         )
@@ -191,21 +191,21 @@         self.dim = dim
         self.scale = dim ** 0.5
 
-        self.layers = ModuleList([])
+        self.layers = nn.CellList([])
         self.residual_lerp_scales = nn.ParameterList([])
 
         for _ in range(depth):
-            self.layers.append(ModuleList([
+            self.layers.append(nn.CellList([
                 Attention(dim, dim_head = dim_head, heads = heads, dropout = dropout),
                 FeedForward(dim, dim_inner = mlp_dim, dropout = dropout),
             ]))
 
             self.residual_lerp_scales.append(nn.ParameterList([
-                nn.Parameter(torch.ones(dim) * residual_lerp_scale_init / self.scale),
-                nn.Parameter(torch.ones(dim) * residual_lerp_scale_init / self.scale),
-            ]))
-
-        self.logit_scale = nn.Parameter(torch.ones(num_classes))
+                mindspore.Parameter(ops.ones(size = dim) * residual_lerp_scale_init / self.scale),
+                mindspore.Parameter(ops.ones(size = dim) * residual_lerp_scale_init / self.scale),
+            ]))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
+
+        self.logit_scale = mindspore.Parameter(ops.ones(size = num_classes))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
 
         self.to_pred = NormLinear(dim, num_classes)
 
@@ -226,7 +226,7 @@         tokens = self.to_patch_embedding(images)
 
         seq_len = tokens.shape[-2]
-        pos_emb = self.abs_pos_emb.weight[torch.arange(seq_len, device = device)]
+        pos_emb = self.abs_pos_emb.weight[ops.arange(start = seq_len)]  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
 
         tokens = l2norm(tokens + pos_emb)
 
@@ -259,6 +259,6 @@         mlp_dim = 2048,
     )
 
-    img = torch.randn(4, 3, 256, 256)
+    img = ops.randn(size = 4, generator = 3, dtype = 256)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
     logits = v(img) # (4, 1000)
     assert logits.shape == (4, 1000)
