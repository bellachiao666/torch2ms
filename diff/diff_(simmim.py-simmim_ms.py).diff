--- pytorch+++ mindspore@@ -1,9 +1,8 @@-import torch
 from torch import nn
-import torch.nn.functional as F
+from mindspore.mint import nn, ops
 from einops import repeat
 
-class SimMIM(nn.Module):
+class SimMIM(nn.Cell):
     def __init__(
         self,
         *,
@@ -20,14 +19,14 @@         num_patches, encoder_dim = encoder.pos_embedding.shape[-2:]
 
         self.to_patch = encoder.to_patch_embedding[0]
-        self.patch_to_emb = nn.Sequential(*encoder.to_patch_embedding[1:])
+        self.patch_to_emb = nn.SequentialCell(*encoder.to_patch_embedding[1:])
 
         pixel_values_per_patch = encoder.to_patch_embedding[2].weight.shape[-1]
 
         # simple linear head
 
-        self.mask_token = nn.Parameter(torch.randn(encoder_dim))
-        self.to_pixels = nn.Linear(encoder_dim, pixel_values_per_patch)
+        self.mask_token = mindspore.Parameter(ops.randn(size = encoder_dim))  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+        self.to_pixels = nn.Linear(in_features = encoder_dim, out_features = pixel_values_per_patch)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, img):
         device = img.device
@@ -39,7 +38,7 @@ 
         # for indexing purposes
 
-        batch_range = torch.arange(batch, device = device)[:, None]
+        batch_range = ops.arange(start = batch)[:, None]  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
 
         # get positions
 
@@ -58,12 +57,12 @@         # calculate of patches needed to be masked, and get positions (indices) to be masked
 
         num_masked = int(self.masking_ratio * num_patches)
-        masked_indices = torch.rand(batch, num_patches, device = device).topk(k = num_masked, dim = -1).indices
-        masked_bool_mask = torch.zeros((batch, num_patches), device = device).scatter_(-1, masked_indices, 1).bool()
+        masked_indices = ops.rand(size = batch, generator = num_patches).topk(k = num_masked, dim = -1).indices  # 'torch.rand':没有对应的mindspore参数 'out';; 'torch.rand':没有对应的mindspore参数 'layout';; 'torch.rand':没有对应的mindspore参数 'device';; 'torch.rand':没有对应的mindspore参数 'requires_grad';; 'torch.rand':没有对应的mindspore参数 'pin_memory';
+        masked_bool_mask = ops.zeros(size = (batch, num_patches)).scatter_(-1, masked_indices, 1).bool()  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
 
         # mask tokens
 
-        tokens = torch.where(masked_bool_mask[..., None], mask_tokens, tokens)
+        tokens = ops.where(condition = masked_bool_mask[..., None], input = mask_tokens, other = tokens)  # 'torch.where':没有对应的mindspore参数 'out';
 
         # attend with vision transformer
 
@@ -83,5 +82,5 @@ 
         # calculate reconstruction loss
 
-        recon_loss = F.l1_loss(pred_pixel_values, masked_patches) / num_masked
+        recon_loss = nn.functional.l1_loss(input = pred_pixel_values, target = masked_patches) / num_masked  # 'torch.nn.functional.l1_loss':没有对应的mindspore参数 'size_average';; 'torch.nn.functional.l1_loss':没有对应的mindspore参数 'reduce';
         return recon_loss
