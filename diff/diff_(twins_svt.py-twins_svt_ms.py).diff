--- pytorch+++ mindspore@@ -1,3 +1,4 @@+from mindspore.mint import nn, ops
 import torch
 from torch import nn, einsum
 import torch.nn.functional as F
@@ -34,12 +35,12 @@     def __init__(self, dim, eps = 1e-5):
         super().__init__()
         self.eps = eps
-        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))
-        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))
-
-    def forward(self, x):
-        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)
-        mean = torch.mean(x, dim = 1, keepdim = True)
+        self.g = nn.Parameter(ops.ones(size = 1, dtype = 1))  # 'torch.ones':没有对应的mindspore参数 'out';; 'torch.ones':没有对应的mindspore参数 'layout';; 'torch.ones':没有对应的mindspore参数 'device';; 'torch.ones':没有对应的mindspore参数 'requires_grad';
+        self.b = nn.Parameter(ops.zeros(size = 1, dtype = 1))  # 'torch.zeros':没有对应的mindspore参数 'out';; 'torch.zeros':没有对应的mindspore参数 'layout';; 'torch.zeros':没有对应的mindspore参数 'device';; 'torch.zeros':没有对应的mindspore参数 'requires_grad';
+
+    def forward(self, x):
+        var = ops.var(input = x, dim = 1, keepdim = True)  # 'torch.var':没有对应的mindspore参数 'out';
+        mean = ops.mean(input = x, dim = 1, keepdim = True)
         return (x - mean) / (var + self.eps).sqrt() * self.g + self.b
 
 class FeedForward(nn.Module):
@@ -47,12 +48,12 @@         super().__init__()
         self.net = nn.Sequential(
             LayerNorm(dim),
-            nn.Conv2d(dim, dim * mult, 1),
+            nn.Conv2d(in_channels = dim, out_channels = dim * mult, kernel_size = 1),
             nn.GELU(),
-            nn.Dropout(dropout),
-            nn.Conv2d(dim * mult, dim, 1),
-            nn.Dropout(dropout)
-        )
+            nn.Dropout(p = dropout),
+            nn.Conv2d(in_channels = dim * mult, out_channels = dim, kernel_size = 1),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
     def forward(self, x):
         return self.net(x)
 
@@ -65,9 +66,9 @@ 
         self.proj = nn.Sequential(
             LayerNorm(patch_size ** 2 * dim),
-            nn.Conv2d(patch_size ** 2 * dim, dim_out, 1),
+            nn.Conv2d(in_channels = patch_size ** 2 * dim, out_channels = dim_out, kernel_size = 1),
             LayerNorm(dim_out)
-        )
+        )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
     def forward(self, fmap):
         p = self.patch_size
@@ -77,7 +78,7 @@ class PEG(nn.Module):
     def __init__(self, dim, kernel_size = 3):
         super().__init__()
-        self.proj = Residual(nn.Conv2d(dim, dim, kernel_size = kernel_size, padding = kernel_size // 2, groups = dim, stride = 1))
+        self.proj = Residual(nn.Conv2d(in_channels = dim, out_channels = dim, kernel_size = kernel_size, stride = 1, padding = kernel_size // 2, groups = dim))  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         return self.proj(x)
@@ -91,13 +92,13 @@         self.scale = dim_head ** -0.5
 
         self.norm = LayerNorm(dim)
-        self.to_q = nn.Conv2d(dim, inner_dim, 1, bias = False)
-        self.to_kv = nn.Conv2d(dim, inner_dim * 2, 1, bias = False)
+        self.to_q = nn.Conv2d(in_channels = dim, out_channels = inner_dim, kernel_size = 1, bias = False)  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
+        self.to_kv = nn.Conv2d(in_channels = dim, out_channels = inner_dim * 2, kernel_size = 1, bias = False)  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
         self.to_out = nn.Sequential(
-            nn.Conv2d(inner_dim, dim, 1),
-            nn.Dropout(dropout)
-        )
+            nn.Conv2d(in_channels = inner_dim, out_channels = dim, kernel_size = 1),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
     def forward(self, fmap):
         fmap = self.norm(fmap)
@@ -111,11 +112,11 @@         q, k, v = (self.to_q(fmap), *self.to_kv(fmap).chunk(2, dim = 1))
         q, k, v = map(lambda t: rearrange(t, 'b (h d) p1 p2 -> (b h) (p1 p2) d', h = h), (q, k, v))
 
-        dots = einsum('b i d, b j d -> b i j', q, k) * self.scale
+        dots = ops.einsum(equation = 'b i d, b j d -> b i j', operands = q) * self.scale
 
         attn = dots.softmax(dim = - 1)
 
-        out = einsum('b i j, b j d -> b i d', attn, v)
+        out = ops.einsum(equation = 'b i j, b j d -> b i d', operands = attn)
         out = rearrange(out, '(b x y h) (p1 p2) d -> b (h d) (x p1) (y p2)', h = h, x = x, y = y, p1 = p, p2 = p)
         return self.to_out(out)
 
@@ -128,15 +129,15 @@ 
         self.norm = LayerNorm(dim)
 
-        self.to_q = nn.Conv2d(dim, inner_dim, 1, bias = False)
-        self.to_kv = nn.Conv2d(dim, inner_dim * 2, k, stride = k, bias = False)
-
-        self.dropout = nn.Dropout(dropout)
+        self.to_q = nn.Conv2d(in_channels = dim, out_channels = inner_dim, kernel_size = 1, bias = False)  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
+        self.to_kv = nn.Conv2d(in_channels = dim, out_channels = inner_dim * 2, kernel_size = k, stride = k, bias = False)  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
+
+        self.dropout = nn.Dropout(p = dropout)
 
         self.to_out = nn.Sequential(
-            nn.Conv2d(inner_dim, dim, 1),
-            nn.Dropout(dropout)
-        )
+            nn.Conv2d(in_channels = inner_dim, out_channels = dim, kernel_size = 1),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         x = self.norm(x)
@@ -147,12 +148,12 @@ 
         q, k, v = map(lambda t: rearrange(t, 'b (h d) x y -> (b h) (x y) d', h = h), (q, k, v))
 
-        dots = einsum('b i d, b j d -> b i j', q, k) * self.scale
+        dots = ops.einsum(equation = 'b i d, b j d -> b i j', operands = q) * self.scale
 
         attn = dots.softmax(dim = -1)
         attn = self.dropout(attn)
 
-        out = einsum('b i j, b j d -> b i d', attn, v)
+        out = ops.einsum(equation = 'b i j, b j d -> b i d', operands = attn)
         out = rearrange(out, '(b h) (x y) d -> b (h d) x y', h = h, y = y)
         return self.to_out(out)
 
@@ -226,10 +227,10 @@ 
         self.layers = nn.Sequential(
             *layers,
-            nn.AdaptiveAvgPool2d(1),
+            nn.AdaptiveAvgPool2d(output_size = 1),
             Rearrange('... () () -> ...'),
-            nn.Linear(dim, num_classes)
-        )
+            nn.Linear(in_features = dim, out_features = num_classes)
+        )  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         return self.layers(x)
