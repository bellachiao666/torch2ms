--- pytorch+++ mindspore@@ -4,14 +4,14 @@ from contextlib import nullcontext
 
 import torch
-import torch.nn.functional as F
 from torch import nn, cat, stack, arange, tensor
-from torch.nn import Module, ModuleList
+from torch.nn import ModuleList
 
 from torchaudio.transforms import Spectrogram
 
 from einops import rearrange, repeat, reduce, pack, unpack
 from einops.layers.torch import Rearrange
+from mindspore.mint import nn, ops
 
 # helpers
 
@@ -34,29 +34,29 @@ ):
     _, h, w, dim, device, dtype = *patches.shape, patches.device, patches.dtype
 
-    y, x = torch.meshgrid(arange(h, device = device), torch.arange(w, device = device), indexing = 'ij')
+    y, x = ops.meshgrid(tensors = ops.arange(start = h), indexing = 'ij')  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
     assert (dim % 4) == 0, 'feature dimension must be multiple of 4 for sincos emb'
 
-    omega = arange(dim // 4, device = device) / (dim // 4 - 1)
+    omega = ops.arange(start = dim // 4) / (dim // 4 - 1)  # 'torch.arange':没有对应的mindspore参数 'out';; 'torch.arange':没有对应的mindspore参数 'layout';; 'torch.arange':没有对应的mindspore参数 'device';; 'torch.arange':没有对应的mindspore参数 'requires_grad';
     omega = temperature ** -omega
 
     y = y.flatten()[:, None] * omega[None, :]
     x = x.flatten()[:, None] * omega[None, :] 
 
-    pe = cat((x.sin(), x.cos(), y.sin(), y.cos()), dim = 1)
+    pe = ops.cat(tensors = (x.sin(), x.cos(), y.sin(), y.cos()), dim = 1)  # 'torch.cat':没有对应的mindspore参数 'out';
     pe = pe.type(dtype)
 
     return rearrange(pe, '(h w) d -> h w d', h = h, w = w)
 
 # classes
 
-class FiLM(Module):
+class FiLM(nn.Cell):
     def __init__(
         self,
         dim,
     ):
         super().__init__()
-        proj = nn.Linear(dim, dim * 2)
+        proj = nn.Linear(in_features = dim, out_features = dim * 2)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         self.to_gamma_beta = nn.Sequential(
             proj,
@@ -71,7 +71,7 @@ 
         return tokens * gamma + beta
 
-class FeedForward(Module):
+class FeedForward(nn.Cell):
     def __init__(
         self,
         dim,
@@ -80,18 +80,18 @@     ):
         super().__init__()
         self.net = nn.Sequential(
-            nn.LayerNorm(dim),
-            nn.Linear(dim, hidden_dim),
+            nn.LayerNorm(normalized_shape = dim),
+            nn.Linear(in_features = dim, out_features = hidden_dim),
             nn.GELU(),
-            nn.Dropout(dropout),
-            nn.Linear(hidden_dim, dim),
-            nn.Dropout(dropout)
-        )
+            nn.Dropout(p = dropout),
+            nn.Linear(in_features = hidden_dim, out_features = dim),
+            nn.Dropout(p = dropout)
+        )  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';; 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, x):
         return self.net(x)
 
-class Attention(Module):
+class Attention(nn.Cell):
     def __init__(
         self,
         dim,
@@ -109,21 +109,21 @@         self.heads = heads
         self.scale = dim_head ** -0.5
 
-        self.norm = nn.LayerNorm(dim)
+        self.norm = nn.LayerNorm(normalized_shape = dim)  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
 
         self.cross_attend = cross_attend
-        self.context_norm = nn.LayerNorm(dim_context) if cross_attend else None
+        self.context_norm = nn.LayerNorm(normalized_shape = dim_context) if cross_attend else None  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
 
         self.attend = nn.Softmax(dim = -1)
-        self.dropout = nn.Dropout(dropout)
-
-        self.to_q = nn.Linear(dim, inner_dim, bias = False)
-        self.to_kv = nn.Linear(dim_context, inner_dim * 2, bias = False)
+        self.dropout = nn.Dropout(p = dropout)
+
+        self.to_q = nn.Linear(in_features = dim, out_features = inner_dim, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
+        self.to_kv = nn.Linear(in_features = dim_context, out_features = inner_dim * 2, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         self.to_out = nn.Sequential(
-            nn.Linear(inner_dim, dim),
-            nn.Dropout(dropout)
-        ) if project_out else nn.Identity()
+            nn.Linear(in_features = inner_dim, out_features = dim),
+            nn.Dropout(p = dropout)
+        ) if project_out else nn.Identity()  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(self, x, context = None):
 
@@ -144,16 +144,16 @@         qkv = (self.to_q(x), *self.to_kv(kv_input).chunk(2, dim = -1))
         q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)
 
-        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale
+        dots = ops.matmul(input = q, other = k.transpose(-1, -2)) * self.scale  # 'torch.matmul':没有对应的mindspore参数 'out';
 
         attn = self.attend(dots)
         attn = self.dropout(attn)
 
-        out = torch.matmul(attn, v)
+        out = ops.matmul(input = attn, other = v)  # 'torch.matmul':没有对应的mindspore参数 'out';
         out = rearrange(out, 'b h n d -> b n (h d)')
         return self.to_out(out)
 
-class Transformer(Module):
+class Transformer(nn.Cell):
     def __init__(
         self,
         dim,
@@ -164,7 +164,7 @@         dropout = 0.
     ):
         super().__init__()
-        self.norm = nn.LayerNorm(dim)
+        self.norm = nn.LayerNorm(normalized_shape = dim)  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
         self.layers = ModuleList([])
 
         for _ in range(depth):
@@ -194,7 +194,7 @@ 
         return x, hiddens
 
-class AST(Module):
+class AST(nn.Cell):
     # audio spectrogram transformer https://arxiv.org/abs/2104.01778
 
     def __init__(
@@ -229,10 +229,10 @@ 
         self.to_patch_tokens = nn.Sequential(
             Rearrange('b (h p1) (w p2) -> b h w (p1 p2)', p1 = self.patch_size[0], p2 = self.patch_size[1]),
-            nn.LayerNorm(patch_input_dim),
-            nn.Linear(patch_input_dim, dim),
-            nn.LayerNorm(dim)
-        )
+            nn.LayerNorm(normalized_shape = patch_input_dim),
+            nn.Linear(in_features = patch_input_dim, out_features = dim),
+            nn.LayerNorm(normalized_shape = dim)
+        )  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';; 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         self.accept_spec = accept_spec
         self.accept_spec_time_first = accept_spec_time_first
@@ -256,11 +256,11 @@             dropout = dropout,
         )
 
-        self.final_norm = nn.LayerNorm(dim)
-
-        self.mlp_head = nn.Linear(dim, num_classes) if exists(num_classes) else nn.Identity()
-
-        self.register_tokens = nn.Parameter(torch.randn(num_register_tokens, dim) * 1e-2)
+        self.final_norm = nn.LayerNorm(normalized_shape = dim)  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
+
+        self.mlp_head = nn.Linear(in_features = dim, out_features = num_classes) if exists(num_classes) else nn.Identity()  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
+
+        self.register_tokens = nn.Parameter(ops.randn(size = num_register_tokens, generator = dim) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
     def forward(
         self,
@@ -315,7 +315,7 @@         normed = self.final_norm(attended)
 
         if return_hiddens:
-            return normed, stack(hiddens)
+            return normed, ops.stack(tensors = hiddens)  # 'torch.stack':没有对应的mindspore参数 'out';
 
         register_tokens, normed = unpack(normed, packed_shape, 'b * d')
 
@@ -325,7 +325,7 @@ 
         return maybe_logits
 
-class ViT(Module):
+class ViT(nn.Cell):
     def __init__(
         self,
         *,
@@ -358,23 +358,23 @@ 
         self.to_patch_embedding = nn.Sequential(
             Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),
-            nn.LayerNorm(patch_dim),
-            nn.Linear(patch_dim, dim),
-            nn.LayerNorm(dim),
-        )
-
-        self.pos_embedding = nn.Parameter(torch.randn(num_patches, dim))
-        self.cls_token = nn.Parameter(torch.randn(dim))
-        self.dropout = nn.Dropout(emb_dropout)
+            nn.LayerNorm(normalized_shape = patch_dim),
+            nn.Linear(in_features = patch_dim, out_features = dim),
+            nn.LayerNorm(normalized_shape = dim),
+        )  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';; 'torch.nn.Linear':没有对应的mindspore参数 'device';
+
+        self.pos_embedding = nn.Parameter(ops.randn(size = num_patches, generator = dim))  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+        self.cls_token = nn.Parameter(ops.randn(size = dim))  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+        self.dropout = nn.Dropout(p = emb_dropout)
 
         self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)
 
         self.pool = pool
         self.to_latent = nn.Identity()
 
-        self.mlp_head = nn.Linear(dim, num_classes)
-
-        self.register_tokens = nn.Parameter(torch.randn(num_register_tokens, dim) * 1e-2)
+        self.mlp_head = nn.Linear(in_features = dim, out_features = num_classes)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
+
+        self.register_tokens = nn.Parameter(ops.randn(size = num_register_tokens, generator = dim) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
     def forward(self, img, return_hiddens = False):
         x = self.to_patch_embedding(img)
@@ -394,7 +394,7 @@         # return the representation trajectory
 
         if return_hiddens:
-            return x, stack(hiddens)
+            return x, ops.stack(tensors = hiddens)  # 'torch.stack':没有对应的mindspore参数 'out';
 
         register_tokens, cls_tokens, x = unpack(x, packed_shape, 'b * d')
 
@@ -409,7 +409,7 @@ # https://openreview.net/forum?id=TalHOvvLZu
 # simple way to get SOTA on Libero dataset (beating fine-tuned pi-zero)
 
-class VAAT(Module):
+class VAAT(nn.Cell):
     def __init__(
         self,
         vit: ViT | dict,
@@ -479,28 +479,28 @@ 
         self.is_video = is_video
         self.time_seq_len = time_seq_len
-        self.time_pos_emb = nn.Parameter(torch.randn(time_seq_len, vit_dim) * 1e-2) if is_video else None
+        self.time_pos_emb = nn.Parameter(ops.randn(size = time_seq_len, generator = vit_dim) * 1e-2) if is_video else None  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         # maybe view embeddings
 
-        self.image_view_emb = nn.Parameter(torch.randn(num_image_views, vit_dim) * 1e-2) if exists(num_image_views) and num_image_views > 1 else None
-
-        self.audio_view_emb = nn.Parameter(torch.randn(num_audio_views, ast_dim) * 1e-2) if exists(num_audio_views) and num_audio_views > 1 else None
+        self.image_view_emb = nn.Parameter(ops.randn(size = num_image_views, generator = vit_dim) * 1e-2) if exists(num_image_views) and num_image_views > 1 else None  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+
+        self.audio_view_emb = nn.Parameter(ops.randn(size = num_audio_views, generator = ast_dim) * 1e-2) if exists(num_audio_views) and num_audio_views > 1 else None  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         # handle maybe task conditioning
 
         self.has_tasks = exists(num_tasks)
 
         if self.has_tasks:
-            self.task_emb = nn.Parameter(torch.randn(num_tasks, dim) * 1e-2)
+            self.task_emb = nn.Parameter(ops.randn(size = num_tasks, generator = dim) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         # register tokens from Darcet et al.
 
-        self.register_tokens = nn.Parameter(torch.randn(num_register_tokens, dim) * 1e-2)
+        self.register_tokens = nn.Parameter(ops.randn(size = num_register_tokens, generator = dim) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         # to action tokens
 
-        self.action_pos_emb = nn.Parameter(torch.randn(action_chunk_len, dim) * 1e-2)
+        self.action_pos_emb = nn.Parameter(ops.randn(size = action_chunk_len, generator = dim) * 1e-2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
         self.layers = ModuleList([])
 
@@ -516,15 +516,15 @@                 FeedForward(dim = dim, hidden_dim = mlp_dim, dropout = dropout)
             ]))
 
-        self.final_norm = nn.LayerNorm(dim)
-        self.to_pred_action = nn.Linear(dim, dim_action, bias = False)
+        self.final_norm = nn.LayerNorm(normalized_shape = dim)  # 'torch.nn.LayerNorm':没有对应的mindspore参数 'device';
+        self.to_pred_action = nn.Linear(in_features = dim, out_features = dim_action, bias = False)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
         # handle the extra token
 
         self.accept_extra_token = exists(dim_extra_token)
 
         if exists(dim_extra_token):
-            self.to_extra_token = nn.Linear(dim_extra_token, dim)
+            self.to_extra_token = nn.Linear(in_features = dim_extra_token, out_features = dim)  # 'torch.nn.Linear':没有对应的mindspore参数 'device';
 
     def forward(
         self,
@@ -584,7 +584,7 @@         with vit_forward_context():
             embed, hiddens = self.vit(images, return_hiddens = True)
 
-        hiddens = cat((hiddens, embed[None, ...]))
+        hiddens = ops.cat(tensors = (hiddens, embed[None, ...]))  # 'torch.cat':没有对应的mindspore参数 'out';
 
         # extract the hiddens needed for the action cross attention
 
@@ -615,7 +615,7 @@         with ast_forward_context():
             audio_embed, audio_hiddens = self.ast(audio_or_spec, return_hiddens = True)
 
-        audio_hiddens = cat((audio_hiddens, audio_embed[None, ...]))
+        audio_hiddens = ops.cat(tensors = (audio_hiddens, audio_embed[None, ...]))  # 'torch.cat':没有对应的mindspore参数 'out';
 
         # extract the hiddens needed for the action cross attention
 
@@ -704,13 +704,13 @@             if not return_hiddens:
                 return pred_action
 
-            return pred_action, stack(hiddens)
+            return pred_action, ops.stack(tensors = hiddens)  # 'torch.stack':没有对应的mindspore参数 'out';
 
         assert pred_action.shape[1] == actions.shape[1]
 
         # they found l1 loss suffices
 
-        return F.l1_loss(pred_action, actions)
+        return nn.functional.l1_loss(input = pred_action, target = actions)  # 'torch.nn.functional.l1_loss':没有对应的mindspore参数 'size_average';; 'torch.nn.functional.l1_loss':没有对应的mindspore参数 'reduce';
 
 # quick test
 
@@ -759,13 +759,13 @@         )
     )
 
-    images = torch.randn(2, 2, 3, 4, 256, 256) # (2 views with 4 frames)
-    audio = torch.randn(2, 2, 14_100 * 5)
-
-    tasks = torch.randint(0, 4, (2,))
-    extra = torch.randn(2, 33)                 # extra internal state
-
-    actions = torch.randn(2, 7, 20)         # actions for learning
+    images = ops.randn(size = 2, generator = 2, dtype = 4)  # (2 views with 4 frames); 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+    audio = ops.randn(size = 2, generator = 2)  # 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+
+    tasks = ops.randint(low = 0, high = 4, size = (2,))  # 'torch.randint':没有对应的mindspore参数 'out';; 'torch.randint':没有对应的mindspore参数 'layout';; 'torch.randint':没有对应的mindspore参数 'device';; 'torch.randint':没有对应的mindspore参数 'requires_grad';
+    extra = ops.randn(size = 2, generator = 33)  # extra internal state; 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
+
+    actions = ops.randn(size = 2, generator = 7)  # actions for learning; 'torch.randn':没有对应的mindspore参数 'out';; 'torch.randn':没有对应的mindspore参数 'layout';; 'torch.randn':没有对应的mindspore参数 'device';; 'torch.randn':没有对应的mindspore参数 'requires_grad';; 'torch.randn':没有对应的mindspore参数 'pin_memory';
 
     loss = vaat(images, audio, actions = actions, tasks = tasks, extra = extra, freeze_vit = True)
     loss.backward()
