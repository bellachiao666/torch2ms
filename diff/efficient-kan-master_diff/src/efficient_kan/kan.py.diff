--- pytorch+++ mindspore@@ -1,9 +1,13 @@-import torch
-import torch.nn.functional as F
+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
+# import torch
 import math
 
 
-class KANLinear(torch.nn.Module):
+class KANLinear(msnn.Cell):
     def __init__(
         self,
         in_features,
@@ -14,7 +18,7 @@         scale_base=1.0,
         scale_spline=1.0,
         enable_standalone_scale_spline=True,
-        base_activation=torch.nn.SiLU,
+        base_activation=nn.SiLU,
         grid_eps=0.02,
         grid_range=[-1, 1],
     ):
@@ -27,7 +31,7 @@         h = (grid_range[1] - grid_range[0]) / grid_size
         grid = (
             (
-                torch.arange(-spline_order, grid_size + spline_order + 1) * h
+                mint.arange(-spline_order, grid_size + spline_order + 1) * h
                 + grid_range[0]
             )
             .expand(in_features, -1)
@@ -35,13 +39,13 @@         )
         self.register_buffer("grid", grid)
 
-        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))
-        self.spline_weight = torch.nn.Parameter(
-            torch.Tensor(out_features, in_features, grid_size + spline_order)
+        self.base_weight = ms.Parameter(ms.Tensor(out_features, in_features))
+        self.spline_weight = ms.Parameter(
+            ms.Tensor(out_features, in_features, grid_size + spline_order)
         )
         if enable_standalone_scale_spline:
-            self.spline_scaler = torch.nn.Parameter(
-                torch.Tensor(out_features, in_features)
+            self.spline_scaler = ms.Parameter(
+                ms.Tensor(out_features, in_features)
             )
 
         self.scale_noise = scale_noise
@@ -54,11 +58,12 @@         self.reset_parameters()
 
     def reset_parameters(self):
-        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)
+        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)  # 'torch.nn.init.kaiming_uniform_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         with torch.no_grad():
             noise = (
                 (
-                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)
+                    mint.rand(self.grid_size + 1, self.in_features, self.out_features)
                     - 1 / 2
                 )
                 * self.scale_noise
@@ -73,9 +78,9 @@             )
             if self.enable_standalone_scale_spline:
                 # torch.nn.init.constant_(self.spline_scaler, self.scale_spline)
-                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)
-
-    def b_splines(self, x: torch.Tensor):
+                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)  # 'torch.nn.init.kaiming_uniform_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def b_splines(self, x: ms.Tensor):
         """
         Compute the B-spline bases for the given input tensor.
 
@@ -87,7 +92,7 @@         """
         assert x.dim() == 2 and x.size(1) == self.in_features
 
-        grid: torch.Tensor = (
+        grid: ms.Tensor = (
             self.grid
         )  # (in_features, grid_size + 2 * spline_order + 1)
         x = x.unsqueeze(-1)
@@ -110,7 +115,7 @@         )
         return bases.contiguous()
 
-    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):
+    def curve2coeff(self, x: ms.Tensor, y: ms.Tensor):
         """
         Compute the coefficients of the curve that interpolates the given points.
 
@@ -130,7 +135,7 @@         B = y.transpose(0, 1)  # (in_features, batch_size, out_features)
         solution = torch.linalg.lstsq(
             A, B
-        ).solution  # (in_features, grid_size + spline_order, out_features)
+        ).solution  # (in_features, grid_size + spline_order, out_features); 'torch.linalg.lstsq' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         result = solution.permute(
             2, 0, 1
         )  # (out_features, in_features, grid_size + spline_order)
@@ -150,23 +155,25 @@             else 1.0
         )
 
-    def forward(self, x: torch.Tensor):
+    def construct(self, x: ms.Tensor):
         assert x.size(-1) == self.in_features
         original_shape = x.shape
         x = x.reshape(-1, self.in_features)
 
-        base_output = F.linear(self.base_activation(x), self.base_weight)
-        spline_output = F.linear(
+        base_output = nn.functional.linear(self.base_activation(x), self.base_weight)
+        spline_output = nn.functional.linear(
             self.b_splines(x).view(x.size(0), -1),
             self.scaled_spline_weight.view(self.out_features, -1),
         )
         output = base_output + spline_output
         
-        output = output.reshape(*original_shape[:-1], self.out_features)
+        output = output.reshape(*original_shape[:-1], self.out_features)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         return output
 
+    # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    # 装饰器 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     @torch.no_grad()
-    def update_grid(self, x: torch.Tensor, margin=0.01):
+    def update_grid(self, x: ms.Tensor, margin=0.01):
         assert x.dim() == 2 and x.size(1) == self.in_features
         batch = x.size(0)
 
@@ -174,23 +181,23 @@         splines = splines.permute(1, 0, 2)  # (in, batch, coeff)
         orig_coeff = self.scaled_spline_weight  # (out, in, coeff)
         orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)
-        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)
+        unreduced_spline_output = mint.bmm(splines, orig_coeff)  # (in, batch, out)
         unreduced_spline_output = unreduced_spline_output.permute(
             1, 0, 2
         )  # (batch, in, out)
 
         # sort each channel individually to collect data distribution
-        x_sorted = torch.sort(x, dim=0)[0]
+        x_sorted = mint.sort(x, dim=0)[0]
         grid_adaptive = x_sorted[
-            torch.linspace(
-                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device
+            mint.linspace(
+                0, batch - 1, self.grid_size + 1, dtype=ms.int64, device=x.device
             )
         ]
 
         uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size
         grid_uniform = (
-            torch.arange(
-                self.grid_size + 1, dtype=torch.float32, device=x.device
+            mint.arange(
+                self.grid_size + 1, dtype=ms.float32, device=x.device
             ).unsqueeze(1)
             * uniform_step
             + x_sorted[0]
@@ -202,14 +209,14 @@             [
                 grid[:1]
                 - uniform_step
-                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),
+                * mint.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),
                 grid,
                 grid[-1:]
                 + uniform_step
-                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),
+                * mint.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),
             ],
             dim=0,
-        )
+        )  # 'torch.concatenate' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         self.grid.copy_(grid.T)
         self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))
@@ -230,14 +237,14 @@         l1_fake = self.spline_weight.abs().mean(-1)
         regularization_loss_activation = l1_fake.sum()
         p = l1_fake / regularization_loss_activation
-        regularization_loss_entropy = -torch.sum(p * p.log())
+        regularization_loss_entropy = -mint.sum(p * p.log())
         return (
             regularize_activation * regularization_loss_activation
             + regularize_entropy * regularization_loss_entropy
         )
 
 
-class KAN(torch.nn.Module):
+class KAN(msnn.Cell):
     def __init__(
         self,
         layers_hidden,
@@ -246,7 +253,7 @@         scale_noise=0.1,
         scale_base=1.0,
         scale_spline=1.0,
-        base_activation=torch.nn.SiLU,
+        base_activation=nn.SiLU,
         grid_eps=0.02,
         grid_range=[-1, 1],
     ):
@@ -254,7 +261,7 @@         self.grid_size = grid_size
         self.spline_order = spline_order
 
-        self.layers = torch.nn.ModuleList()
+        self.layers = msnn.CellList()
         for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):
             self.layers.append(
                 KANLinear(
@@ -271,7 +278,7 @@                 )
             )
 
-    def forward(self, x: torch.Tensor, update_grid=False):
+    def construct(self, x: ms.Tensor, update_grid=False):
         for layer in self.layers:
             if update_grid:
                 layer.update_grid(x)
