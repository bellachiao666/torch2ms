--- pytorch+++ mindspore@@ -1,20 +1,25 @@-import torch
-import torch.nn as nn
+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
+# import torch
+# import torch.nn as nn
 from tqdm import tqdm
 
 from efficient_kan import KAN
 
 
 def test_mul():
-    kan = KAN([2, 2, 1], base_activation=nn.Identity)
-    optimizer = torch.optim.LBFGS(kan.parameters(), lr=1)
+    kan = KAN([2, 2, 1], base_activation=msnn.Identity)
+    optimizer = torch.optim.LBFGS(kan.parameters(), lr=1)  # 'torch.optim.LBFGS' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with tqdm(range(100)) as pbar:
         for i in pbar:
             loss, reg_loss = None, None
 
             def closure():
                 optimizer.zero_grad()
-                x = torch.rand(1024, 2)
+                x = mint.rand(1024, 2)
                 y = kan(x, update_grid=(i % 20 == 0))
 
                 assert y.shape == (1024, 1)
