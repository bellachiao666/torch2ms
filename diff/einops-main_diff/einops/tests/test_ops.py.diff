--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import itertools
 
 import numpy as np
@@ -595,7 +600,7 @@ def test_torch_compile_with_dynamic_shape():
     if not is_backend_tested("torch"):
         pytest.skip()
-    import torch
+    # import torch
 
     # somewhat reasonable debug messages
     torch._dynamo.config.verbose = True
@@ -609,16 +614,16 @@         return x
 
     # seems can't test static and dynamic in the same test run.
-    func1_compiled_static = torch.compile(func1, dynamic=False, fullgraph=True)
-    func1_compiled_dynamic = torch.compile(func1, dynamic=True, fullgraph=True)
-
-    x = torch.randn(size=[4, 5, 6, 3])
-    assert torch.allclose(func1_compiled_static(x), func1(x), atol=1e-5)
-    assert torch.allclose(func1_compiled_dynamic(x), func1(x), atol=1e-5)
+    func1_compiled_static = torch.compile(func1, dynamic=False, fullgraph=True)  # 'torch.compile' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    func1_compiled_dynamic = torch.compile(func1, dynamic=True, fullgraph=True)  # 'torch.compile' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    x = mint.randn(size = [4, 5, 6, 3])
+    assert mint.allclose(func1_compiled_static(x), func1(x), atol = 1e-5)
+    assert mint.allclose(func1_compiled_dynamic(x), func1(x), atol = 1e-5)
     # check with input of different dimensionality, and with all shape elements changed
-    x = torch.randn(size=[6, 3, 4, 2, 3])
-    assert torch.allclose(func1_compiled_static(x), func1(x), atol=1e-5)
-    assert torch.allclose(func1_compiled_dynamic(x), func1(x), atol=1e-5)
+    x = mint.randn(size = [6, 3, 4, 2, 3])
+    assert mint.allclose(func1_compiled_static(x), func1(x), atol = 1e-5)
+    assert mint.allclose(func1_compiled_dynamic(x), func1(x), atol = 1e-5)
 
 
 def bit_count(x):
