--- pytorch+++ mindspore@@ -1,16 +1,19 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 from __future__ import print_function
 import argparse
 import os
 import random
-import torch
-import torch.nn as nn
-import torch.nn.parallel
-import torch.backends.cudnn as cudnn
-import torch.optim as optim
-import torch.utils.data
-import torchvision.datasets as dset
-import torchvision.transforms as transforms
-import torchvision.utils as vutils
+# import torch
+# import torch.nn as nn
+# import torch.backends.cudnn as cudnn
+# import torch.optim as optim
+# import torchvision.datasets as dset
+# import torchvision.transforms as transforms
+# import torchvision.utils as vutils
 
 
 parser = argparse.ArgumentParser()
@@ -46,14 +49,15 @@     opt.manualSeed = random.randint(1, 10000)
 print("Random Seed: ", opt.manualSeed)
 random.seed(opt.manualSeed)
-torch.manual_seed(opt.manualSeed)
+torch.manual_seed(opt.manualSeed)  # 'torch.manual_seed' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 cudnn.benchmark = True
 
+# 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 if opt.accel and torch.accelerator.is_available():
-    device = torch.accelerator.current_accelerator()
+    device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 else:
-    device = torch.device("cpu")
+    device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 print(f"Using device: {device}")
 
@@ -63,49 +67,49 @@ if opt.dataset in ['imagenet', 'folder', 'lfw']:
     # folder dataset
     dataset = dset.ImageFolder(root=opt.dataroot,
-                               transform=transforms.Compose([
-                                   transforms.Resize(opt.imageSize),
-                                   transforms.CenterCrop(opt.imageSize),
+                               transform=ms.dataset.transforms.Compose([
+                                   ms.dataset.vision.Resize(opt.imageSize),
+                                   ms.dataset.vision.CenterCrop(opt.imageSize),
                                    transforms.ToTensor(),
                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
-                               ]))
+                               ]))  # 'torchvision.transforms.Resize'默认值不一致(position 1): PyTorch=<InterpolationMode.BILINEAR: 'bilinear'>, MindSpore=2;; 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.ImageFolder' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     nc=3
 elif opt.dataset == 'lsun':
     classes = [ c + '_train' for c in opt.classes.split(',')]
     dataset = dset.LSUN(root=opt.dataroot, classes=classes,
-                        transform=transforms.Compose([
-                            transforms.Resize(opt.imageSize),
-                            transforms.CenterCrop(opt.imageSize),
+                        transform=ms.dataset.transforms.Compose([
+                            ms.dataset.vision.Resize(opt.imageSize),
+                            ms.dataset.vision.CenterCrop(opt.imageSize),
                             transforms.ToTensor(),
                             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
-                        ]))
+                        ]))  # 'torchvision.transforms.Resize'默认值不一致(position 1): PyTorch=<InterpolationMode.BILINEAR: 'bilinear'>, MindSpore=2;; 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.LSUN' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     nc=3
 elif opt.dataset == 'cifar10':
     dataset = dset.CIFAR10(root=opt.dataroot, download=True,
-                           transform=transforms.Compose([
-                               transforms.Resize(opt.imageSize),
+                           transform=ms.dataset.transforms.Compose([
+                               ms.dataset.vision.Resize(opt.imageSize),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
-                           ]))
+                           ]))  # 'torchvision.transforms.Resize'默认值不一致(position 1): PyTorch=<InterpolationMode.BILINEAR: 'bilinear'>, MindSpore=2;; 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.CIFAR10' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     nc=3
 
 elif opt.dataset == 'mnist':
         dataset = dset.MNIST(root=opt.dataroot, download=True,
-                           transform=transforms.Compose([
-                               transforms.Resize(opt.imageSize),
+                           transform=ms.dataset.transforms.Compose([
+                               ms.dataset.vision.Resize(opt.imageSize),
                                transforms.ToTensor(),
                                transforms.Normalize((0.5,), (0.5,)),
-                           ]))
+                           ]))  # 'torchvision.transforms.Resize'默认值不一致(position 1): PyTorch=<InterpolationMode.BILINEAR: 'bilinear'>, MindSpore=2;; 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.MNIST' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         nc=1
 
 elif opt.dataset == 'fake':
     dataset = dset.FakeData(image_size=(3, opt.imageSize, opt.imageSize),
-                            transform=transforms.ToTensor())
+                            transform=transforms.ToTensor())  # 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.FakeData' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     nc=3
 
 assert dataset
 dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,
-                                         shuffle=True, num_workers=int(opt.workers))
+                                         shuffle=True, num_workers=int(opt.workers))  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 ngpu = int(opt.ngpu)
 nz = int(opt.nz)
@@ -117,43 +121,39 @@ def weights_init(m):
     classname = m.__class__.__name__
     if classname.find('Conv') != -1:
-        torch.nn.init.normal_(m.weight, 0.0, 0.02)
+        torch.nn.init.normal_(m.weight, 0.0, 0.02)  # 'torch.nn.init.normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif classname.find('BatchNorm') != -1:
-        torch.nn.init.normal_(m.weight, 1.0, 0.02)
-        torch.nn.init.zeros_(m.bias)
-
-
-class Generator(nn.Module):
+        torch.nn.init.normal_(m.weight, 1.0, 0.02)  # 'torch.nn.init.normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        torch.nn.init.zeros_(m.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+
+class Generator(msnn.Cell):
     def __init__(self, ngpu):
         super(Generator, self).__init__()
         self.ngpu = ngpu
-        self.main = nn.Sequential(
+        self.main = msnn.SequentialCell(
             # input is Z, going into a convolution
-            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias=False),
+            [
+            nn.ConvTranspose2d(     nz, ngf * 8, 4, 1, 0, bias = False),
             nn.BatchNorm2d(ngf * 8),
-            nn.ReLU(True),
-            # state size. (ngf*8) x 4 x 4
-            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
+            nn.ReLU(),
+            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias = False),
             nn.BatchNorm2d(ngf * 4),
-            nn.ReLU(True),
-            # state size. (ngf*4) x 8 x 8
-            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
+            nn.ReLU(),
+            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias = False),
             nn.BatchNorm2d(ngf * 2),
-            nn.ReLU(True),
-            # state size. (ngf*2) x 16 x 16
-            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),
+            nn.ReLU(),
+            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias = False),
             nn.BatchNorm2d(ngf),
-            nn.ReLU(True),
-            # state size. (ngf) x 32 x 32
-            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),
+            nn.ReLU(),
+            nn.ConvTranspose2d(    ngf, nc, 4, 2, 1, bias = False),
             nn.Tanh()
-            # state size. (nc) x 64 x 64
-        )
-
-    def forward(self, input):
+        ])  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
+
+    def construct(self, input):
         
         if (input.is_cuda or input.is_xpu) and self.ngpu > 1:
-            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))
+            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))  # 'torch.nn.parallel.data_parallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
             output = self.main(input)
         return output
@@ -162,38 +162,35 @@ netG = Generator(ngpu).to(device)
 netG.apply(weights_init)
 if opt.netG != '':
-    netG.load_state_dict(torch.load(opt.netG))
+    netG.load_state_dict(torch.load(opt.netG))  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 print(netG)
 
 
-class Discriminator(nn.Module):
+class Discriminator(msnn.Cell):
     def __init__(self, ngpu):
         super(Discriminator, self).__init__()
         self.ngpu = ngpu
-        self.main = nn.Sequential(
+        self.main = msnn.SequentialCell(
             # input is (nc) x 64 x 64
-            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),
-            nn.LeakyReLU(0.2, inplace=True),
-            # state size. (ndf) x 32 x 32
-            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
+            [
+            nn.Conv2d(nc, ndf, 4, 2, 1, bias = False),
+            nn.LeakyReLU(0.2, inplace=True),
+            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias = False),
             nn.BatchNorm2d(ndf * 2),
             nn.LeakyReLU(0.2, inplace=True),
-            # state size. (ndf*2) x 16 x 16
-            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
+            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias = False),
             nn.BatchNorm2d(ndf * 4),
             nn.LeakyReLU(0.2, inplace=True),
-            # state size. (ndf*4) x 8 x 8
-            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
+            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias = False),
             nn.BatchNorm2d(ndf * 8),
             nn.LeakyReLU(0.2, inplace=True),
-            # state size. (ndf*8) x 4 x 4
-            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
+            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias = False),
             nn.Sigmoid()
-        )
-
-    def forward(self, input):
+        ])  # 'torch.nn.LeakyReLU' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, input):
         if (input.is_cuda or input.is_xpu) and self.ngpu > 1:
-            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))
+            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))  # 'torch.nn.parallel.data_parallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
             output = self.main(input)
 
@@ -203,18 +200,18 @@ netD = Discriminator(ngpu).to(device)
 netD.apply(weights_init)
 if opt.netD != '':
-    netD.load_state_dict(torch.load(opt.netD))
+    netD.load_state_dict(torch.load(opt.netD))  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 print(netD)
 
 criterion = nn.BCELoss()
 
-fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)
+fixed_noise = mint.randn(opt.batchSize, nz, 1, 1, device=device)
 real_label = 1
 fake_label = 0
 
 # setup optimizer
-optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
-optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
+optimizerD = mint.optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
+optimizerG = mint.optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))
 
 if opt.dry_run:
     opt.niter = 1
@@ -228,7 +225,7 @@         netD.zero_grad()
         real_cpu = data[0].to(device)
         batch_size = real_cpu.size(0)
-        label = torch.full((batch_size,), real_label,
+        label = mint.full((batch_size,), real_label,
                            dtype=real_cpu.dtype, device=device)
 
         output = netD(real_cpu)
@@ -237,7 +234,7 @@         D_x = output.mean().item()
 
         # train with fake
-        noise = torch.randn(batch_size, nz, 1, 1, device=device)
+        noise = mint.randn(batch_size, nz, 1, 1, device=device)
         fake = netG(noise)
         label.fill_(fake_label)
         output = netD(fake.detach())
@@ -264,14 +261,14 @@         if i % 100 == 0:
             vutils.save_image(real_cpu,
                     '%s/real_samples.png' % opt.outf,
-                    normalize=True)
+                    normalize=True)  # 'torchvision.utils.save_image' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             fake = netG(fixed_noise)
             vutils.save_image(fake.detach(),
                     '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),
-                    normalize=True)
+                    normalize=True)  # 'torchvision.utils.save_image' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if opt.dry_run:
             break
     # do checkpointing
-    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))
-    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))
+    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (opt.outf, epoch))  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (opt.outf, epoch))  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
