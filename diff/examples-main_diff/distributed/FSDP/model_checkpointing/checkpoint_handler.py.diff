--- pytorch+++ mindspore@@ -1,31 +1,32 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 from pathlib import Path
 from datetime import datetime
-import torch
+# import torch
 import time
 
-from torch.distributed.fsdp import (
+# from torch.distributed.fsdp import (
     FullyShardedDataParallel as FSDP,
     StateDictType,
     FullStateDictConfig,  # general model non-sharded, non-flattened params
-    LocalStateDictConfig,  # flattened params, usable only by FSDP
-    # ShardedStateDictConfig, # un-flattened param but shards, usable by other parallel schemes.
-)
-
-from torch.distributed.checkpoint import (
+    )
+
+# from torch.distributed.checkpoint import (
     FileSystemReader,
     FileSystemWriter,
     save_state_dict,
     load_state_dict,
 )
-from torch.distributed.checkpoint.default_planner import (
+# from torch.distributed.checkpoint.default_planner import (
     DefaultSavePlanner,
-    DefaultLoadPlanner,
-)
-
-
-from torch.distributed.fsdp.fully_sharded_data_parallel import StateDictType
-import torch.distributed.checkpoint as dist_cp
-import torch.distributed as dist
+    )
+
+
+# from torch.distributed.fsdp.fully_sharded_data_parallel import StateDictType
+# import torch.distributed.checkpoint as dist_cp
 
 
 def get_date_of_run():
@@ -38,7 +39,7 @@ 
 
 # create singleton saving policies to avoid making over and over
-fullstate_save_policy = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)
+fullstate_save_policy = FullStateDictConfig(offload_to_cpu=True, rank0_only=True)  # 'torch.distributed.fsdp.FullStateDictConfig' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
 def load_model_sharded(model, rank, cfg, verbose=True):
@@ -58,8 +59,9 @@             print(f"No sharded_state_dict checkpoint directory found...skipping")
         return
 
-    reader = FileSystemReader(load_dir)
-
+    reader = FileSystemReader(load_dir)  # 'torch.distributed.checkpoint.FileSystemReader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    # 'torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with FSDP.state_dict_type(model, StateDictType.SHARDED_STATE_DICT):
         checkpoint = model.state_dict()
         if rank == 0:
@@ -69,7 +71,7 @@         dist_cp.load_state_dict(
             state_dict=checkpoint,
             storage_reader=reader,
-        )
+        )  # 'torch.distributed.checkpoint.load_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if rank == 0:
             print(f"checkpoint after load_state_dict()")
             ck = checkpoint.keys()
@@ -95,22 +97,23 @@ 
     distributed_writer = dist_cp.FileSystemWriter(
         save_dir,
-    )
+    )  # 'torch.distributed.checkpoint.FileSystemWriter' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     t0 = time.perf_counter()
 
+    # 'torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with FSDP.state_dict_type(model, StateDictType.SHARDED_STATE_DICT):
 
         state_dict = {"model": model.state_dict()}
         if optim is not None:
-            state_dict["optim"] = FSDP.optim_state_dict(model, optim)
+            state_dict["optim"] = FSDP.optim_state_dict(model, optim)  # 'torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         dist_cp.save_state_dict(
             state_dict=state_dict,
             storage_writer=distributed_writer,
             planner=DefaultSavePlanner(),
 
-        )
-    dist.barrier()
+        )  # 'torch.distributed.checkpoint.default_planner.DefaultSavePlanner' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.distributed.checkpoint.save_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    mint.distributed.barrier()
     t1 = time.perf_counter()
     if rank == 0:
         print(f"Sharded state checkpoint saved to {save_dir}")
@@ -131,6 +134,7 @@     if not cfg.checkpoint_type == StateDictType.FULL_STATE_DICT:
         print(f" unable to handle checkpoint type {cfg.checkpoint_type}, aborting")
 
+    # 'torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with FSDP.state_dict_type(
         model, StateDictType.FULL_STATE_DICT, fullstate_save_policy
     ):
@@ -149,7 +153,7 @@         save_full_path = str(save_dir) + "/" + save_name
 
         # save model
-        torch.save(cpu_state, save_full_path)
+        torch.save(cpu_state, save_full_path)  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if cfg.verbose:
             print(f"model checkpoint saved for epoch {epoch} at {save_full_path}\n")
@@ -175,7 +179,7 @@         return
 
 
-    model_checkpoint = torch.load(full_state_dict_model_path)
+    model_checkpoint = torch.load(full_state_dict_model_path)  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     # integrate into loaded model
     model.load_state_dict(model_checkpoint)
 
@@ -191,7 +195,7 @@ 
     # pull all sharded optimizer states to rank0 cpu...
 
-    optim_state = FSDP.full_optim_state_dict(model, optimizer)
+    optim_state = FSDP.full_optim_state_dict(model, optimizer)  # 'torch.distributed.fsdp.FullyShardedDataParallel.full_optim_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if cfg.verbose:
         print(f"optim state dict ready on {rank} and len of {len(optim_state)}\n")
@@ -207,7 +211,7 @@ 
         print(f"--> saving optimizer state...")
 
-        torch.save(optim_state, opt_save_full_path)
+        torch.save(optim_state, opt_save_full_path)  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         print(f"--> saved {opt_save_full_path} to disk")
 
@@ -228,13 +232,13 @@     full_osd = None
 
     if rank == 0:
-        full_osd = torch.load(opt_file_path)
+        full_osd = torch.load(opt_file_path)  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if cfg.verbose:
             print(f"loaded full osd on rank 0")
 
     # called from all ranks, though only rank0 has a valid param for full_osd
-    sharded_osd = FSDP.scatter_full_optim_state_dict(full_osd, model)
+    sharded_osd = FSDP.scatter_full_optim_state_dict(full_osd, model)  # 'torch.distributed.fsdp.FullyShardedDataParallel.scatter_full_optim_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if cfg.verbose:
         print(f"optimizer shard loaded on rank {rank}")
@@ -260,14 +264,15 @@             return
 
 
-        reader = FileSystemReader(checkdir)
-
+        reader = FileSystemReader(checkdir)  # 'torch.distributed.checkpoint.FileSystemReader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        # 'torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         with FSDP.state_dict_type(
             model,
             StateDictType.LOCAL_STATE_DICT,
         ):
             state_dict = model.state_dict()
-            load_state_dict(state_dict, reader)
+            load_state_dict(state_dict, reader)  # 'torch.distributed.checkpoint.load_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             model.load_state_dict(state_dict)
 
         print(f"--> local state loaded on rank {rank}")
@@ -292,8 +297,9 @@ 
         writer = FileSystemWriter(
             save_dir,
-        )
-
+        )  # 'torch.distributed.checkpoint.FileSystemWriter' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        # 'torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         with FSDP.state_dict_type(
             model,
             StateDictType.LOCAL_STATE_DICT,
@@ -302,6 +308,6 @@ 
 
         # write out distributed checkpoint
-        save_state_dict(state_dict, writer)
-
-        return
+        save_state_dict(state_dict, writer)  # 'torch.distributed.checkpoint.save_state_dict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        return
