--- pytorch+++ mindspore@@ -1,8 +1,13 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import os
 import sys
-import torch
-from torch.utils.data import random_split
-from torch.distributed import init_process_group, destroy_process_group
+# import torch
+# from torch.utils.data import random_split
+# from torch.distributed import init_process_group, destroy_process_group
 from model import GPT, GPTConfig, OptimizerConfig, create_optimizer
 from trainer import Trainer, TrainerConfig
 from char_dataset import CharDataset, DataConfig
@@ -10,22 +15,23 @@ import hydra
 
 def verify_min_gpu_count(min_gpus: int = 2) -> bool:
-    has_gpu = torch.accelerator.is_available()
-    gpu_count = torch.accelerator.device_count()
+    has_gpu = torch.accelerator.is_available()  # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    gpu_count = torch.accelerator.device_count()  # 'torch.accelerator.device_count' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     return has_gpu and gpu_count >= min_gpus
 
+# 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def ddp_setup():
-    acc = torch.accelerator.current_accelerator()
+    acc = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     rank = int(os.environ["LOCAL_RANK"])
-    device: torch.device = torch.device(f"{acc}:{rank}")
-    backend = torch.distributed.get_default_backend_for_device(device)
-    init_process_group(backend=backend)
-    torch.accelerator.set_device_index(rank)
+    device: torch.device = torch.device(f"{acc}:{rank}")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    backend = torch.distributed.get_default_backend_for_device(device)  # 'torch.distributed.get_default_backend_for_device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    mint.distributed.init_process_group(backend = backend)
+    torch.accelerator.set_device_index(rank)  # 'torch.accelerator.set_device_index' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 def get_train_objs(gpt_cfg: GPTConfig, opt_cfg: OptimizerConfig, data_cfg: DataConfig):
     dataset = CharDataset(data_cfg)
     train_len = int(len(dataset) * data_cfg.train_split)
-    train_set, test_set = random_split(dataset, [train_len, len(dataset) - train_len])
+    train_set, test_set = random_split(dataset, [train_len, len(dataset) - train_len])  # 'torch.utils.data.random_split' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     gpt_cfg.vocab_size = dataset.vocab_size
     gpt_cfg.block_size = dataset.block_size
@@ -38,16 +44,16 @@ def main(cfg: DictConfig):
     ddp_setup()
 
-    gpt_cfg = GPTConfig(**cfg['gpt_config'])
-    opt_cfg = OptimizerConfig(**cfg['optimizer_config'])
-    data_cfg = DataConfig(**cfg['data_config'])
-    trainer_cfg = TrainerConfig(**cfg['trainer_config'])
+    gpt_cfg = GPTConfig(**cfg['gpt_config'])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    opt_cfg = OptimizerConfig(**cfg['optimizer_config'])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    data_cfg = DataConfig(**cfg['data_config'])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    trainer_cfg = TrainerConfig(**cfg['trainer_config'])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     model, optimizer, train_data, test_data = get_train_objs(gpt_cfg, opt_cfg, data_cfg)
     trainer = Trainer(trainer_cfg, model, optimizer, train_data, test_data)
     trainer.train()
 
-    destroy_process_group()
+    destroy_process_group()  # 'torch.distributed.destroy_process_group' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 if __name__ == "__main__":
     _min_gpu_count = 2
