--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """
 Simple training loop; Boilerplate that could apply to any arbitrary neural network,
 so nothing in this file really has anything to do with GPT specifically.
@@ -8,10 +13,10 @@ from typing import Optional, Any, Dict
 import os
 
-import torch
-from torch.utils.data import Dataset, DataLoader
-from torch.nn.parallel import DistributedDataParallel as DDP
-from torch.utils.data.distributed import DistributedSampler
+# import torch
+# from torch.utils.data import Dataset, DataLoader
+# from torch.nn.parallel import DistributedDataParallel as DDP
+# from torch.utils.data.distributed import DistributedSampler
 
 import boto3
 from urllib.parse import urlparse
@@ -36,21 +41,22 @@ 
 def upload_to_s3(obj, dst):
     buffer = io.BytesIO()
-    torch.save(obj, buffer)
+    torch.save(obj, buffer)  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     buffer.seek(0)
     dst = urlparse(dst, allow_fragments=False)
     boto3.client('s3').upload_fileobj(buffer, dst.netloc, dst.path.lstrip('/'))
 
 class Trainer:
 
+    # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     def __init__(self, trainer_config: TrainerConfig, model, optimizer, train_dataset, test_dataset=None):
         self.config = trainer_config
         # set torchrun variables
         self.local_rank = int(os.environ["LOCAL_RANK"])
         self.global_rank = int(os.environ["RANK"])  
         # set device
-        self.acc = torch.accelerator.current_accelerator()
-        self.device: torch.device = torch.device(f"{self.acc}:{self.local_rank}")
+        self.acc = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.device: torch.device = torch.device(f"{self.acc}:{self.local_rank}")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         self.device_type = self.device.type
         # data stuff
         self.train_dataset = train_dataset
@@ -62,14 +68,15 @@         self.optimizer = optimizer        
         self.save_every = self.config.save_every
         if self.config.use_amp:
-            self.scaler = torch.amp.GradScaler(self.device_type)
+            self.scaler = torch.amp.GradScaler(self.device_type)  # 'torch.amp.GradScaler' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         # load snapshot if available. only necessary on the first node.
         if self.config.snapshot_path is None:
             self.config.snapshot_path = "snapshot.pt"
         self._load_snapshot()
         # wrap with DDP. this step will synch model across all the processes.
-        self.model = DDP(self.model, device_ids=[self.local_rank])
+        self.model = DDP(self.model, device_ids=[self.local_rank])  # 'torch.nn.parallel.DistributedDataParallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         
+    # 'torch.utils.data.Dataset' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     def _prepare_dataloader(self, dataset: Dataset):
         return DataLoader(
             dataset,
@@ -78,18 +85,18 @@             shuffle=False,
             num_workers=self.config.data_loader_workers,
             sampler=DistributedSampler(dataset)
-        )
+        )  # 'torch.utils.data.distributed.DistributedSampler' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def _load_snapshot(self):
         try:
             snapshot = fsspec.open(self.config.snapshot_path)
             with snapshot as f:
-                snapshot_data = torch.load(f, map_location="cpu")
+                snapshot_data = torch.load(f, map_location="cpu")  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         except FileNotFoundError:
             print("Snapshot not found. Training model from scratch")
             return 
 
-        snapshot = Snapshot(**snapshot_data)
+        snapshot = Snapshot(**snapshot_data)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.model.load_state_dict(snapshot.model_state)
         self.optimizer.load_state_dict(snapshot.optimizer_state)
         self.epochs_run = snapshot.finished_epoch
@@ -97,23 +104,26 @@ 
 
     def _run_batch(self, source, targets, train: bool = True) -> float:
-        with torch.set_grad_enabled(train), torch.amp.autocast(device_type=self.device_type, dtype=torch.float16, enabled=(self.config.use_amp)):
+        # 'torch.set_grad_enabled' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        # 'torch.amp.autocast' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        with torch.set_grad_enabled(train), torch.amp.autocast(device_type=self.device_type, dtype=ms.float16, enabled=(self.config.use_amp)):
             _, loss = self.model(source, targets)
         
         if train:
             self.optimizer.zero_grad(set_to_none=True)
             if self.config.use_amp: 
                 self.scaler.scale(loss).backward()
-                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_norm_clip)
+                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_norm_clip)  # 'torch.nn.utils.clip_grad_norm_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                 self.scaler.step(self.optimizer)
                 self.scaler.update()
             else:
                 loss.backward()
-                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_norm_clip)
+                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.grad_norm_clip)  # 'torch.nn.utils.clip_grad_norm_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                 self.optimizer.step()
         
         return loss.item()
 
+    # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     def _run_epoch(self, epoch: int, dataloader: DataLoader, train: bool = True):
         if train:
             dataloader.sampler.set_epoch(epoch)
@@ -139,7 +149,7 @@         if self.config.snapshot_path.startswith("s3://"):
             upload_to_s3(snapshot, self.config.snapshot_path)
         else:
-            torch.save(snapshot, self.config.snapshot_path)
+            torch.save(snapshot, self.config.snapshot_path)  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             
         print(f"Snapshot saved at epoch {epoch}")
 
