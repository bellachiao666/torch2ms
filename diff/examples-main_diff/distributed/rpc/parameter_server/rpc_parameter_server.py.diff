--- pytorch+++ mindspore@@ -1,62 +1,68 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import argparse
 import os
 from threading import Lock
 
-import torch
-import torch.distributed.autograd as dist_autograd
-import torch.distributed.rpc as rpc
-import torch.multiprocessing as mp
-import torch.nn as nn
-import torch.nn.functional as F
-from torch import optim
-from torch.distributed.optim import DistributedOptimizer
-from torchvision import datasets, transforms
+# import torch
+# import torch.distributed.autograd as dist_autograd
+# import torch.distributed.rpc as rpc
+# import torch.multiprocessing as mp
+# import torch.nn as nn
+# from torch import optim
+# from torch.distributed.optim import DistributedOptimizer
+# from torchvision import datasets, transforms
 
 # --------- MNIST Network to train, from pytorch/examples -----
 
 
-class Net(nn.Module):
+class Net(msnn.Cell):
     def __init__(self, num_gpus=0):
         super(Net, self).__init__()
         print(f"Using {num_gpus} GPUs to train")
         self.num_gpus = num_gpus
+        # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if torch.accelerator.is_available() and self.num_gpus > 0:
-            acc = torch.accelerator.current_accelerator()
-            device = torch.device(f'{acc}:0')
+            acc = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            device = torch.device(f'{acc}:0')  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
-            device = torch.device("cpu")
+            device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         print(f"Putting first 2 convs on {str(device)}")
         # Put conv layers on the first accelerator device
-        self.conv1 = nn.Conv2d(1, 32, 3, 1).to(device)
-        self.conv2 = nn.Conv2d(32, 64, 3, 1).to(device)
+        self.conv1 = nn.Conv2d(1, 32, 3, 1).to(device)  # 'torch.nn.Conv2d.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.conv2 = nn.Conv2d(32, 64, 3, 1).to(device)  # 'torch.nn.Conv2d.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         # Put rest of the network on the 2nd accelerator device, if there is one
+        # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if torch.accelerator.is_available() and self.num_gpus > 0:
-            acc = torch.accelerator.current_accelerator()
-            device = torch.device(f'{acc}:1')
+            acc = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            device = torch.device(f'{acc}:1')  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         print(f"Putting rest of layers on {str(device)}")
-        self.dropout1 = nn.Dropout2d(0.25).to(device)
-        self.dropout2 = nn.Dropout2d(0.5).to(device)
-        self.fc1 = nn.Linear(9216, 128).to(device)
-        self.fc2 = nn.Linear(128, 10).to(device)
-
-    def forward(self, x):
+        self.dropout1 = nn.Dropout2d(0.25).to(device)  # 'torch.nn.Dropout2d.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.dropout2 = nn.Dropout2d(0.5).to(device)  # 'torch.nn.Dropout2d.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.fc1 = nn.Linear(9216, 128).to(device)  # 'torch.nn.Linear.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.fc2 = nn.Linear(128, 10).to(device)  # 'torch.nn.Linear.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         x = self.conv1(x)
-        x = F.relu(x)
+        x = nn.functional.relu(x)
         x = self.conv2(x)
-        x = F.max_pool2d(x, 2)
+        x = nn.functional.max_pool2d(x, 2)
 
         x = self.dropout1(x)
-        x = torch.flatten(x, 1)
+        x = mint.flatten(x, 1)
         # Move tensor to next device if necessary
         next_device = next(self.fc1.parameters()).device
         x = x.to(next_device)
 
         x = self.fc1(x)
-        x = F.relu(x)
+        x = nn.functional.relu(x)
         x = self.dropout2(x)
         x = self.fc2(x)
-        output = F.log_softmax(x, dim=1)
+        output = mint.special.log_softmax(x, dim=1)
         return output
 
 
@@ -66,7 +72,7 @@ # RRef. Other args are passed in as arguments to the function called.
 # Useful for calling instance methods.
 def call_method(method, rref, *args, **kwargs):
-    return method(rref.local_value(), *args, **kwargs)
+    return method(rref.local_value(), *args, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 # Given an RRef, return the result of calling the passed in method on the value
 # held by the RRef. This call is done on the remote node that owns
@@ -78,21 +84,22 @@ 
 def remote_method(method, rref, *args, **kwargs):
     args = [method, rref] + list(args)
-    return rpc.rpc_sync(rref.owner(), call_method, args=args, kwargs=kwargs)
+    return rpc.rpc_sync(rref.owner(), call_method, args=args, kwargs=kwargs)  # 'torch.distributed.rpc.rpc_sync' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 # --------- Parameter Server --------------------
-class ParameterServer(nn.Module):
+class ParameterServer(msnn.Cell):
     def __init__(self, num_gpus=0):
         super().__init__()
         model = Net(num_gpus=num_gpus)
         self.model = model
+        # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if torch.accelerator.is_available() and num_gpus > 0:
-            acc = torch.accelerator.current_accelerator()
-            self.input_device = torch.device(f'{acc}:0')
+            acc = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            self.input_device = torch.device(f'{acc}:0')  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
-            self.input_device = torch.device("cpu")
+            self.input_device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             
-    def forward(self, inp):
+    def construct(self, inp):
         inp = inp.to(self.input_device)
         out = self.model(inp)
         # This output is forwarded over RPC, which as of 1.5.0 only accepts CPU tensors.
@@ -103,7 +110,7 @@     # Use dist autograd to retrieve gradients accumulated for this model.
     # Primarily used for verification.
     def get_dist_gradients(self, cid):
-        grads = dist_autograd.get_gradients(cid)
+        grads = dist_autograd.get_gradients(cid)  # 'torch.distributed.autograd.get_gradients' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         # This output is forwarded over RPC, which as of 1.5.0 only accepts CPU tensors.
         # Tensors must be moved in and out of GPU memory due to this.
         cpu_grads = {}
@@ -115,7 +122,7 @@     # Wrap local parameters in a RRef. Needed for building the
     # DistributedOptimizer which optimizes parameters remotely.
     def get_param_rrefs(self):
-        param_rrefs = [rpc.RRef(param) for param in self.model.parameters()]
+        param_rrefs = [rpc.RRef(param) for param in self.model.parameters()]  # 'torch.distributed.rpc.RRef' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         return param_rrefs
 
 param_server = None
@@ -138,9 +145,9 @@     # in this case means that the parameter server will wait for all trainers
     # to complete, and then exit.
     print("PS master initializing RPC")
-    rpc.init_rpc(name="parameter_server", rank=rank, world_size=world_size)
+    rpc.init_rpc(name="parameter_server", rank=rank, world_size=world_size)  # 'torch.distributed.rpc.init_rpc' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     print("RPC initialized! Running parameter server...")
-    rpc.shutdown()
+    rpc.shutdown()  # 'torch.distributed.rpc.shutdown' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     print("RPC shutdown on parameter server.")
 
 
@@ -149,12 +156,12 @@ # nn.Module corresponding to the network trained by this trainer. The
 # forward() method simply invokes the network on the given parameter
 # server.
-class TrainerNet(nn.Module):
+class TrainerNet(msnn.Cell):
     def __init__(self, num_gpus=0):
         super().__init__()
         self.num_gpus = num_gpus
         self.param_server_rref = rpc.remote(
-            "parameter_server", get_parameter_server, args=(num_gpus,))
+            "parameter_server", get_parameter_server, args=(num_gpus,))  # 'torch.distributed.rpc.remote' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def get_global_param_rrefs(self):
         remote_params = remote_method(
@@ -162,7 +169,7 @@             self.param_server_rref)
         return remote_params
 
-    def forward(self, x):
+    def construct(self, x):
         model_output = remote_method(
             ParameterServer.forward, self.param_server_rref, x)
         return model_output
@@ -174,15 +181,16 @@     net = TrainerNet(num_gpus=num_gpus)
     # Build DistributedOptimizer.
     param_rrefs = net.get_global_param_rrefs()
-    opt = DistributedOptimizer(optim.SGD, param_rrefs, lr=0.03)
+    opt = DistributedOptimizer(optim.SGD, param_rrefs, lr=0.03)  # 'torch.distributed.optim.DistributedOptimizer' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     for i, (data, target) in enumerate(train_loader):
+        # 'torch.distributed.autograd.context' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         with dist_autograd.context() as cid:
             model_output = net(data)
             target = target.to(model_output.device)
-            loss = F.nll_loss(model_output, target)
+            loss = nn.functional.nll_loss(model_output, target)
             if i % 5 == 0:
                 print(f"Rank {rank} training batch {i} loss {loss.item()}")
-            dist_autograd.backward(cid, [loss])
+            dist_autograd.backward(cid, [loss])  # 'torch.distributed.autograd.backward' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             # Ensure that dist autograd ran successfully and gradients were
             # returned.
             assert remote_method(
@@ -200,11 +208,13 @@     model.eval()
     correct_sum = 0
     # Use GPU to evaluate if possible
+    # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     if torch.accelerator.is_available() and model.num_gpus > 0:
-        acc = torch.accelerator.current_accelerator()
-        device = torch.device(f'{acc}:0')
+        acc = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        device = torch.device(f'{acc}:0')  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
-        device = torch.device("cpu")
+        device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with torch.no_grad():
         for i, (data, target) in enumerate(test_loader):
             out = model(data)
@@ -222,12 +232,12 @@     rpc.init_rpc(
         name=f"trainer_{rank}",
         rank=rank,
-        world_size=world_size)
+        world_size=world_size)  # 'torch.distributed.rpc.init_rpc' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     print(f"Worker {rank} done initializing RPC")
 
     run_training_loop(rank, num_gpus, train_loader, test_loader)
-    rpc.shutdown()
+    rpc.shutdown()  # 'torch.distributed.rpc.shutdown' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 # --------- Launcher --------------------
 
@@ -275,28 +285,28 @@ 
     # Note that Linux uses "fork" by default, which may cause deadlock.
     # Besides, cuda doesn't support "fork" and Windows only supports "spawn"
-    mp.set_start_method("spawn")
+    mp.set_start_method("spawn")  # 'torch.multiprocessing.set_start_method' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if args.rank == 0:
-        p = mp.Process(target=run_parameter_server, args=(0, world_size))
+        p = mp.Process(target=run_parameter_server, args=(0, world_size))  # 'torch.multiprocessing.Process' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         p.start()
         processes.append(p)
     else:
         # Get data to train on
         train_loader = torch.utils.data.DataLoader(
             datasets.MNIST('../data', train=True, download=True,
-                           transform=transforms.Compose([
+                           transform=ms.dataset.transforms.Compose([
                                transforms.ToTensor(),
                                transforms.Normalize((0.1307,), (0.3081,))
                            ])),
-            batch_size=32, shuffle=True)
+            batch_size=32, shuffle=True)  # 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.MNIST' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         test_loader = torch.utils.data.DataLoader(
             datasets.MNIST('../data', train=False,
-                           transform=transforms.Compose([
+                           transform=ms.dataset.transforms.Compose([
                                transforms.ToTensor(),
                                transforms.Normalize((0.1307,), (0.3081,))
                            ])),
-            batch_size=32, shuffle=True)
+            batch_size=32, shuffle=True)  # 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.MNIST' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         # start training worker on this node
         p = mp.Process(
             target=run_worker,
@@ -304,7 +314,7 @@                 args.rank,
                 world_size, args.num_gpus,
                 train_loader,
-                test_loader))
+                test_loader))  # 'torch.multiprocessing.Process' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         p.start()
         processes.append(p)
 
