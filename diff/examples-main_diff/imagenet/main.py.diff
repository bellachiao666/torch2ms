--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import argparse
 import os
 import random
@@ -6,20 +11,16 @@ import warnings
 from enum import Enum
 
-import torch
-import torch.backends.cudnn as cudnn
-import torch.distributed as dist
-import torch.multiprocessing as mp
-import torch.nn as nn
-import torch.nn.parallel
-import torch.optim
-import torch.utils.data
-import torch.utils.data.distributed
-import torchvision.datasets as datasets
-import torchvision.models as models
-import torchvision.transforms as transforms
-from torch.optim.lr_scheduler import StepLR
-from torch.utils.data import Subset
+# import torch
+# import torch.backends.cudnn as cudnn
+# import torch.distributed as dist
+# import torch.multiprocessing as mp
+# import torch.nn as nn
+# import torchvision.datasets as datasets
+# import torchvision.models as models
+# import torchvision.transforms as transforms
+# from torch.optim.lr_scheduler import StepLR
+# from torch.utils.data import Subset
 
 model_names = sorted(name for name in models.__dict__
     if name.islower() and not name.startswith("__")
@@ -88,7 +89,7 @@ 
     if args.seed is not None:
         random.seed(args.seed)
-        torch.manual_seed(args.seed)
+        torch.manual_seed(args.seed)  # 'torch.manual_seed' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         cudnn.deterministic = True
         cudnn.benchmark = False
         warnings.warn('You have chosen to seed training. '
@@ -106,17 +107,17 @@ 
     args.distributed = args.world_size > 1 or args.multiprocessing_distributed
 
-    use_accel = not args.no_accel and torch.accelerator.is_available()
+    use_accel = not args.no_accel and torch.accelerator.is_available()  # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if use_accel:
-        device = torch.accelerator.current_accelerator()
-    else:
-        device = torch.device("cpu")
+        device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    else:
+        device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     print(f"Using device: {device}")
 
     if device.type =='cuda':
-        ngpus_per_node = torch.accelerator.device_count()
+        ngpus_per_node = torch.accelerator.device_count()  # 'torch.accelerator.device_count' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if ngpus_per_node == 1 and args.dist_backend == "nccl":
             warnings.warn("nccl backend >=2.5 requires GPU count>1, see https://github.com/NVIDIA/nccl/issues/103 perhaps use 'gloo'")
     else:
@@ -128,7 +129,7 @@         args.world_size = ngpus_per_node * args.world_size
         # Use torch.multiprocessing.spawn to launch distributed processes: the
         # main_worker process function
-        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))
+        mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))  # 'torch.multiprocessing.spawn' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         # Simply call main_worker function
         main_worker(args.gpu, ngpus_per_node, args)
@@ -138,14 +139,14 @@     global best_acc1
     args.gpu = gpu
 
-    use_accel = not args.no_accel and torch.accelerator.is_available()
+    use_accel = not args.no_accel and torch.accelerator.is_available()  # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if use_accel:
         if args.gpu is not None:
-            torch.accelerator.set_device_index(args.gpu)
-        device = torch.accelerator.current_accelerator()
-    else:
-        device = torch.device("cpu")
+            torch.accelerator.set_device_index(args.gpu)  # 'torch.accelerator.set_device_index' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    else:
+        device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if args.distributed:
         if args.dist_url == "env://" and args.rank == -1:
@@ -154,15 +155,15 @@             # For multiprocessing distributed training, rank needs to be the
             # global rank among all the processes
             args.rank = args.rank * ngpus_per_node + gpu
-        dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,
+        mint.distributed.init_process_group(backend=args.dist_backend, init_method=args.dist_url,
                                 world_size=args.world_size, rank=args.rank)
     # create model
     if args.pretrained:
         print("=> using pre-trained model '{}'".format(args.arch))
-        model = models.__dict__[args.arch](pretrained=True)
+        model = models.__dict__[args.arch](pretrained=True)  # 'torchvision.models.__dict__' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         print("=> creating model '{}'".format(args.arch))
-        model = models.__dict__[args.arch]()
+        model = models.__dict__[args.arch]()  # 'torchvision.models.__dict__' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if not use_accel:
         print('using CPU, this will be slow')
@@ -172,50 +173,50 @@         # DistributedDataParallel will use all available devices.
         if device.type == 'cuda':
             if args.gpu is not None:
-                torch.cuda.set_device(args.gpu)
+                torch.cuda.set_device(args.gpu)  # 'torch.cuda.set_device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                 model.cuda(device)
                 # When using a single GPU per process and per
                 # DistributedDataParallel, we need to divide the batch size
                 # ourselves based on the total number of GPUs of the current node.
                 args.batch_size = int(args.batch_size / ngpus_per_node)
                 args.workers = int((args.workers + ngpus_per_node - 1) / ngpus_per_node)
-                model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])
+                model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])  # 'torch.nn.parallel.DistributedDataParallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             else:
                 model.cuda()
                 # DistributedDataParallel will divide and allocate batch_size to all
                 # available GPUs if device_ids are not set
-                model = torch.nn.parallel.DistributedDataParallel(model)
+                model = torch.nn.parallel.DistributedDataParallel(model)  # 'torch.nn.parallel.DistributedDataParallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif device.type == 'cuda':
         # DataParallel will divide and allocate batch_size to all available GPUs
         if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):
-            model.features = torch.nn.DataParallel(model.features)
+            model.features = torch.nn.DataParallel(model.features)  # 'torch.nn.DataParallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             model.cuda()
         else:
-            model = torch.nn.DataParallel(model).cuda()
+            model = torch.nn.DataParallel(model).cuda()  # 'torch.nn.DataParallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.nn.DataParallel.cuda' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         model.to(device)
 
 
     # define loss function (criterion), optimizer, and learning rate scheduler
-    criterion = nn.CrossEntropyLoss().to(device)
+    criterion = nn.CrossEntropyLoss().to(device)  # 'torch.nn.CrossEntropyLoss.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     optimizer = torch.optim.SGD(model.parameters(), args.lr,
                                 momentum=args.momentum,
-                                weight_decay=args.weight_decay)
+                                weight_decay=args.weight_decay)  # 'torch.optim.SGD' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     
     """Sets the learning rate to the initial LR decayed by 10 every 30 epochs"""
-    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)
+    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)  # 'torch.optim.lr_scheduler.StepLR' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     
     # optionally resume from a checkpoint
     if args.resume:
         if os.path.isfile(args.resume):
             print("=> loading checkpoint '{}'".format(args.resume))
             if args.gpu is None:
-                checkpoint = torch.load(args.resume)
+                checkpoint = torch.load(args.resume)  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             else:
                 # Map model to be loaded to specified single gpu.
                 loc = f'{device.type}:{args.gpu}'
-                checkpoint = torch.load(args.resume, map_location=loc)
+                checkpoint = torch.load(args.resume, map_location=loc)  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             args.start_epoch = checkpoint['epoch']
             best_acc1 = checkpoint['best_acc1']
             if args.gpu is not None:
@@ -233,46 +234,46 @@     # Data loading code
     if args.dummy:
         print("=> Dummy data is used!")
-        train_dataset = datasets.FakeData(1281167, (3, 224, 224), 1000, transforms.ToTensor())
-        val_dataset = datasets.FakeData(50000, (3, 224, 224), 1000, transforms.ToTensor())
+        train_dataset = datasets.FakeData(1281167, (3, 224, 224), 1000, transforms.ToTensor())  # 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.FakeData' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        val_dataset = datasets.FakeData(50000, (3, 224, 224), 1000, transforms.ToTensor())  # 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.FakeData' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         traindir = os.path.join(args.data, 'train')
         valdir = os.path.join(args.data, 'val')
         normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
-                                     std=[0.229, 0.224, 0.225])
+                                     std=[0.229, 0.224, 0.225])  # 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         train_dataset = datasets.ImageFolder(
             traindir,
-            transforms.Compose([
+            ms.dataset.transforms.Compose([
                 transforms.RandomResizedCrop(224),
                 transforms.RandomHorizontalFlip(),
                 transforms.ToTensor(),
                 normalize,
-            ]))
+            ]))  # 'torchvision.transforms.RandomResizedCrop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.RandomHorizontalFlip' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.ImageFolder' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         val_dataset = datasets.ImageFolder(
             valdir,
-            transforms.Compose([
-                transforms.Resize(256),
-                transforms.CenterCrop(224),
+            ms.dataset.transforms.Compose([
+                ms.dataset.vision.Resize(256),
+                ms.dataset.vision.CenterCrop(224),
                 transforms.ToTensor(),
                 normalize,
-            ]))
+            ]))  # 'torchvision.transforms.Resize'默认值不一致(position 1): PyTorch=<InterpolationMode.BILINEAR: 'bilinear'>, MindSpore=2;; 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.datasets.ImageFolder' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if args.distributed:
-        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)
-        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False, drop_last=True)
+        train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)  # 'torch.utils.data.distributed.DistributedSampler' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False, drop_last=True)  # 'torch.utils.data.distributed.DistributedSampler' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         train_sampler = None
         val_sampler = None
 
     train_loader = torch.utils.data.DataLoader(
         train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),
-        num_workers=args.workers, pin_memory=True, sampler=train_sampler)
+        num_workers=args.workers, pin_memory=True, sampler=train_sampler)  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     val_loader = torch.utils.data.DataLoader(
         val_dataset, batch_size=args.batch_size, shuffle=False,
-        num_workers=args.workers, pin_memory=True, sampler=val_sampler)
+        num_workers=args.workers, pin_memory=True, sampler=val_sampler)  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if args.evaluate:
         validate(val_loader, model, criterion, args)
@@ -308,7 +309,7 @@ 
 def train(train_loader, model, criterion, optimizer, epoch, device, args):
     
-    use_accel = not args.no_accel and torch.accelerator.is_available()
+    use_accel = not args.no_accel and torch.accelerator.is_available()  # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     batch_time = AverageMeter('Time', use_accel, ':6.3f', Summary.NONE)
     data_time = AverageMeter('Data', use_accel, ':6.3f', Summary.NONE)
@@ -357,22 +358,23 @@ 
 def validate(val_loader, model, criterion, args):
 
-    use_accel = not args.no_accel and torch.accelerator.is_available()
+    use_accel = not args.no_accel and torch.accelerator.is_available()  # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def run_validate(loader, base_progress=0):
 
         if use_accel:
-            device = torch.accelerator.current_accelerator()
+            device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
-            device = torch.device("cpu")
-
+            device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         with torch.no_grad():
             end = time.time()
             for i, (images, target) in enumerate(loader):
                 i = base_progress + i
                 if use_accel:
                     if args.gpu is not None and device.type=='cuda':
-                        torch.accelerator.set_device_index(args.gpu)
+                        torch.accelerator.set_device_index(args.gpu)  # 'torch.accelerator.set_device_index' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                         images = images.cuda(args.gpu, non_blocking=True)
                         target = target.cuda(args.gpu, non_blocking=True)
                     else:
@@ -415,10 +417,10 @@ 
     if args.distributed and (len(val_loader.sampler) * args.world_size < len(val_loader.dataset)):
         aux_val_dataset = Subset(val_loader.dataset,
-                                 range(len(val_loader.sampler) * args.world_size, len(val_loader.dataset)))
+                                 range(len(val_loader.sampler) * args.world_size, len(val_loader.dataset)))  # 'torch.utils.data.Subset' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         aux_val_loader = torch.utils.data.DataLoader(
             aux_val_dataset, batch_size=args.batch_size, shuffle=False,
-            num_workers=args.workers, pin_memory=True)
+            num_workers=args.workers, pin_memory=True)  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         run_validate(aux_val_loader, len(val_loader))
 
     progress.display_summary()
@@ -427,7 +429,7 @@ 
 
 def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):
-    torch.save(state, filename)
+    torch.save(state, filename)  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     if is_best:
         shutil.copyfile(filename, 'model_best.pth.tar')
 
@@ -460,17 +462,17 @@ 
     def all_reduce(self):    
         if self.use_accel:
-            device = torch.accelerator.current_accelerator()
+            device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
-            device = torch.device("cpu")
-        total = torch.tensor([self.sum, self.count], dtype=torch.float32, device=device)
-        dist.all_reduce(total, dist.ReduceOp.SUM, async_op=False)
+            device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        total = ms.Tensor([self.sum, self.count], dtype=ms.float32, device=device)
+        mint.distributed.all_reduce(total, dist.ReduceOp.SUM, async_op=False)
         self.sum, self.count = total.tolist()
         self.avg = self.sum / self.count
 
     def __str__(self):
         fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'
-        return fmtstr.format(**self.__dict__)
+        return fmtstr.format(**self.__dict__)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     
     def summary(self):
         fmtstr = ''
@@ -485,7 +487,7 @@         else:
             raise ValueError('invalid summary type %r' % self.summary_type)
         
-        return fmtstr.format(**self.__dict__)
+        return fmtstr.format(**self.__dict__)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 class ProgressMeter(object):
@@ -511,6 +513,7 @@ 
 def accuracy(output, target, topk=(1,)):
     """Computes the accuracy over the k top predictions for the specified values of k"""
+    # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with torch.no_grad():
         maxk = max(topk)
         batch_size = target.size(0)
