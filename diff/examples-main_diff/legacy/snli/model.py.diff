--- pytorch+++ mindspore@@ -1,10 +1,14 @@-import torch
-import torch.nn as nn
+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
+# import torch.nn as nn
 
 
-class Bottle(nn.Module):
+class Bottle(msnn.Cell):
 
-    def forward(self, input):
+    def construct(self, input):
         if len(input.size()) <= 2:
             return super(Bottle, self).forward(input)
         size = input.size()[:2]
@@ -16,7 +20,7 @@     pass
 
 
-class Encoder(nn.Module):
+class Encoder(msnn.Cell):
 
     def __init__(self, config):
         super(Encoder, self).__init__()
@@ -25,9 +29,9 @@         dropout = 0 if config.n_layers == 1 else config.dp_ratio
         self.rnn = nn.LSTM(input_size=input_size, hidden_size=config.d_hidden,
                         num_layers=config.n_layers, dropout=dropout,
-                        bidirectional=config.birnn)
+                        bidirectional=config.birnn)  # 'torch.nn.LSTM' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
-    def forward(self, inputs):
+    def construct(self, inputs):
         batch_size = inputs.size()[1]
         state_shape = self.config.n_cells, batch_size, self.config.d_hidden
         h0 = c0 = inputs.new_zeros(state_shape)
@@ -35,7 +39,7 @@         return ht[-1] if not self.config.birnn else ht[-2:].transpose(0, 1).contiguous().view(batch_size, -1)
 
 
-class SNLIClassifier(nn.Module):
+class SNLIClassifier(msnn.Cell):
 
     def __init__(self, config):
         super(SNLIClassifier, self).__init__()
@@ -43,13 +47,14 @@         self.embed = nn.Embedding(config.n_embed, config.d_embed)
         self.projection = Linear(config.d_embed, config.d_proj)
         self.encoder = Encoder(config)
-        self.dropout = nn.Dropout(p=config.dp_ratio)
+        self.dropout = nn.Dropout(p = config.dp_ratio)
         self.relu = nn.ReLU()
         seq_in_size = 2*config.d_hidden
         if self.config.birnn:
             seq_in_size *= 2
         lin_config = [seq_in_size]*2
-        self.out = nn.Sequential(
+        self.out = msnn.SequentialCell(
+            [
             Linear(*lin_config),
             self.relu,
             self.dropout,
@@ -59,9 +64,10 @@             Linear(*lin_config),
             self.relu,
             self.dropout,
-            Linear(seq_in_size, config.d_out))
+            Linear(seq_in_size, config.d_out)
+        ])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
-    def forward(self, batch):
+    def construct(self, batch):
         prem_embed = self.embed(batch.premise)
         hypo_embed = self.embed(batch.hypothesis)
         if self.config.fix_emb:
@@ -72,5 +78,5 @@             hypo_embed = self.relu(self.projection(hypo_embed))
         premise = self.encoder(prem_embed)
         hypothesis = self.encoder(hypo_embed)
-        scores = self.out(torch.cat([premise, hypothesis], 1))
+        scores = self.out(mint.cat([premise, hypothesis], 1))
         return scores
