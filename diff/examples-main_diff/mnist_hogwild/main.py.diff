--- pytorch+++ mindspore@@ -1,11 +1,14 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 from __future__ import print_function
 import argparse
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import torch.multiprocessing as mp
-from torch.utils.data.sampler import Sampler
-from torchvision import datasets, transforms
+# import torch
+# import torch.nn as nn
+# import torch.multiprocessing as mp
+# from torchvision import datasets, transforms
 
 from train import train, test
 
@@ -36,45 +39,45 @@ parser.add_argument('--dry-run', action='store_true', default=False,
                     help='quickly check a single pass')
 
-class Net(nn.Module):
+class Net(msnn.Cell):
     def __init__(self):
         super(Net, self).__init__()
-        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
-        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
+        self.conv1 = nn.Conv2d(1, 10, kernel_size = 5)
+        self.conv2 = nn.Conv2d(10, 20, kernel_size = 5)
         self.conv2_drop = nn.Dropout2d()
         self.fc1 = nn.Linear(320, 50)
         self.fc2 = nn.Linear(50, 10)
 
-    def forward(self, x):
-        x = F.relu(F.max_pool2d(self.conv1(x), 2))
-        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
+    def construct(self, x):
+        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))
+        x = nn.functional.relu(nn.functional.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
         x = x.view(-1, 320)
-        x = F.relu(self.fc1(x))
-        x = F.dropout(x, training=self.training)
+        x = nn.functional.relu(self.fc1(x))
+        x = nn.functional.dropout(x, training = self.training)
         x = self.fc2(x)
-        return F.log_softmax(x, dim=1)
+        return mint.special.log_softmax(x, dim=1)
 
 
 if __name__ == '__main__':
     args = parser.parse_args()
 
-    use_cuda = args.cuda and torch.cuda.is_available()
-    use_mps = args.mps and torch.backends.mps.is_available()
+    use_cuda = args.cuda and torch.cuda.is_available()  # 'torch.cuda.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    use_mps = args.mps and torch.backends.mps.is_available()  # 'torch.backends.mps.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     if use_cuda:
-        device = torch.device("cuda")
+        device = torch.device("cuda")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif use_mps:
-        device = torch.device("mps")
+        device = torch.device("mps")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
-        device = torch.device("cpu")
+        device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
-    transform=transforms.Compose([
+    transform=ms.dataset.transforms.Compose([
         transforms.ToTensor(),
         transforms.Normalize((0.1307,), (0.3081,))
-        ])
+        ])  # 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     dataset1 = datasets.MNIST('../data', train=True, download=True,
-                       transform=transform)
+                       transform=transform)  # 'torchvision.datasets.MNIST' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     dataset2 = datasets.MNIST('../data', train=False,
-                       transform=transform)
+                       transform=transform)  # 'torchvision.datasets.MNIST' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     kwargs = {'batch_size': args.batch_size,
               'shuffle': True}
     if use_cuda:
@@ -82,8 +85,8 @@                        'pin_memory': True,
                       })
 
-    torch.manual_seed(args.seed)
-    mp.set_start_method('spawn', force=True)
+    torch.manual_seed(args.seed)  # 'torch.manual_seed' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    mp.set_start_method('spawn', force=True)  # 'torch.multiprocessing.set_start_method' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     model = Net().to(device)
     model.share_memory() # gradients are allocated lazily, so they are not shared here
@@ -91,7 +94,7 @@     processes = []
     for rank in range(args.num_processes):
         p = mp.Process(target=train, args=(rank, args, model, device,
-                                           dataset1, kwargs))
+                                           dataset1, kwargs))  # 'torch.multiprocessing.Process' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         # We first train the model across `num_processes` processes
         p.start()
         processes.append(p)
@@ -99,7 +102,7 @@         p.join()
 
     if args.save_model:
-        torch.save(model.state_dict(), "MNIST_hogwild.pt")
+        torch.save(model.state_dict(), "MNIST_hogwild.pt")  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     # Once training is complete, we can test the model
     test(args, model, device, dataset2, kwargs)
