--- pytorch+++ mindspore@@ -1,19 +1,22 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 from __future__ import print_function
 import argparse, random, copy
 import numpy as np
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import torch.optim as optim
-import torchvision
-from torch.utils.data import Dataset
-from torchvision import datasets
-from torchvision import transforms as T
-from torch.optim.lr_scheduler import StepLR
-
-
-class SiameseNetwork(nn.Module):
+# import torch
+# import torch.nn as nn
+# import torch.optim as optim
+# import torchvision
+# from torch.utils.data import Dataset
+# from torchvision import datasets
+# from torch.optim.lr_scheduler import StepLR
+
+
+class SiameseNetwork(msnn.Cell):
     """
         Siamese network for image similarity estimation.
         The network is composed of two identical networks, one for each input.
@@ -27,23 +30,24 @@     def __init__(self):
         super(SiameseNetwork, self).__init__()
         # get resnet model
-        self.resnet = torchvision.models.resnet18(weights=None)
+        self.resnet = torchvision.models.resnet18(weights=None)  # 'torchvision.models.resnet18' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         # over-write the first conv layer to be able to read MNIST images
         # as resnet18 reads (3,x,x) where 3 is RGB channels
         # whereas MNIST has (1,x,x) where 1 is a gray-scale channel
-        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
+        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)
         self.fc_in_features = self.resnet.fc.in_features
         
         # remove the last layer of resnet18 (linear layer which is before avgpool layer)
-        self.resnet = torch.nn.Sequential(*(list(self.resnet.children())[:-1]))
+        self.resnet = msnn.SequentialCell(*(list(self.resnet.children())[:-1]))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         # add linear layers to compare between the features of the two images
-        self.fc = nn.Sequential(
+        self.fc = msnn.SequentialCell(
+            [
             nn.Linear(self.fc_in_features * 2, 256),
-            nn.ReLU(inplace=True),
-            nn.Linear(256, 1),
-        )
+            nn.ReLU(),
+            nn.Linear(256, 1)
+        ])  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
 
         self.sigmoid = nn.Sigmoid()
 
@@ -53,7 +57,7 @@         
     def init_weights(self, m):
         if isinstance(m, nn.Linear):
-            torch.nn.init.xavier_uniform_(m.weight)
+            torch.nn.init.xavier_uniform_(m.weight)  # 'torch.nn.init.xavier_uniform_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             m.bias.data.fill_(0.01)
 
     def forward_once(self, x):
@@ -61,13 +65,13 @@         output = output.view(output.size()[0], -1)
         return output
 
-    def forward(self, input1, input2):
+    def construct(self, input1, input2):
         # get two images' features
         output1 = self.forward_once(input1)
         output2 = self.forward_once(input2)
 
         # concatenate both images' features
-        output = torch.cat((output1, output2), 1)
+        output = mint.cat((output1, output2), 1)
 
         # pass the concatenation to the linear layers
         output = self.fc(output)
@@ -77,12 +81,13 @@         
         return output
 
+# 'torch.utils.data.Dataset' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 class APP_MATCHER(Dataset):
     def __init__(self, root, train, download=False):
         super(APP_MATCHER, self).__init__()
 
         # get MNIST dataset
-        self.dataset = datasets.MNIST(root, train=train, download=download)
+        self.dataset = datasets.MNIST(root, train=train, download=download)  # 'torchvision.datasets.MNIST' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         
         # as `self.dataset.data`'s shape is (Nx28x28), where N is the number of
         # examples in MNIST dataset, a single example has the dimensions of
@@ -159,7 +164,7 @@             image_2 = self.data[index_2].clone().float()
 
             # set the label for this example to be positive (1)
-            target = torch.tensor(1, dtype=torch.float)
+            target = ms.Tensor(1, dtype=ms.float32)
         
         # different class
         else:
@@ -182,7 +187,7 @@             image_2 = self.data[index_2].clone().float()
 
             # set the label for this example to be negative (0)
-            target = torch.tensor(0, dtype=torch.float)
+            target = ms.Tensor(0, dtype=ms.float32)
 
         return image_1, image_2, target
 
@@ -216,12 +221,13 @@     # we aren't using `TripletLoss` as the MNIST dataset is simple, so `BCELoss` can do the trick.
     criterion = nn.BCELoss()
 
+    # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with torch.no_grad():
         for (images_1, images_2, targets) in test_loader:
             images_1, images_2, targets = images_1.to(device), images_2.to(device), targets.to(device)
             outputs = model(images_1, images_2).squeeze()
             test_loss += criterion(outputs, targets).sum().item()  # sum up batch loss
-            pred = torch.where(outputs > 0.5, 1, 0)  # get the index of the max log-probability
+            pred = mint.where(outputs > 0.5, 1, 0)  # get the index of the max log-probability
             correct += pred.eq(targets.view_as(pred)).sum().item()
 
     test_loss /= len(test_loader.dataset)
@@ -259,15 +265,15 @@                         help='For Saving the current Model')
     args = parser.parse_args()
     
-    use_accel = not args.no_accel and torch.accelerator.is_available()
-
-    torch.manual_seed(args.seed)
+    use_accel = not args.no_accel and torch.accelerator.is_available()  # 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    torch.manual_seed(args.seed)  # 'torch.manual_seed' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
     if use_accel:
-        device = torch.accelerator.current_accelerator()
+        device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
-        device = torch.device("cpu")
+        device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     
     print(f"Using device: {device}")
 
@@ -282,20 +288,20 @@ 
     train_dataset = APP_MATCHER('../data', train=True, download=True)
     test_dataset = APP_MATCHER('../data', train=False)
-    train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)
-    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)
+    train_loader = torch.utils.data.DataLoader(train_dataset,**train_kwargs)  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    test_loader = torch.utils.data.DataLoader(test_dataset, **test_kwargs)  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     model = SiameseNetwork().to(device)
-    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)
-
-    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)
+    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)  # 'torch.optim.Adadelta' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)  # 'torch.optim.lr_scheduler.StepLR' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     for epoch in range(1, args.epochs + 1):
         train(args, model, device, train_loader, optimizer, epoch)
         test(model, device, test_loader)
         scheduler.step()
 
     if args.save_model:
-        torch.save(model.state_dict(), "siamese_network.pt")
+        torch.save(model.state_dict(), "siamese_network.pt")  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
 if __name__ == '__main__':
