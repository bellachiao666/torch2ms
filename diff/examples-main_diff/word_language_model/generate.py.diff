--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 ###############################################################################
 # Language Modeling on Wikitext-2
 #
@@ -5,7 +10,7 @@ #
 ###############################################################################
 import argparse
-import torch
+# import torch
 
 import data
 from model import PositionalEncoding, RNNModel, TransformerModel
@@ -31,13 +36,14 @@ args = parser.parse_args()
 
 # Set the random seed manually for reproducibility.
-torch.manual_seed(args.seed)
+torch.manual_seed(args.seed)  # 'torch.manual_seed' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
+# 'torch.accelerator.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 if args.accel and torch.accelerator.is_available():
-    device = torch.accelerator.current_accelerator()
+    device = torch.accelerator.current_accelerator()  # 'torch.accelerator.current_accelerator' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 else:
-    device = torch.device("cpu")
+    device = torch.device("cpu")  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 if args.temperature < 1e-3:
     parser.error("--temperature has to be greater or equal 1e-3.")
@@ -47,22 +53,23 @@         PositionalEncoding,
         RNNModel,
         TransformerModel,
-        torch.nn.functional.relu,
+        nn.functional.relu,
         torch.nn.modules.activation.MultiheadAttention,
-        torch.nn.modules.container.ModuleList,
-        torch.nn.modules.dropout.Dropout,
-        torch.nn.modules.linear.Linear,
-        torch.nn.modules.linear.NonDynamicallyQuantizableLinear,
-        torch.nn.modules.normalization.LayerNorm,
-        torch.nn.modules.sparse.Embedding,
+        msnn.CellList,
+        nn.functional.dropout.Dropout,
+        nn.functional.linear.Linear,
+        nn.functional.linear.NonDynamicallyQuantizableLinear,
+        nn.LayerNorm,
+        nn.Embedding,
         torch.nn.modules.rnn.GRU,
         torch.nn.modules.rnn.LSTM,
         torch.nn.modules.rnn.RNN,
         torch.nn.modules.transformer.TransformerEncoder,
         torch.nn.modules.transformer.TransformerEncoderLayer,
     ]
+    # 'torch.serialization.safe_globals' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with torch.serialization.safe_globals(safe_globals):
-        model = torch.load(f, map_location=device)
+        model = torch.load(f, map_location=device)  # 'torch.load' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 model.eval()
 
 corpus = data.Corpus(args.data)
@@ -71,21 +78,22 @@ is_transformer_model = hasattr(model, 'model_type') and model.model_type == 'Transformer'
 if not is_transformer_model:
     hidden = model.init_hidden(1)
-input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)
+input = mint.randint(ntokens, (1, 1), dtype=ms.int64).to(device)
 
 with open(args.outf, 'w') as outf:
+    # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     with torch.no_grad():  # no tracking history
         for i in range(args.words):
             if is_transformer_model:
                 output = model(input, False)
                 word_weights = output[-1].squeeze().div(args.temperature).exp().cpu()
-                word_idx = torch.multinomial(word_weights, 1)[0]
-                word_tensor = torch.Tensor([[word_idx]]).long().to(device)
-                input = torch.cat([input, word_tensor], 0)
+                word_idx = mint.multinomial(word_weights, 1)[0]
+                word_tensor = ms.Tensor([[word_idx]]).long().to(device)
+                input = mint.cat([input, word_tensor], 0)
             else:
                 output, hidden = model(input, hidden)
                 word_weights = output.squeeze().div(args.temperature).exp().cpu()
-                word_idx = torch.multinomial(word_weights, 1)[0]
+                word_idx = mint.multinomial(word_weights, 1)[0]
                 input.fill_(word_idx)
 
             word = corpus.dictionary.idx2word[word_idx]
