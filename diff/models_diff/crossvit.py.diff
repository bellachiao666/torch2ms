--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ CrossViT Model
 
 @inproceedings{
@@ -23,8 +28,8 @@ from functools import partial
 from typing import List, Optional, Tuple, Type, Union
 
-import torch
-import torch.nn as nn
+# import torch
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import DropPath, calculate_drop_path_rates, to_2tuple, trunc_normal_, _assert
@@ -36,7 +41,7 @@ __all__ = ['CrossVit']  # model_registry will add each entrypoint fn to this
 
 
-class PatchEmbed(nn.Module):
+class PatchEmbed(msnn.Cell):
     """ Image to Patch Embedding
     """
 
@@ -60,25 +65,25 @@         self.num_patches = num_patches
         if multi_conv:
             if patch_size[0] == 12:
-                self.proj = nn.Sequential(
+                self.proj = msnn.SequentialCell(
                     nn.Conv2d(in_chans, embed_dim // 4, kernel_size=7, stride=4, padding=3, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 4, embed_dim // 2, kernel_size=3, stride=3, padding=0, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 2, embed_dim, kernel_size=3, stride=1, padding=1, **dd),
-                )
+                )  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
             elif patch_size[0] == 16:
-                self.proj = nn.Sequential(
+                self.proj = msnn.SequentialCell(
                     nn.Conv2d(in_chans, embed_dim // 4, kernel_size=7, stride=4, padding=3, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 4, embed_dim // 2, kernel_size=3, stride=2, padding=1, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 2, embed_dim, kernel_size=3, stride=2, padding=1, **dd),
-                )
+                )  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
         else:
             self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, **dd)
 
-    def forward(self, x):
+    def construct(self, x):
         B, C, H, W = x.shape
         # FIXME look at relaxing size constraints
         _assert(H == self.img_size[0],
@@ -89,7 +94,7 @@         return x
 
 
-class CrossAttention(nn.Module):
+class CrossAttention(msnn.Cell):
     def __init__(
             self,
             dim: int,
@@ -114,7 +119,7 @@         self.proj = nn.Linear(dim, dim, **dd)
         self.proj_drop = nn.Dropout(proj_drop)
 
-    def forward(self, x):
+    def construct(self, x):
         B, N, C = x.shape
         # B1C -> B1H(C/H) -> BH1(C/H)
         q = self.wq(x[:, 0:1, ...]).reshape(B, 1, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)
@@ -133,7 +138,7 @@         return x
 
 
-class CrossAttentionBlock(nn.Module):
+class CrossAttentionBlock(msnn.Cell):
 
     def __init__(
             self,
@@ -144,8 +149,8 @@             proj_drop: float = 0.,
             attn_drop: float = 0.,
             drop_path: float = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             device=None,
             dtype=None,
     ):
@@ -161,14 +166,14 @@             **dd,
         )
         # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here
-        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x):
+        self.drop_path = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x):
         x = x[:, 0:1, ...] + self.drop_path(self.attn(self.norm1(x)))
         return x
 
 
-class MultiScaleBlock(nn.Module):
+class MultiScaleBlock(msnn.Cell):
 
     def __init__(
             self,
@@ -181,8 +186,8 @@             proj_drop: float = 0.,
             attn_drop: float = 0.,
             drop_path: Union[List[float], float] = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             device=None,
             dtype=None,
     ):
@@ -191,7 +196,7 @@         num_branches = len(dim)
         self.num_branches = num_branches
         # different branch could have different embedding size, the first one is the base
-        self.blocks = nn.ModuleList()
+        self.blocks = msnn.CellList()
         for d in range(num_branches):
             tmp = []
             for i in range(depth[d]):
@@ -207,20 +212,20 @@                     **dd,
                 ))
             if len(tmp) != 0:
-                self.blocks.append(nn.Sequential(*tmp))
+                self.blocks.append(msnn.SequentialCell(*tmp))
 
         if len(self.blocks) == 0:
             self.blocks = None
 
-        self.projs = nn.ModuleList()
+        self.projs = msnn.CellList()
         for d in range(num_branches):
             if dim[d] == dim[(d + 1) % num_branches] and False:
-                tmp = [nn.Identity()]
+                tmp = [msnn.Identity()]
             else:
                 tmp = [norm_layer(dim[d], **dd), act_layer(), nn.Linear(dim[d], dim[(d + 1) % num_branches], **dd)]
-            self.projs.append(nn.Sequential(*tmp))
-
-        self.fusion = nn.ModuleList()
+            self.projs.append(msnn.SequentialCell(*tmp))
+
+        self.fusion = msnn.CellList()
         for d in range(num_branches):
             d_ = (d + 1) % num_branches
             nh = num_heads[d_]
@@ -251,35 +256,35 @@                         norm_layer=norm_layer,
                         **dd,
                     ))
-                self.fusion.append(nn.Sequential(*tmp))
-
-        self.revert_projs = nn.ModuleList()
+                self.fusion.append(msnn.SequentialCell(*tmp))
+
+        self.revert_projs = msnn.CellList()
         for d in range(num_branches):
             if dim[(d + 1) % num_branches] == dim[d] and False:
-                tmp = [nn.Identity()]
+                tmp = [msnn.Identity()]
             else:
                 tmp = [norm_layer(dim[(d + 1) % num_branches], **dd), act_layer(),
                        nn.Linear(dim[(d + 1) % num_branches], dim[d], **dd)]
-            self.revert_projs.append(nn.Sequential(*tmp))
-
-    def forward(self, x: List[torch.Tensor]) -> List[torch.Tensor]:
+            self.revert_projs.append(msnn.SequentialCell(*tmp))
+
+    def construct(self, x: List[ms.Tensor]) -> List[ms.Tensor]:
 
         outs_b = []
         for i, block in enumerate(self.blocks):
             outs_b.append(block(x[i]))
 
         # only take the cls token out
-        proj_cls_token = torch.jit.annotate(List[torch.Tensor], [])
+        proj_cls_token = torch.jit.annotate(List[ms.Tensor], [])  # 'torch.jit.annotate' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         for i, proj in enumerate(self.projs):
             proj_cls_token.append(proj(outs_b[i][:, 0:1, ...]))
 
         # cross attention
         outs = []
         for i, (fusion, revert_proj) in enumerate(zip(self.fusion, self.revert_projs)):
-            tmp = torch.cat((proj_cls_token[i], outs_b[(i + 1) % self.num_branches][:, 1:, ...]), dim=1)
+            tmp = mint.cat((proj_cls_token[i], outs_b[(i + 1) % self.num_branches][:, 1:, ...]), dim=1)
             tmp = fusion(tmp)
             reverted_proj_cls_token = revert_proj(tmp[:, 0:1, ...])
-            tmp = torch.cat((reverted_proj_cls_token, outs_b[i][:, 1:, ...]), dim=1)
+            tmp = mint.cat((reverted_proj_cls_token, outs_b[i][:, 1:, ...]), dim=1)
             outs.append(tmp)
         return outs
 
@@ -305,11 +310,11 @@             cu, cl = int(round((H - ss[0]) / 2.)), int(round((W - ss[1]) / 2.))
             x = x[:, :, cu:cu + ss[0], cl:cl + ss[1]]
         else:
-            x = torch.nn.functional.interpolate(x, size=ss, mode='bicubic', align_corners=False)
+            x = nn.functional.interpolate(x, size = ss, mode = 'bicubic', align_corners = False)
     return x
 
 
-class CrossVit(nn.Module):
+class CrossVit(msnn.Cell):
     """ Vision Transformer with support for patch or hybrid CNN input stage
     """
 
@@ -332,7 +337,7 @@             proj_drop_rate: float = 0.,
             attn_drop_rate: float = 0.,
             drop_path_rate: float = 0.,
-            norm_layer: Type[nn.Module] = partial(nn.LayerNorm, eps=1e-6),
+            norm_layer: Type[msnn.Cell] = partial(nn.LayerNorm, eps=1e-6),
             global_pool: str = 'token',
             device=None,
             dtype=None,
@@ -351,12 +356,12 @@         self.num_branches = len(patch_size)
         self.embed_dim = embed_dim
         self.num_features = self.head_hidden_size = sum(embed_dim)
-        self.patch_embed = nn.ModuleList()
+        self.patch_embed = msnn.CellList()
 
         # hard-coded for torch jit script
         for i in range(self.num_branches):
-            setattr(self, f'pos_embed_{i}', nn.Parameter(torch.zeros(1, 1 + num_patches[i], embed_dim[i], **dd)))
-            setattr(self, f'cls_token_{i}', nn.Parameter(torch.zeros(1, 1, embed_dim[i], **dd)))
+            setattr(self, f'pos_embed_{i}', ms.Parameter(mint.zeros(1, 1 + num_patches[i], embed_dim[i], **dd)))
+            setattr(self, f'cls_token_{i}', ms.Parameter(mint.zeros(1, 1, embed_dim[i], **dd)))
 
         for im_s, p, d in zip(self.img_size_scaled, patch_size, embed_dim):
             self.patch_embed.append(
@@ -369,12 +374,12 @@                     **dd,
                 ))
 
-        self.pos_drop = nn.Dropout(p=pos_drop_rate)
+        self.pos_drop = nn.Dropout(p = pos_drop_rate)
 
         total_depth = sum([sum(x[-2:]) for x in depth])
         dpr = calculate_drop_path_rates(drop_path_rate, total_depth)  # stochastic depth decay rule
         dpr_ptr = 0
-        self.blocks = nn.ModuleList()
+        self.blocks = msnn.CellList()
         for idx, block_cfg in enumerate(depth):
             curr_depth = max(block_cfg[:-1]) + block_cfg[-1]
             dpr_ = dpr[dpr_ptr:dpr_ptr + curr_depth]
@@ -394,10 +399,10 @@             dpr_ptr += curr_depth
             self.blocks.append(blk)
 
-        self.norm = nn.ModuleList([norm_layer(embed_dim[i], **dd) for i in range(self.num_branches)])
+        self.norm = msnn.CellList([norm_layer(embed_dim[i], **dd) for i in range(self.num_branches)])
         self.head_drop = nn.Dropout(drop_rate)
-        self.head = nn.ModuleList([
-            nn.Linear(embed_dim[i], num_classes, **dd) if num_classes > 0 else nn.Identity()
+        self.head = msnn.CellList([
+            nn.Linear(embed_dim[i], num_classes, **dd) if num_classes > 0 else msnn.Identity()
             for i in range(self.num_branches)])
 
         for i in range(self.num_branches):
@@ -410,10 +415,10 @@         if isinstance(m, nn.Linear):
             trunc_normal_(m.weight, std=.02)
             if isinstance(m, nn.Linear) and m.bias is not None:
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         elif isinstance(m, nn.LayerNorm):
-            nn.init.constant_(m.bias, 0)
-            nn.init.constant_(m.weight, 1.0)
+            nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            nn.init.constant_(m.weight, 1.0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     @torch.jit.ignore
     def no_weight_decay(self):
@@ -437,7 +442,7 @@         assert not enable, 'gradient checkpointing not supported'
 
     @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    def get_classifier(self) -> msnn.Cell:
         return self.head
 
     def reset_classifier(self, num_classes: int, global_pool: Optional[str] = None):
@@ -448,12 +453,12 @@         device = self.head[0].weight.device if hasattr(self.head[0], 'weight') else None
         dtype = self.head[0].weight.dtype if hasattr(self.head[0], 'weight') else None
         dd = {'device': device, 'dtype': dtype}
-        self.head = nn.ModuleList([
-            nn.Linear(self.embed_dim[i], num_classes, **dd) if num_classes > 0 else nn.Identity()
+        self.head = msnn.CellList([
+            nn.Linear(self.embed_dim[i], num_classes, **dd) if num_classes > 0 else msnn.Identity()
             for i in range(self.num_branches)
         ])
 
-    def forward_features(self, x) -> List[torch.Tensor]:
+    def forward_features(self, x) -> List[ms.Tensor]:
         B = x.shape[0]
         xs = []
         for i, patch_embed in enumerate(self.patch_embed):
@@ -463,7 +468,7 @@             x_ = patch_embed(x_)
             cls_tokens = self.cls_token_0 if i == 0 else self.cls_token_1  # hard-coded for torch jit script
             cls_tokens = cls_tokens.expand(B, -1, -1)
-            x_ = torch.cat((cls_tokens, x_), dim=1)
+            x_ = mint.cat((cls_tokens, x_), dim=1)
             pos_embed = self.pos_embed_0 if i == 0 else self.pos_embed_1  # hard-coded for torch jit script
             x_ = x_ + pos_embed
             x_ = self.pos_drop(x_)
@@ -476,14 +481,14 @@         xs = [norm(xs[i]) for i, norm in enumerate(self.norm)]
         return xs
 
-    def forward_head(self, xs: List[torch.Tensor], pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, xs: List[ms.Tensor], pre_logits: bool = False) -> ms.Tensor:
         xs = [x[:, 1:].mean(dim=1) for x in xs] if self.global_pool == 'avg' else [x[:, 0] for x in xs]
         xs = [self.head_drop(x) for x in xs]
-        if pre_logits or isinstance(self.head[0], nn.Identity):
-            return torch.cat([x for x in xs], dim=1)
-        return torch.mean(torch.stack([head(xs[i]) for i, head in enumerate(self.head)], dim=0), dim=0)
-
-    def forward(self, x):
+        if pre_logits or isinstance(self.head[0], msnn.Identity):
+            return mint.cat([x for x in xs], dim=1)
+        return mint.mean(mint.stack([head(xs[i]) for i, head in enumerate(self.head)], dim=0), dim=0)
+
+    def construct(self, x):
         xs = self.forward_features(x)
         x = self.forward_head(xs)
         return x
