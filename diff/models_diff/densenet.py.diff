--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """Pytorch Densenet implementation w/ tweaks
 This file is a copy of https://github.com/pytorch/vision 'densenet.py' (BSD-3-Clause) with
 fixed kwargs passthrough and addition of dynamic global avg/max pool.
@@ -6,10 +11,9 @@ from collections import OrderedDict
 from typing import Any, Dict, Optional, Tuple, Type, Union
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-from torch.jit.annotations import List
+# import torch
+# import torch.nn as nn
+# from torch.jit.annotations import List
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import BatchNormAct2d, get_norm_act_layer, BlurPool2d, create_classifier
@@ -20,7 +24,7 @@ __all__ = ['DenseNet']
 
 
-class DenseLayer(nn.Module):
+class DenseLayer(msnn.Cell):
     """Dense layer for DenseNet.
 
     Implements the bottleneck layer with 1x1 and 3x3 convolutions.
@@ -31,7 +35,7 @@             num_input_features: int,
             growth_rate: int,
             bn_size: int,
-            norm_layer: Type[nn.Module] = BatchNormAct2d,
+            norm_layer: Type[msnn.Cell] = BatchNormAct2d,
             drop_rate: float = 0.,
             grad_checkpointing: bool = False,
             device=None,
@@ -58,22 +62,25 @@         self.drop_rate = float(drop_rate)
         self.grad_checkpointing = grad_checkpointing
 
-    def bottleneck_fn(self, xs: List[torch.Tensor]) -> torch.Tensor:
+    # 'torch.jit.annotations.List' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    def bottleneck_fn(self, xs: List[ms.Tensor]) -> ms.Tensor:
         """Bottleneck function for concatenated features."""
-        concated_features = torch.cat(xs, 1)
+        concated_features = mint.cat(xs, 1)
         bottleneck_output = self.conv1(self.norm1(concated_features))  # noqa: T484
         return bottleneck_output
 
     # todo: rewrite when torchscript supports any
-    def any_requires_grad(self, x: List[torch.Tensor]) -> bool:
+    # 'torch.jit.annotations.List' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    def any_requires_grad(self, x: List[ms.Tensor]) -> bool:
         """Check if any tensor in list requires gradient."""
         for tensor in x:
             if tensor.requires_grad:
                 return True
         return False
 
+    # 'torch.jit.annotations.List' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     @torch.jit.unused  # noqa: T484
-    def call_checkpoint_bottleneck(self, x: List[torch.Tensor]) -> torch.Tensor:
+    def call_checkpoint_bottleneck(self, x: List[ms.Tensor]) -> ms.Tensor:
         """Call bottleneck function with gradient checkpointing."""
         def closure(*xs):
             return self.bottleneck_fn(xs)
@@ -81,18 +88,19 @@         return checkpoint(closure, *x)
 
     @torch.jit._overload_method  # noqa: F811
-    def forward(self, x):
+    def construct(self, x):
         # type: (List[torch.Tensor]) -> (torch.Tensor)
         pass
 
     @torch.jit._overload_method  # noqa: F811
-    def forward(self, x):
+    def construct(self, x):
         # type: (torch.Tensor) -> (torch.Tensor)
         pass
 
     # torchscript does not yet support *args, so we overload method
     # allowing it to take either a List[Tensor] or single Tensor
-    def forward(self, x: Union[torch.Tensor, List[torch.Tensor]]) -> torch.Tensor:  # noqa: F811
+    # 'torch.jit.annotations.List' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    def construct(self, x: Union[ms.Tensor, List[ms.Tensor]]) -> ms.Tensor:  # noqa: F811
         """Forward pass.
 
         Args:
@@ -101,7 +109,7 @@         Returns:
             New features to be concatenated.
         """
-        if isinstance(x, torch.Tensor):
+        if isinstance(x, ms.Tensor):
             prev_features = [x]
         else:
             prev_features = x
@@ -115,10 +123,11 @@ 
         new_features = self.conv2(self.norm2(bottleneck_output))
         if self.drop_rate > 0:
-            new_features = F.dropout(new_features, p=self.drop_rate, training=self.training)
+            new_features = nn.functional.dropout(new_features, p = self.drop_rate, training = self.training)
         return new_features
 
 
+# 'torch.nn.ModuleDict' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 class DenseBlock(nn.ModuleDict):
     """DenseNet Block.
 
@@ -132,7 +141,7 @@             num_input_features: int,
             bn_size: int,
             growth_rate: int,
-            norm_layer: Type[nn.Module] = BatchNormAct2d,
+            norm_layer: Type[msnn.Cell] = BatchNormAct2d,
             drop_rate: float = 0.,
             grad_checkpointing: bool = False,
             device=None,
@@ -163,7 +172,7 @@             )
             self.add_module('denselayer%d' % (i + 1), layer)
 
-    def forward(self, init_features: torch.Tensor) -> torch.Tensor:
+    def forward(self, init_features: ms.Tensor) -> ms.Tensor:
         """Forward pass through all layers in the block.
 
         Args:
@@ -176,10 +185,10 @@         for name, layer in self.items():
             new_features = layer(features)
             features.append(new_features)
-        return torch.cat(features, 1)
-
-
-class DenseTransition(nn.Sequential):
+        return mint.cat(features, 1)
+
+
+class DenseTransition(msnn.SequentialCell):
     """Transition layer between DenseNet blocks.
 
     Reduces feature dimensions and spatial resolution.
@@ -189,8 +198,8 @@             self,
             num_input_features: int,
             num_output_features: int,
-            norm_layer: Type[nn.Module] = BatchNormAct2d,
-            aa_layer: Optional[Type[nn.Module]] = None,
+            norm_layer: Type[msnn.Cell] = BatchNormAct2d,
+            aa_layer: Optional[Type[msnn.Cell]] = None,
             device=None,
             dtype=None,
     ) -> None:
@@ -210,10 +219,10 @@         if aa_layer is not None:
             self.add_module('pool', aa_layer(num_output_features, stride=2, **dd))
         else:
-            self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))
-
-
-class DenseNet(nn.Module):
+            self.add_module('pool', nn.AvgPool2d(kernel_size = 2, stride = 2))
+
+
+class DenseNet(msnn.Cell):
     """Densenet-BC model class.
 
     Based on `"Densely Connected Convolutional Networks" <https://arxiv.org/pdf/1608.06993.pdf>`_
@@ -241,7 +250,7 @@             stem_type: str = '',
             act_layer: str = 'relu',
             norm_layer: str = 'batchnorm2d',
-            aa_layer: Optional[Type[nn.Module]] = None,
+            aa_layer: Optional[Type[msnn.Cell]] = None,
             drop_rate: float = 0.,
             proj_drop_rate: float = 0.,
             memory_efficient: bool = False,
@@ -276,17 +285,17 @@         deep_stem = 'deep' in stem_type  # 3x3 deep stem
         num_init_features = growth_rate * 2
         if aa_layer is None:
-            stem_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
+            stem_pool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)
         else:
-            stem_pool = nn.Sequential(*[
-                nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
+            stem_pool = msnn.SequentialCell(*[
+                nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),
                 aa_layer(channels=num_init_features, stride=2, **dd)])
         if deep_stem:
             stem_chs_1 = stem_chs_2 = growth_rate
             if 'tiered' in stem_type:
                 stem_chs_1 = 3 * (growth_rate // 4)
                 stem_chs_2 = num_init_features if 'narrow' in stem_type else 6 * (growth_rate // 4)
-            self.features = nn.Sequential(OrderedDict([
+            self.features = msnn.SequentialCell(OrderedDict([
                 ('conv0', nn.Conv2d(in_chans, stem_chs_1, 3, stride=2, padding=1, bias=False, **dd)),
                 ('norm0', norm_layer(stem_chs_1, **dd)),
                 ('conv1', nn.Conv2d(stem_chs_1, stem_chs_2, 3, stride=1, padding=1, bias=False, **dd)),
@@ -296,7 +305,7 @@                 ('pool0', stem_pool),
             ]))
         else:
-            self.features = nn.Sequential(OrderedDict([
+            self.features = msnn.SequentialCell(OrderedDict([
                 ('conv0', nn.Conv2d(in_chans, num_init_features, kernel_size=7, stride=2, padding=3, bias=False, **dd)),
                 ('norm0', norm_layer(num_init_features, **dd)),
                 ('pool0', stem_pool),
@@ -356,12 +365,12 @@         # Official init from torch repo.
         for m in self.modules():
             if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight)
+                nn.init.kaiming_normal_(m.weight)  # 'torch.nn.init.kaiming_normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.BatchNorm2d):
-                nn.init.constant_(m.weight, 1)
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.weight, 1)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.Linear):
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     @torch.jit.ignore
     def group_matcher(self, coarse: bool = False) -> Dict[str, Any]:
@@ -383,7 +392,7 @@                 b.grad_checkpointing = enable
 
     @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    def get_classifier(self) -> msnn.Cell:
         """Get the classifier head."""
         return self.classifier
 
@@ -398,11 +407,11 @@         self.global_pool, self.classifier = create_classifier(
             self.num_features, self.num_classes, pool_type=global_pool)
 
-    def forward_features(self, x: torch.Tensor) -> torch.Tensor:
+    def forward_features(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through feature extraction layers."""
         return self.features(x)
 
-    def forward_head(self, x: torch.Tensor, pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, x: ms.Tensor, pre_logits: bool = False) -> ms.Tensor:
         """Forward pass through classifier head.
 
         Args:
@@ -416,7 +425,7 @@         x = self.head_drop(x)
         return x if pre_logits else self.classifier(x)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -430,7 +439,7 @@         return x
 
 
-def _filter_torchvision_pretrained(state_dict: dict) -> Dict[str, torch.Tensor]:
+def _filter_torchvision_pretrained(state_dict: dict) -> Dict[str, ms.Tensor]:
     """Filter torchvision pretrained state dict for compatibility.
 
     Args:
