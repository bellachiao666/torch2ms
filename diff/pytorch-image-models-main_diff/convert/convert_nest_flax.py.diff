--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """
 Convert weights from https://github.com/google-research/nested-transformer
 NOTE: You'll need https://github.com/google/CommonLoopUtils, not included in requirements.txt
@@ -6,7 +11,7 @@ import sys
 
 import numpy as np
-import torch
+# import torch
 
 from clu import checkpoint
 
@@ -33,14 +38,14 @@     state_dict = {}
 
     # Patch embedding
-    state_dict['patch_embed.proj.weight'] = torch.tensor(
+    state_dict['patch_embed.proj.weight'] = ms.Tensor(
         flax_dict['PatchEmbedding_0']['Conv_0']['kernel']).permute(3, 2, 0, 1)
-    state_dict['patch_embed.proj.bias'] = torch.tensor(flax_dict['PatchEmbedding_0']['Conv_0']['bias'])
+    state_dict['patch_embed.proj.bias'] = ms.Tensor(flax_dict['PatchEmbedding_0']['Conv_0']['bias'])
     
     # Positional embeddings
     posemb_keys = [k for k in flax_dict.keys() if k.startswith('PositionEmbedding')]
     for i, k in enumerate(posemb_keys):
-        state_dict[f'levels.{i}.pos_embed'] = torch.tensor(flax_dict[k]['pos_embedding'])
+        state_dict[f'levels.{i}.pos_embed'] = ms.Tensor(flax_dict[k]['pos_embedding'])
     
     # Transformer encoders
     depths = arch_depths[arch]
@@ -49,9 +54,9 @@             global_layer_ix = sum(depths[:level]) + layer
             # Norms
             for i in range(2):
-                state_dict[f'levels.{level}.transformer_encoder.{layer}.norm{i+1}.weight'] = torch.tensor(
+                state_dict[f'levels.{level}.transformer_encoder.{layer}.norm{i+1}.weight'] = ms.Tensor(
                     flax_dict[f'EncoderNDBlock_{global_layer_ix}'][f'LayerNorm_{i}']['scale'])
-                state_dict[f'levels.{level}.transformer_encoder.{layer}.norm{i+1}.bias'] = torch.tensor(
+                state_dict[f'levels.{level}.transformer_encoder.{layer}.norm{i+1}.bias'] = ms.Tensor(
                     flax_dict[f'EncoderNDBlock_{global_layer_ix}'][f'LayerNorm_{i}']['bias'])
             # Attention qkv
             w_q = flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MultiHeadAttention_0']['DenseGeneral_0']['kernel']
@@ -59,46 +64,46 @@             # Pay attention to dims here (maybe get pen and paper)
             w_kv = np.concatenate(np.split(w_kv, 2, -1), 1)
             w_qkv = np.concatenate([w_q, w_kv], 1)
-            state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.qkv.weight'] = torch.tensor(w_qkv).flatten(1).permute(1,0)
+            state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.qkv.weight'] = ms.Tensor(w_qkv).flatten(1).permute(1,0)
             b_q = flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MultiHeadAttention_0']['DenseGeneral_0']['bias']
             b_kv = flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MultiHeadAttention_0']['DenseGeneral_1']['bias']
             # Pay attention to dims here (maybe get pen and paper)
             b_kv = np.concatenate(np.split(b_kv, 2, -1), 0)
             b_qkv = np.concatenate([b_q, b_kv], 0)
-            state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.qkv.bias'] = torch.tensor(b_qkv).reshape(-1)
+            state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.qkv.bias'] = ms.Tensor(b_qkv).reshape(-1)
             # Attention proj
             w_proj = flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MultiHeadAttention_0']['proj_kernel']
-            w_proj = torch.tensor(w_proj).permute(2, 1, 0).flatten(1)
+            w_proj = ms.Tensor(w_proj).permute(2, 1, 0).flatten(1)
             state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.proj.weight'] = w_proj
-            state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.proj.bias'] = torch.tensor(
+            state_dict[f'levels.{level}.transformer_encoder.{layer}.attn.proj.bias'] = ms.Tensor(
                 flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MultiHeadAttention_0']['bias'])
             # MLP
             for i in range(2):
-                state_dict[f'levels.{level}.transformer_encoder.{layer}.mlp.fc{i+1}.weight'] = torch.tensor(
+                state_dict[f'levels.{level}.transformer_encoder.{layer}.mlp.fc{i+1}.weight'] = ms.Tensor(
                     flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MlpBlock_0'][f'Dense_{i}']['kernel']).permute(1, 0)
-                state_dict[f'levels.{level}.transformer_encoder.{layer}.mlp.fc{i+1}.bias'] = torch.tensor(
+                state_dict[f'levels.{level}.transformer_encoder.{layer}.mlp.fc{i+1}.bias'] = ms.Tensor(
                     flax_dict[f'EncoderNDBlock_{global_layer_ix}']['MlpBlock_0'][f'Dense_{i}']['bias'])
 
     # Block aggregations (ConvPool)
     for level in range(1, len(depths)):
         # Convs
-        state_dict[f'levels.{level}.pool.conv.weight'] = torch.tensor(
+        state_dict[f'levels.{level}.pool.conv.weight'] = ms.Tensor(
             flax_dict[f'ConvPool_{level-1}']['Conv_0']['kernel']).permute(3, 2, 0, 1)
-        state_dict[f'levels.{level}.pool.conv.bias'] = torch.tensor(
+        state_dict[f'levels.{level}.pool.conv.bias'] = ms.Tensor(
             flax_dict[f'ConvPool_{level-1}']['Conv_0']['bias'])
         # Norms
-        state_dict[f'levels.{level}.pool.norm.weight'] = torch.tensor(
+        state_dict[f'levels.{level}.pool.norm.weight'] = ms.Tensor(
                     flax_dict[f'ConvPool_{level-1}']['LayerNorm_0']['scale'])
-        state_dict[f'levels.{level}.pool.norm.bias'] = torch.tensor(
+        state_dict[f'levels.{level}.pool.norm.bias'] = ms.Tensor(
                     flax_dict[f'ConvPool_{level-1}']['LayerNorm_0']['bias'])
 
     # Final norm
-    state_dict[f'norm.weight'] = torch.tensor(flax_dict['LayerNorm_0']['scale'])
-    state_dict[f'norm.bias'] = torch.tensor(flax_dict['LayerNorm_0']['bias'])
+    state_dict[f'norm.weight'] = ms.Tensor(flax_dict['LayerNorm_0']['scale'])
+    state_dict[f'norm.bias'] = ms.Tensor(flax_dict['LayerNorm_0']['bias'])
 
     # Classifier
-    state_dict['head.weight'] = torch.tensor(flax_dict['Dense_0']['kernel']).permute(1, 0)
-    state_dict['head.bias'] = torch.tensor(flax_dict['Dense_0']['bias'])
+    state_dict['head.weight'] = ms.Tensor(flax_dict['Dense_0']['kernel']).permute(1, 0)
+    state_dict['head.bias'] = ms.Tensor(flax_dict['Dense_0']['bias'])
 
     return state_dict
 
@@ -106,4 +111,4 @@ if __name__ == '__main__':
     variant = sys.argv[1] # base, small, or tiny
     state_dict = convert_nest(f'./nest-{variant[0]}_imagenet', f'nest_{variant}')
-    torch.save(state_dict, f'./jx_nest_{variant}.pth')+    torch.save(state_dict, f'./jx_nest_{variant}.pth')  # 'torch.save' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;