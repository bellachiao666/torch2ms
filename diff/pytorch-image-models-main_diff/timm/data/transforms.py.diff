--- pytorch+++ mindspore@@ -1,14 +1,17 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import math
 import numbers
 import random
 import warnings
 from typing import List, Sequence, Tuple, Union
-
-import torch
-import torchvision.transforms as transforms
-import torchvision.transforms.functional as F
+# import torchvision.transforms as transforms
+# import torchvision.transforms.functional as F
 try:
-    from torchvision.transforms.functional import InterpolationMode
+    # from torchvision.transforms.functional import InterpolationMode
     has_interpolation_mode = True
 except ImportError:
     has_interpolation_mode = False
@@ -34,13 +37,14 @@ 
 class ToTensor:
     """ ToTensor with no rescaling of values"""
-    def __init__(self, dtype=torch.float32):
+    def __init__(self, dtype=ms.float32):
         self.dtype = dtype
 
     def __call__(self, pil_img):
-        return F.pil_to_tensor(pil_img).to(dtype=self.dtype)
-
-
+        return F.pil_to_tensor(pil_img).to(dtype=self.dtype)  # 'torchvision.transforms.functional.pil_to_tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.functional.pil_to_tensor.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+
+# 'torchvision.transforms.ToTensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 class MaybeToTensor(transforms.ToTensor):
     """Convert a PIL Image or ndarray to tensor if it's not already one.
     """
@@ -48,7 +52,7 @@     def __init__(self) -> None:
         super().__init__()
 
-    def __call__(self, pic) -> torch.Tensor:
+    def __call__(self, pic) -> ms.Tensor:
         """
         Args:
             pic (PIL Image or numpy.ndarray): Image to be converted to tensor.
@@ -56,9 +60,9 @@         Returns:
             Tensor: Converted image.
         """
-        if isinstance(pic, torch.Tensor):
+        if isinstance(pic, ms.Tensor):
             return pic
-        return F.to_tensor(pic)
+        return F.to_tensor(pic)  # 'torchvision.transforms.functional.to_tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def __repr__(self) -> str:
         return f"{self.__class__.__name__}()"
@@ -81,9 +85,9 @@         Returns:
             Tensor: Converted image.
         """
-        if isinstance(pic, torch.Tensor):
+        if isinstance(pic, ms.Tensor):
             return pic
-        return F.pil_to_tensor(pic)
+        return F.pil_to_tensor(pic)  # 'torchvision.transforms.functional.pil_to_tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def __repr__(self) -> str:
         return f"{self.__class__.__name__}()"
@@ -212,13 +216,13 @@             tuple: params (i, j, h, w) to be passed to ``crop`` for a random
                 sized crop.
         """
-        img_w, img_h = F.get_image_size(img)
+        img_w, img_h = F.get_image_size(img)  # 'torchvision.transforms.functional.get_image_size' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         area = img_w * img_h
 
         for attempt in range(10):
-            target_area = random.uniform(*scale) * area
+            target_area = random.uniform(*scale) * area  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             log_ratio = (math.log(ratio[0]), math.log(ratio[1]))
-            aspect_ratio = math.exp(random.uniform(*log_ratio))
+            aspect_ratio = math.exp(random.uniform(*log_ratio))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
             target_w = int(round(math.sqrt(target_area * aspect_ratio)))
             target_h = int(round(math.sqrt(target_area / aspect_ratio)))
@@ -255,7 +259,7 @@             interpolation = random.choice(self.interpolation)
         else:
             interpolation = self.interpolation
-        return F.resized_crop(img, i, j, h, w, self.size, interpolation)
+        return F.resized_crop(img, i, j, h, w, self.size, interpolation)  # 'torchvision.transforms.functional.resized_crop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def __repr__(self):
         if isinstance(self.interpolation, (tuple, list)):
@@ -270,11 +274,11 @@ 
 
 def center_crop_or_pad(
-        img: torch.Tensor,
+        img: ms.Tensor,
         output_size: Union[int, List[int]],
         fill: Union[int, Tuple[int, int, int]] = 0,
         padding_mode: str = 'constant',
-) -> torch.Tensor:
+) -> ms.Tensor:
     """Center crops and/or pads the given image.
 
     If the image is torch Tensor, it is expected
@@ -292,7 +296,7 @@     """
     output_size = _setup_size(output_size)
     crop_height, crop_width = output_size
-    _, image_height, image_width = F.get_dimensions(img)
+    _, image_height, image_width = F.get_dimensions(img)  # 'torchvision.transforms.functional.get_dimensions' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if crop_width > image_width or crop_height > image_height:
         padding_ltrb = [
@@ -301,17 +305,17 @@             (crop_width - image_width + 1) // 2 if crop_width > image_width else 0,
             (crop_height - image_height + 1) // 2 if crop_height > image_height else 0,
         ]
-        img = F.pad(img, padding_ltrb, fill=fill, padding_mode=padding_mode)
-        _, image_height, image_width = F.get_dimensions(img)
+        img = nn.functional.pad(img, padding_ltrb)  # 'torch.nn.functional.pad':存在 MindSpore 未支持的参数 fill, padding_mode，需手动确认;
+        _, image_height, image_width = F.get_dimensions(img)  # 'torchvision.transforms.functional.get_dimensions' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if crop_width == image_width and crop_height == image_height:
             return img
 
     crop_top = int(round((image_height - crop_height) / 2.0))
     crop_left = int(round((image_width - crop_width) / 2.0))
-    return F.crop(img, crop_top, crop_left, crop_height, crop_width)
-
-
-class CenterCropOrPad(torch.nn.Module):
+    return F.crop(img, crop_top, crop_left, crop_height, crop_width)  # 'torchvision.transforms.functional.crop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+
+class CenterCropOrPad(msnn.Cell):
     """Crops the given image at the center.
     If the image is torch Tensor, it is expected
     to have [..., H, W] shape, where ... means an arbitrary number of leading dimensions.
@@ -334,7 +338,7 @@         self.fill = fill
         self.padding_mode = padding_mode
 
-    def forward(self, img):
+    def construct(self, img):
         """
         Args:
             img (PIL Image or Tensor): Image to be cropped.
@@ -349,17 +353,17 @@ 
 
 def crop_or_pad(
-        img: torch.Tensor,
+        img: ms.Tensor,
         top: int,
         left: int,
         height: int,
         width: int,
         fill: Union[int, Tuple[int, int, int]] = 0,
         padding_mode: str = 'constant',
-) -> torch.Tensor:
+) -> ms.Tensor:
     """ Crops and/or pads image to meet target size, with control over fill and padding_mode.
     """
-    _, image_height, image_width = F.get_dimensions(img)
+    _, image_height, image_width = F.get_dimensions(img)  # 'torchvision.transforms.functional.get_dimensions' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     right = left + width
     bottom = top + height
     if left < 0 or top < 0 or right > image_width or bottom > image_height:
@@ -369,14 +373,14 @@             max(right - max(image_width, left), 0),
             max(bottom - max(image_height, top), 0),
         ]
-        img = F.pad(img, padding_ltrb, fill=fill, padding_mode=padding_mode)
+        img = nn.functional.pad(img, padding_ltrb)  # 'torch.nn.functional.pad':存在 MindSpore 未支持的参数 fill, padding_mode，需手动确认;
 
     top = max(top, 0)
     left = max(left, 0)
-    return F.crop(img, top, left, height, width)
-
-
-class RandomCropOrPad(torch.nn.Module):
+    return F.crop(img, top, left, height, width)  # 'torchvision.transforms.functional.crop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+
+class RandomCropOrPad(msnn.Cell):
     """ Crop and/or pad image with random placement within the crop or pad margin.
     """
 
@@ -393,14 +397,14 @@ 
     @staticmethod
     def get_params(img, size):
-        _, image_height, image_width = F.get_dimensions(img)
+        _, image_height, image_width = F.get_dimensions(img)  # 'torchvision.transforms.functional.get_dimensions' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         delta_height = image_height - size[0]
         delta_width = image_width - size[1]
         top = int(math.copysign(random.randint(0, abs(delta_height)), delta_height))
         left = int(math.copysign(random.randint(0, abs(delta_width)), delta_width))
         return top, left
 
-    def forward(self, img):
+    def construct(self, img):
         """
         Args:
             img (PIL Image or Tensor): Image to be cropped.
@@ -430,7 +434,7 @@ 
     @staticmethod
     def get_params(img, input_size):
-        width, height = F.get_image_size(img)
+        width, height = F.get_image_size(img)  # 'torchvision.transforms.functional.get_image_size' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         delta_width = max(input_size[1] - width, 0)
         delta_height = max(input_size[0] - height, 0)
         pad_left = random.randint(0, delta_width)
@@ -441,7 +445,7 @@ 
     def __call__(self, img):
         padding = self.get_params(img, self.input_size)
-        img = F.pad(img, padding, self.fill)
+        img = nn.functional.pad(img, padding, self.fill)
         return img
 
 
@@ -500,7 +504,7 @@     ):
         """Get parameters
         """
-        img_h, img_w = img_size = F.get_dimensions(img)[1:]
+        img_h, img_w = img_size = F.get_dimensions(img)[1:]  # 'torchvision.transforms.functional.get_dimensions' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         target_h, target_w = target_size
         ratio_h = img_h / target_h
         ratio_w = img_w / target_w
@@ -518,7 +522,7 @@ 
         if random_aspect_prob > 0 and random.random() < random_aspect_prob:
             log_aspect = (math.log(random_aspect_range[0]), math.log(random_aspect_range[1]))
-            aspect_factor = math.exp(random.uniform(*log_aspect))
+            aspect_factor = math.exp(random.uniform(*log_aspect))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             aspect_factor = math.sqrt(aspect_factor)
             # currently applying random aspect adjustment equally to both dims,
             # could change to keep output sizes above their target where possible
@@ -544,7 +548,7 @@             interpolation = random.choice(self.interpolation)
         else:
             interpolation = self.interpolation
-        img = F.resize(img, size, interpolation)
+        img = F.resize(img, size, interpolation)  # 'torchvision.transforms.functional.resize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         return img
 
     def __repr__(self):
@@ -564,7 +568,7 @@         return format_string
 
 
-class TrimBorder(torch.nn.Module):
+class TrimBorder(msnn.Cell):
 
     def __init__(
             self,
@@ -573,11 +577,11 @@         super().__init__()
         self.border_size = border_size
 
-    def forward(self, img):
-        w, h = F.get_image_size(img)
+    def construct(self, img):
+        w, h = F.get_image_size(img)  # 'torchvision.transforms.functional.get_image_size' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         top = left = self.border_size
         top = min(top, h)
         left = min(left, h)
         height = max(0, h - 2 * self.border_size)
         width = max(0, w - 2 * self.border_size)
-        return F.crop(img, top, left, height, width)
+        return F.crop(img, top, left, height, width)  # 'torchvision.transforms.functional.crop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
