--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Image to Patch Embedding using Conv2d
 
 A convolution based approach to patchifying a 2D image w/ embedding projection.
@@ -12,9 +17,8 @@ import math
 from typing import Callable, Dict, List, Optional, Tuple, Union
 
-import torch
-from torch import nn as nn
-import torch.nn.functional as F
+# import torch
+# from torch import nn as nn
 
 from .format import Format, nchw_to
 from .helpers import to_2tuple
@@ -23,11 +27,11 @@ _logger = logging.getLogger(__name__)
 
 
-class PatchEmbed(nn.Module):
+class PatchEmbed(msnn.Cell):
     """ 2D Image to Patch Embedding
     """
     output_fmt: Format
-    dynamic_img_pad: torch.jit.Final[bool]
+    dynamic_img_pad: torch.jit.Final[bool]  # 'torch.jit.Final' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def __init__(
             self,
@@ -59,8 +63,8 @@         self.strict_img_size = strict_img_size
         self.dynamic_img_pad = dynamic_img_pad
 
-        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias, **dd)
-        self.norm = norm_layer(embed_dim, **dd) if norm_layer else nn.Identity()
+        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.norm = norm_layer(embed_dim, **dd) if norm_layer else msnn.Identity()  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     def _init_img_size(self, img_size: Union[int, Tuple[int, int]]):
         assert self.patch_size
@@ -80,16 +84,10 @@         if patch_size is not None:
             new_patch_size = to_2tuple(patch_size)
         if new_patch_size is not None and new_patch_size != self.patch_size:
+            # 'torch.no_grad' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             with torch.no_grad():
                 new_proj = nn.Conv2d(
-                    self.proj.in_channels,
-                    self.proj.out_channels,
-                    kernel_size=new_patch_size,
-                    stride=new_patch_size,
-                    bias=self.proj.bias is not None,
-                    device=self.proj.weight.device,
-                    dtype=self.proj.weight.dtype,
-                )
+                    self.proj.in_channels, self.proj.out_channels, kernel_size = new_patch_size, stride = new_patch_size, bias = self.proj.bias is not None, dtype = self.proj.weight.dtype)  # 'torch.nn.Conv2d':没有对应的mindspore参数 'device' (position 9);
                 new_proj.weight.copy_(resample_patch_embed(self.proj.weight, new_patch_size, verbose=True))
                 if self.proj.bias is not None:
                     new_proj.bias.copy_(self.proj.bias)
@@ -114,7 +112,7 @@         else:
             return img_size[0] // self.patch_size[0], img_size[1] // self.patch_size[1]
 
-    def forward(self, x):
+    def construct(self, x):
         B, C, H, W = x.shape
         if self.img_size is not None:
             if self.strict_img_size:
@@ -132,7 +130,7 @@         if self.dynamic_img_pad:
             pad_h = (self.patch_size[0] - H % self.patch_size[0]) % self.patch_size[0]
             pad_w = (self.patch_size[1] - W % self.patch_size[1]) % self.patch_size[1]
-            x = F.pad(x, (0, pad_w, 0, pad_h))
+            x = nn.functional.pad(x, (0, pad_w, 0, pad_h))
         x = self.proj(x)
         if self.flatten:
             x = x.flatten(2).transpose(1, 2)  # NCHW -> NLC
@@ -173,7 +171,7 @@             dtype=dtype,
         )
 
-    def forward(self, x) -> Tuple[torch.Tensor, List[int]]:
+    def forward(self, x) -> Tuple[ms.Tensor, List[int]]:
         B, C, H, W = x.shape
         if self.img_size is not None:
             _assert(H % self.patch_size[0] == 0, f"Input image height ({H}) must be divisible by patch size ({self.patch_size[0]}).")
@@ -218,9 +216,9 @@     """
     import numpy as np
     try:
-        from torch import vmap
+        # from torch import vmap
     except ImportError:
-        from functorch import vmap
+        # from functorch import vmap
 
     assert len(patch_embed.shape) == 4, "Four dimensions expected"
     assert len(new_size) == 2, "New shape should only be hw"
@@ -232,9 +230,9 @@         _logger.info(f"Resize patch embedding {patch_embed.shape} to {new_size}, w/ {interpolation} interpolation.")
 
     def resize(x_np, _new_size):
-        x_tf = torch.Tensor(x_np)[None, None, ...]
-        x_upsampled = F.interpolate(
-            x_tf, size=_new_size, mode=interpolation, antialias=antialias)[0, 0, ...].numpy()
+        x_tf = ms.Tensor(x_np)[None, None, ...]
+        x_upsampled = nn.functional.interpolate(
+            x_tf, size = _new_size, mode = interpolation)[0, 0, ...].numpy()  # 'torch.nn.functional.interpolate':没有对应的mindspore参数 'antialias' (position 6);; 'torch.nn.functional.interpolate.numpy' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         return x_upsampled
 
     def get_resize_mat(_old_size, _new_size):
@@ -246,13 +244,13 @@         return np.stack(mat).T
 
     resize_mat = get_resize_mat(old_size, new_size)
-    resize_mat_pinv = torch.tensor(np.linalg.pinv(resize_mat.T), device=patch_embed.device)
+    resize_mat_pinv = ms.Tensor(np.linalg.pinv(resize_mat.T), device=patch_embed.device)
 
     def resample_kernel(kernel):
         resampled_kernel = resize_mat_pinv @ kernel.reshape(-1)
         return resampled_kernel.reshape(new_size)
 
-    v_resample_kernel = vmap(vmap(resample_kernel, 0, 0), 1, 1)
+    v_resample_kernel = vmap(vmap(resample_kernel, 0, 0), 1, 1)  # 'torch.vmap' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     orig_dtype = patch_embed.dtype
     patch_embed = patch_embed.float()
     patch_embed = v_resample_kernel(patch_embed)
@@ -260,9 +258,11 @@     return patch_embed
 
 
-DTYPE_INTERMEDIATE = torch.float32
-
-
+DTYPE_INTERMEDIATE = ms.float32
+
+
+# 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+# 'torch.dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def _compute_resize_matrix(
         old_size: Tuple[int, int],
         new_size: Tuple[int, int],
@@ -270,33 +270,29 @@         antialias: bool,
         device: torch.device,
         dtype: torch.dtype = DTYPE_INTERMEDIATE
-) -> torch.Tensor:
+) -> ms.Tensor:
     """Computes the resize matrix basis vectors and interpolates them to new_size."""
     old_h, old_w = old_size
     new_h, new_w = new_size
     old_total = old_h * old_w
     new_total = new_h * new_w
 
-    eye_matrix = torch.eye(old_total, device=device, dtype=dtype)
+    eye_matrix = mint.eye(old_total, device=device, dtype=dtype)
     basis_vectors_batch = eye_matrix.reshape(old_total, 1, old_h, old_w)
-    resized_basis_vectors_batch = F.interpolate(
-        basis_vectors_batch,
-        size=new_size,
-        mode=interpolation,
-        antialias=antialias,
-        align_corners=False
-    ) # Output shape: (old_total, 1, new_h, new_w)
+    resized_basis_vectors_batch = nn.functional.interpolate(
+        basis_vectors_batch, size = new_size, mode = interpolation, align_corners = False)  # Output shape: (old_total, 1, new_h, new_w); 'torch.nn.functional.interpolate':没有对应的mindspore参数 'antialias' (position 6);
     resize_matrix = resized_basis_vectors_batch.squeeze(1).permute(1, 2, 0).reshape(new_total, old_total)
     return resize_matrix # Shape: (new_total, old_total)
 
 
+# 'torch.dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def _apply_resampling(
-        patch_embed: torch.Tensor,
-        pinv_matrix: torch.Tensor,
+        patch_embed: ms.Tensor,
+        pinv_matrix: ms.Tensor,
         new_size_tuple: Tuple[int, int],
         orig_dtype: torch.dtype,
         intermediate_dtype: torch.dtype = DTYPE_INTERMEDIATE
-) -> torch.Tensor:
+) -> ms.Tensor:
     """ Simplified resampling w/o vmap use.
     As proposed by https://github.com/stas-sl
     """
@@ -304,12 +300,12 @@     patch_embed = patch_embed.reshape(c_out, c_in, -1).to(dtype=intermediate_dtype)
     pinv_matrix = pinv_matrix.to(dtype=intermediate_dtype)
     resampled_patch_embed = patch_embed @ pinv_matrix  # (C_out, C_in, P_old * P_old) @ (P_old * P_old, P_new * P_new)
-    resampled_patch_embed = resampled_patch_embed.reshape(c_out, c_in, *new_size_tuple).to(dtype=orig_dtype)
+    resampled_patch_embed = resampled_patch_embed.reshape(c_out, c_in, *new_size_tuple).to(dtype=orig_dtype)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return resampled_patch_embed
 
 
 def resample_patch_embed(
-        patch_embed: torch.Tensor,
+        patch_embed: ms.Tensor,
         new_size: List[int],
         interpolation: str = 'bicubic',
         antialias: bool = True,
@@ -331,14 +327,14 @@     resize_mat = _compute_resize_matrix(
         old_size_tuple, new_size_tuple, interpolation, antialias, device, DTYPE_INTERMEDIATE
     )
-    pinv_matrix = torch.linalg.pinv(resize_mat)  # Calculates the pseudoinverse matrix used for resampling
+    pinv_matrix = torch.linalg.pinv(resize_mat)  # Calculates the pseudoinverse matrix used for resampling; 'torch.linalg.pinv' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     resampled_patch_embed = _apply_resampling(
         patch_embed, pinv_matrix, new_size_tuple, orig_dtype, DTYPE_INTERMEDIATE
     )
     return resampled_patch_embed
 
 
-class PatchEmbedResamplerFixedOrigSize(nn.Module):
+class PatchEmbedResamplerFixedOrigSize(msnn.Cell):
     """
     Resample patch embedding weights from a fixed original size,
     caching the pseudoinverse matrix based on the target size.
@@ -364,12 +360,14 @@         # Cache map key is the target new_size tuple
         self._pinv_cache_map: Dict[Tuple[int, int], str] = {}
 
+    # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    # 'torch.dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     def _get_or_create_pinv_matrix(
             self,
             new_size: Tuple[int, int],
             device: torch.device,
             dtype: torch.dtype = DTYPE_INTERMEDIATE
-    ) -> torch.Tensor:
+    ) -> ms.Tensor:
         """Retrieves the cached pinv matrix or computes and caches it for the given new_size."""
         cache_key = new_size
         buffer_name = self._pinv_cache_map.get(cache_key)
@@ -383,7 +381,7 @@         resize_mat = _compute_resize_matrix(
             self.orig_size, new_size, self.interpolation, self.antialias, device, dtype
         )
-        pinv_matrix = torch.linalg.pinv(resize_mat)  # Calculates the pseudoinverse matrix used for resampling
+        pinv_matrix = torch.linalg.pinv(resize_mat)  # Calculates the pseudoinverse matrix used for resampling; 'torch.linalg.pinv' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         # Cache using register_buffer
         buffer_name = f"pinv_{new_size[0]}x{new_size[1]}"
@@ -394,7 +392,7 @@ 
         return pinv_matrix
 
-    def forward(self, patch_embed: torch.Tensor, new_size: List[int]) -> torch.Tensor:
+    def construct(self, patch_embed: ms.Tensor, new_size: List[int]) -> ms.Tensor:
         """ Resamples the patch embedding weights to new_size.
 
         Args:
@@ -431,7 +429,7 @@         return resampled_patch_embed
 
 
-class PatchEmbedInterpolator(nn.Module):
+class PatchEmbedInterpolator(msnn.Cell):
     """Dynamically interpolates patch embedding weights for variable patch sizes.
 
     This module wraps patch embedding weight resampling functionality to support
@@ -463,9 +461,9 @@ 
     def resample_linear_weight(
             self,
-            weight: torch.Tensor,
+            weight: ms.Tensor,
             target_patch_size: Tuple[int, int],
-    ) -> torch.Tensor:
+    ) -> ms.Tensor:
         """Resample linear patch embedding weights for a new patch size.
 
         Args:
@@ -505,9 +503,9 @@ 
     def resample_conv_weight(
             self,
-            weight: torch.Tensor,
+            weight: ms.Tensor,
             target_patch_size: Tuple[int, int],
-    ) -> torch.Tensor:
+    ) -> ms.Tensor:
         """Resample conv2d patch embedding weights for a new patch size.
 
         Args:
@@ -531,14 +529,14 @@ 
         return weight_resampled
 
-    def forward(
-            self,
-            patches: torch.Tensor,
-            proj_weight: torch.Tensor,
-            proj_bias: Optional[torch.Tensor] = None,
+    def construct(
+            self,
+            patches: ms.Tensor,
+            proj_weight: ms.Tensor,
+            proj_bias: Optional[ms.Tensor] = None,
             patch_size: Optional[Tuple[int, int]] = None,
             is_linear: bool = True,
-    ) -> torch.Tensor:
+    ) -> ms.Tensor:
         """Apply patch embedding with dynamic weight resampling.
 
         Args:
@@ -568,26 +566,22 @@ 
                 # Flatten patches and apply linear projection
                 patches_flat = patches.reshape(B, N, -1)
-                output = torch.nn.functional.linear(patches_flat, weight_resampled, proj_bias)
+                output = nn.functional.linear(patches_flat, weight_resampled, proj_bias)
             else:
                 # No resampling needed, patches can be pre-flattened
                 if patches.ndim == 5:
                     B, N, Ph, Pw, C = patches.shape
                     patches = patches.reshape(B, N, -1)
-                output = torch.nn.functional.linear(patches, proj_weight, proj_bias)
+                output = nn.functional.linear(patches, proj_weight, proj_bias)
         else:
             # Conv mode
             if patch_size != self.base_patch_size:
                 weight_resampled = self.resample_conv_weight(proj_weight, patch_size)
-                output = torch.nn.functional.conv2d(
-                    patches, weight_resampled, proj_bias,
-                    stride=patch_size, padding=0
-                )
+                output = nn.functional.conv2d(
+                    patches, weight_resampled, proj_bias, stride = patch_size, padding = 0)
             else:
-                output = torch.nn.functional.conv2d(
-                    patches, proj_weight, proj_bias,
-                    stride=patch_size, padding=0
-                )
+                output = nn.functional.conv2d(
+                    patches, proj_weight, proj_bias, stride = patch_size, padding = 0)
 
         return output
 
