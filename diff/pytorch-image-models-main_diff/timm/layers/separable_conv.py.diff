--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Depthwise Separable Conv Modules
 
 Basic DWS convs. Other variations of DWS exist with batch norm or activations between the
@@ -7,13 +12,13 @@ """
 from typing import Optional, Type, Union
 
-from torch import nn as nn
+# from torch import nn as nn
 
 from .create_conv2d import create_conv2d
 from .create_norm_act import get_norm_act_layer
 
 
-class SeparableConvNormAct(nn.Module):
+class SeparableConvNormAct(msnn.Cell):
     """ Separable Conv w/ trailing Norm and Activation
     """
     def __init__(
@@ -27,10 +32,10 @@             bias: bool = False,
             channel_multiplier: float = 1.0,
             pw_kernel_size: int = 1,
-            norm_layer: Type[nn.Module] = nn.BatchNorm2d,
-            act_layer: Type[nn.Module] = nn.ReLU,
+            norm_layer: Type[msnn.Cell] = nn.BatchNorm2d,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
             apply_act: bool = True,
-            drop_layer: Optional[Type[nn.Module]] = None,
+            drop_layer: Optional[Type[msnn.Cell]] = None,
             device=None,
             dtype=None,
     ):
@@ -46,7 +51,7 @@             padding=padding,
             depthwise=True,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.conv_pw = create_conv2d(
             int(in_channels * channel_multiplier),
@@ -55,11 +60,11 @@             padding=padding,
             bias=bias,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         norm_act_layer = get_norm_act_layer(norm_layer, act_layer)
         norm_kwargs = dict(drop_layer=drop_layer) if drop_layer is not None else {}
-        self.bn = norm_act_layer(out_channels, apply_act=apply_act, **norm_kwargs, **dd)
+        self.bn = norm_act_layer(out_channels, apply_act=apply_act, **norm_kwargs, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     @property
     def in_channels(self):
@@ -69,7 +74,7 @@     def out_channels(self):
         return self.conv_pw.out_channels
 
-    def forward(self, x):
+    def construct(self, x):
         x = self.conv_dw(x)
         x = self.conv_pw(x)
         x = self.bn(x)
@@ -79,7 +84,7 @@ SeparableConvBnAct = SeparableConvNormAct
 
 
-class SeparableConv2d(nn.Module):
+class SeparableConv2d(msnn.Cell):
     """ Separable Conv
     """
     def __init__(
@@ -108,7 +113,7 @@             padding=padding,
             depthwise=True,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.conv_pw = create_conv2d(
             int(in_channels * channel_multiplier),
@@ -117,7 +122,7 @@             padding=padding,
             bias=bias,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     @property
     def in_channels(self):
@@ -127,7 +132,7 @@     def out_channels(self):
         return self.conv_pw.out_channels
 
-    def forward(self, x):
+    def construct(self, x):
         x = self.conv_dw(x)
         x = self.conv_pw(x)
         return x
