--- pytorch+++ mindspore@@ -1,11 +1,15 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Test Time Pooling (Average-Max Pool)
 
 Hacked together by / Copyright 2020 Ross Wightman
 """
 
 import logging
-from torch import nn
-import torch.nn.functional as F
+# from torch import nn
 
 from .adaptive_avgmax_pool import adaptive_avgmax_pool2d
 
@@ -13,7 +17,7 @@ _logger = logging.getLogger(__name__)
 
 
-class TestTimePoolHead(nn.Module):
+class TestTimePoolHead(msnn.Cell):
     def __init__(self, base, original_pool=7):
         super().__init__()
         self.base = base
@@ -23,14 +27,14 @@             self.fc = base_fc
         else:
             self.fc = nn.Conv2d(
-                self.base.num_features, self.base.num_classes, kernel_size=1, bias=True)
+                self.base.num_features, self.base.num_classes, kernel_size = 1, bias = True)
             self.fc.weight.data.copy_(base_fc.weight.data.view(self.fc.weight.size()))
             self.fc.bias.data.copy_(base_fc.bias.data.view(self.fc.bias.size()))
         self.base.reset_classifier(0)  # delete original fc layer
 
-    def forward(self, x):
+    def construct(self, x):
         x = self.base.forward_features(x)
-        x = F.avg_pool2d(x, kernel_size=self.original_pool, stride=1)
+        x = nn.functional.avg_pool2d(x, kernel_size = self.original_pool, stride = 1)
         x = self.fc(x)
         x = adaptive_avgmax_pool2d(x, 1)
         return x.view(x.size(0), -1)
