--- pytorch+++ mindspore@@ -1,12 +1,15 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import dataclasses
 import logging
 import os
 from copy import deepcopy
 from pathlib import Path
 from typing import Any, Callable, Dict, List, Optional, Tuple, Type, TypeVar, Union
-
-from torch import nn as nn
-from torch.hub import load_state_dict_from_url
+# from torch.hub import load_state_dict_from_url
 
 from timm.models._features import FeatureListNet, FeatureDictNet, FeatureHookNet, FeatureGetterNet
 from timm.models._features_fx import FeatureGraphNet
@@ -37,7 +40,7 @@ ]
 
 
-ModelT = TypeVar("ModelT", bound=nn.Module)              # any subclass of nn.Module
+ModelT = TypeVar("ModelT", bound=msnn.Cell)              # any subclass of nn.Module
 
 
 def _resolve_pretrained_source(pretrained_cfg: Dict[str, Any]) -> Tuple[str, str]:
@@ -101,7 +104,7 @@ 
 
 def load_custom_pretrained(
-        model: nn.Module,
+        model: msnn.Cell,
         pretrained_cfg: Optional[Dict[str, Any]] = None,
         load_fn: Optional[Callable] = None,
         cache_dir: Optional[Union[str, Path]] = None,
@@ -150,7 +153,7 @@ 
 
 def load_pretrained(
-        model: nn.Module,
+        model: msnn.Cell,
         pretrained_cfg: Optional[Dict[str, Any]] = None,
         num_classes: int = 1000,
         in_chans: int = 3,
@@ -204,7 +207,7 @@                     check_hash=_CHECK_HASH,
                     weights_only=True,
                     model_dir=cache_dir,
-                )
+                )  # 'torch.hub.load_state_dict_from_url' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             except TypeError:
                 state_dict = load_state_dict_from_url(
                     pretrained_loc,
@@ -212,16 +215,16 @@                     progress=_DOWNLOAD_PROGRESS,
                     check_hash=_CHECK_HASH,
                     model_dir=cache_dir,
-                )
+                )  # 'torch.hub.load_state_dict_from_url' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif load_from == 'hf-hub':
         _logger.info(f'Loading pretrained weights from Hugging Face hub ({pretrained_loc})')
         if isinstance(pretrained_loc, (list, tuple)):
             custom_load = pretrained_cfg.get('custom_load', False)
             if isinstance(custom_load, str) and custom_load == 'hf':
-                load_custom_from_hf(*pretrained_loc, model, cache_dir=cache_dir)
+                load_custom_from_hf(*pretrained_loc, model, cache_dir=cache_dir)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
                 return
             else:
-                state_dict = load_state_dict_from_hf(*pretrained_loc, cache_dir=cache_dir)
+                state_dict = load_state_dict_from_hf(*pretrained_loc, cache_dir=cache_dir)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         else:
             state_dict = load_state_dict_from_hf(pretrained_loc, weights_only=True, cache_dir=cache_dir)
     elif load_from == 'local-dir':
@@ -356,7 +359,7 @@     if pretrained_cfg:
         if isinstance(pretrained_cfg, dict):
             # pretrained_cfg dict passed as arg, validate by converting to PretrainedCfg
-            pretrained_cfg = PretrainedCfg(**pretrained_cfg)
+            pretrained_cfg = PretrainedCfg(**pretrained_cfg)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         elif isinstance(pretrained_cfg, str):
             pretrained_tag = pretrained_cfg
             pretrained_cfg = None
@@ -376,7 +379,7 @@     pretrained_cfg_overlay = pretrained_cfg_overlay or {}
     if not pretrained_cfg.architecture:
         pretrained_cfg_overlay.setdefault('architecture', variant)
-    pretrained_cfg = dataclasses.replace(pretrained_cfg, **pretrained_cfg_overlay)
+    pretrained_cfg = dataclasses.replace(pretrained_cfg, **pretrained_cfg_overlay)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     return pretrained_cfg
 
@@ -442,9 +445,9 @@ 
     # Instantiate the model
     if model_cfg is None:
-        model = model_cls(**kwargs)
+        model = model_cls(**kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     else:
-        model = model_cls(cfg=model_cfg, **kwargs)
+        model = model_cls(cfg=model_cfg, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     model.pretrained_cfg = pretrained_cfg
     model.default_cfg = model.pretrained_cfg  # alias for backwards compat
 
@@ -496,7 +499,7 @@         if output_fmt is not None and not use_getter:  # don't set default for intermediate feat getter
             feature_cfg.setdefault('output_fmt', output_fmt)
 
-        model = feature_cls(model, **feature_cfg)
+        model = feature_cls(model, **feature_cfg)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         model.pretrained_cfg = pretrained_cfg_for_features(pretrained_cfg)  # add back pretrained cfg
         model.default_cfg = model.pretrained_cfg  # alias for rename backwards compat (default_cfg -> pretrained_cfg)
 
