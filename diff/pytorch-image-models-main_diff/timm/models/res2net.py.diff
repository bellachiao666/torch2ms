--- pytorch+++ mindspore@@ -1,12 +1,15 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Res2Net and Res2NeXt
 Adapted from Official Pytorch impl at: https://github.com/gasvn/Res2Net/
 Paper: `Res2Net: A New Multi-scale Backbone Architecture` - https://arxiv.org/abs/1904.01169
 """
 import math
 from typing import Optional, Type
-
-import torch
-import torch.nn as nn
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from ._builder import build_model_with_cfg
@@ -16,7 +19,7 @@ __all__ = []
 
 
-class Bottle2neck(nn.Module):
+class Bottle2neck(msnn.Cell):
     """ Res2Net/Res2NeXT Bottleneck
     Adapted from https://github.com/gasvn/Res2Net/blob/master/res2net.py
     """
@@ -27,15 +30,15 @@             inplanes: int,
             planes: int,
             stride: int = 1,
-            downsample: Optional[nn.Module] = None,
+            downsample: Optional[msnn.Cell] = None,
             cardinality: int = 1,
             base_width: int = 26,
             scale: int = 4,
             dilation: int = 1,
             first_dilation: Optional[int] = None,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            norm_layer: Optional[Type[nn.Module]] = None,
-            attn_layer: Optional[Type[nn.Module]] = None,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            norm_layer: Optional[Type[msnn.Cell]] = None,
+            attn_layer: Optional[Type[msnn.Cell]] = None,
             device=None,
             dtype=None,
             **_,
@@ -50,8 +53,8 @@         outplanes = planes * self.expansion
         first_dilation = first_dilation or dilation
 
-        self.conv1 = nn.Conv2d(inplanes, width * scale, kernel_size=1, bias=False, **dd)
-        self.bn1 = norm_layer(width * scale, **dd)
+        self.conv1 = nn.Conv2d(inplanes, width * scale, kernel_size=1, bias=False, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn1 = norm_layer(width * scale, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         convs = []
         bns = []
@@ -66,35 +69,35 @@                 groups=cardinality,
                 bias=False,
                 **dd,
-            ))
-            bns.append(norm_layer(width, **dd))
-        self.convs = nn.ModuleList(convs)
-        self.bns = nn.ModuleList(bns)
+            ))  # 存在 *args/**kwargs，需手动确认参数映射;
+            bns.append(norm_layer(width, **dd))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.convs = msnn.CellList(convs)
+        self.bns = msnn.CellList(bns)
         if self.is_first:
             # FIXME this should probably have count_include_pad=False, but hurts original weights
-            self.pool = nn.AvgPool2d(kernel_size=3, stride=stride, padding=1)
+            self.pool = nn.AvgPool2d(kernel_size = 3, stride = stride, padding = 1)
         else:
             self.pool = None
 
-        self.conv3 = nn.Conv2d(width * scale, outplanes, kernel_size=1, bias=False, **dd)
-        self.bn3 = norm_layer(outplanes, **dd)
-        self.se = attn_layer(outplanes, **dd) if attn_layer is not None else None
+        self.conv3 = nn.Conv2d(width * scale, outplanes, kernel_size=1, bias=False, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn3 = norm_layer(outplanes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.se = attn_layer(outplanes, **dd) if attn_layer is not None else None  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.relu = act_layer(inplace=True)
         self.downsample = downsample
 
     def zero_init_last(self):
         if getattr(self.bn3, 'weight', None) is not None:
-            nn.init.zeros_(self.bn3.weight)
-
-    def forward(self, x):
+            nn.init.zeros_(self.bn3.weight)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         shortcut = x
 
         out = self.conv1(x)
         out = self.bn1(out)
         out = self.relu(out)
 
-        spx = torch.split(out, self.width, 1)
+        spx = mint.split(out, self.width, 1)
         spo = []
         sp = spx[0]  # redundant, for torchscript
         for i, (conv, bn) in enumerate(zip(self.convs, self.bns)):
@@ -111,7 +114,7 @@                 spo.append(self.pool(spx[-1]))
             else:
                 spo.append(spx[-1])
-        out = torch.cat(spo, 1)
+        out = mint.cat(spo, 1)
 
         out = self.conv3(out)
         out = self.bn3(out)
@@ -129,7 +132,7 @@ 
 
 def _create_res2net(variant, pretrained=False, **kwargs):
-    return build_model_with_cfg(ResNet, variant, pretrained, **kwargs)
+    return build_model_with_cfg(ResNet, variant, pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _cfg(url='', **kwargs):
@@ -163,7 +166,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, block_args=dict(scale=4))
-    return _create_res2net('res2net50_26w_4s', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net50_26w_4s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -172,7 +175,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 23, 3], base_width=26, block_args=dict(scale=4))
-    return _create_res2net('res2net101_26w_4s', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net101_26w_4s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -181,7 +184,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, block_args=dict(scale=6))
-    return _create_res2net('res2net50_26w_6s', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net50_26w_6s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -190,7 +193,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, block_args=dict(scale=8))
-    return _create_res2net('res2net50_26w_8s', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net50_26w_8s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -199,7 +202,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=48, block_args=dict(scale=2))
-    return _create_res2net('res2net50_48w_2s', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net50_48w_2s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -208,7 +211,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=14, block_args=dict(scale=8))
-    return _create_res2net('res2net50_14w_8s', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net50_14w_8s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -217,7 +220,7 @@     """
     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=4, cardinality=8, block_args=dict(scale=4))
-    return _create_res2net('res2next50', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2next50', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -227,7 +230,7 @@     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 6, 3], base_width=26, stem_type='deep',
         avg_down=True, stem_width=32, block_args=dict(scale=4))
-    return _create_res2net('res2net50d', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net50d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -237,4 +240,4 @@     model_args = dict(
         block=Bottle2neck, layers=[3, 4, 23, 3], base_width=26, stem_type='deep',
         avg_down=True, stem_width=32, block_args=dict(scale=4))
-    return _create_res2net('res2net101d', pretrained, **dict(model_args, **kwargs))
+    return _create_res2net('res2net101d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
