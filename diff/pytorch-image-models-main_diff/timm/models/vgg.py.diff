--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """VGG
 
 Adapted from https://github.com/pytorch/vision 'vgg.py' (BSD-3-Clause) with a few changes for
@@ -6,10 +11,7 @@ Copyright 2021 Ross Wightman
 """
 from typing import Any, Dict, List, Optional, Type, Union, cast
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import ClassifierHead
@@ -29,7 +31,7 @@ 
 
 @register_notrace_module  # reason: FX can't symbolically trace control flow in forward method
-class ConvMlp(nn.Module):
+class ConvMlp(msnn.Cell):
     """Convolutional MLP block for VGG head.
 
     Replaces traditional Linear layers with Conv2d layers in the classifier.
@@ -42,8 +44,8 @@             kernel_size: int = 7,
             mlp_ratio: float = 1.0,
             drop_rate: float = 0.2,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            conv_layer: Type[nn.Module] = nn.Conv2d,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            conv_layer: Type[msnn.Cell] = nn.Conv2d,
             device=None,
             dtype=None,
     ) -> None:
@@ -62,13 +64,13 @@         super().__init__()
         self.input_kernel_size = kernel_size
         mid_features = int(out_features * mlp_ratio)
-        self.fc1 = conv_layer(in_features, mid_features, kernel_size, bias=True, **dd)
+        self.fc1 = conv_layer(in_features, mid_features, kernel_size, bias=True, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.act1 = act_layer(True)
         self.drop = nn.Dropout(drop_rate)
-        self.fc2 = conv_layer(mid_features, out_features, 1, bias=True, **dd)
+        self.fc2 = conv_layer(mid_features, out_features, 1, bias=True, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.act2 = act_layer(True)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -80,7 +82,7 @@         if x.shape[-2] < self.input_kernel_size or x.shape[-1] < self.input_kernel_size:
             # keep the input size >= 7x7
             output_size = (max(self.input_kernel_size, x.shape[-2]), max(self.input_kernel_size, x.shape[-1]))
-            x = F.adaptive_avg_pool2d(x, output_size)
+            x = nn.functional.adaptive_avg_pool2d(x, output_size)
         x = self.fc1(x)
         x = self.act1(x)
         x = self.drop(x)
@@ -89,7 +91,7 @@         return x
 
 
-class VGG(nn.Module):
+class VGG(msnn.Cell):
     """VGG model architecture.
 
     Based on `Very Deep Convolutional Networks for Large-Scale Image Recognition`
@@ -103,9 +105,9 @@             in_chans: int = 3,
             output_stride: int = 32,
             mlp_ratio: float = 1.0,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            conv_layer: Type[nn.Module] = nn.Conv2d,
-            norm_layer: Optional[Type[nn.Module]] = None,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            conv_layer: Type[msnn.Cell] = nn.Conv2d,
+            norm_layer: Optional[Type[msnn.Cell]] = None,
             global_pool: str = 'avg',
             drop_rate: float = 0.,
             device=None,
@@ -137,22 +139,22 @@         prev_chs = in_chans
         net_stride = 1
         pool_layer = nn.MaxPool2d
-        layers: List[nn.Module] = []
+        layers: List[msnn.Cell] = []
         for v in cfg:
             last_idx = len(layers) - 1
             if v == 'M':
                 self.feature_info.append(dict(num_chs=prev_chs, reduction=net_stride, module=f'features.{last_idx}'))
-                layers += [pool_layer(kernel_size=2, stride=2)]
+                layers += [nn.MaxPool2d(kernel_size = 2, stride = 2)]
                 net_stride *= 2
             else:
                 v = cast(int, v)
-                conv2d = conv_layer(prev_chs, v, kernel_size=3, padding=1, **dd)
+                conv2d = conv_layer(prev_chs, v, kernel_size=3, padding=1, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
                 if norm_layer is not None:
-                    layers += [conv2d, norm_layer(v, **dd), act_layer(inplace=True)]
+                    layers += [conv2d, norm_layer(v, **dd), act_layer(inplace=True)]  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
                 else:
                     layers += [conv2d, act_layer(inplace=True)]
                 prev_chs = v
-        self.features = nn.Sequential(*layers)
+        self.features = msnn.SequentialCell(*layers)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.feature_info.append(dict(num_chs=prev_chs, reduction=net_stride, module=f'features.{len(layers) - 1}'))
 
         self.num_features = prev_chs
@@ -166,18 +168,18 @@             act_layer=act_layer,
             conv_layer=conv_layer,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.head = ClassifierHead(
             self.head_hidden_size,
             num_classes,
             pool_type=global_pool,
             drop_rate=drop_rate,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self._initialize_weights()
 
-    @torch.jit.ignore
+    @ms.jit
     def group_matcher(self, coarse: bool = False) -> Dict[str, Any]:
         """Group matcher for parameter groups.
 
@@ -190,7 +192,7 @@         # this treats BN layers as separate groups for bn variants, a lot of effort to fix that
         return dict(stem=r'^features\.0', blocks=r'^features\.(\d+)')
 
-    @torch.jit.ignore
+    @ms.jit
     def set_grad_checkpointing(self, enable: bool = True) -> None:
         """Enable or disable gradient checkpointing.
 
@@ -199,8 +201,8 @@         """
         assert not enable, 'gradient checkpointing not supported'
 
-    @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    @ms.jit
+    def get_classifier(self) -> msnn.Cell:
         """Get the classifier module.
 
         Returns:
@@ -218,7 +220,7 @@         self.num_classes = num_classes
         self.head.reset(num_classes, global_pool)
 
-    def forward_features(self, x: torch.Tensor) -> torch.Tensor:
+    def forward_features(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through feature extraction layers.
 
         Args:
@@ -230,7 +232,7 @@         x = self.features(x)
         return x
 
-    def forward_head(self, x: torch.Tensor, pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, x: ms.Tensor, pre_logits: bool = False) -> ms.Tensor:
         """Forward pass through head.
 
         Args:
@@ -243,7 +245,7 @@         x = self.pre_logits(x)
         return self.head(x, pre_logits=pre_logits) if pre_logits else self.head(x)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -260,18 +262,18 @@         """Initialize model weights."""
         for m in self.modules():
             if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')  # 'torch.nn.init.kaiming_normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                 if m.bias is not None:
-                    nn.init.constant_(m.bias, 0)
+                    nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.BatchNorm2d):
-                nn.init.constant_(m.weight, 1)
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.weight, 1)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.Linear):
-                nn.init.normal_(m.weight, 0, 0.01)
-                nn.init.constant_(m.bias, 0)
-
-
-def _filter_fn(state_dict: dict) -> Dict[str, torch.Tensor]:
+                nn.init.normal_(m.weight, 0, 0.01)  # 'torch.nn.init.normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+
+def _filter_fn(state_dict: dict) -> Dict[str, ms.Tensor]:
     """Convert patch embedding weight from manual patchify + linear proj to conv.
 
     Args:
@@ -316,7 +318,7 @@         feature_cfg=dict(flatten_sequential=True, out_indices=out_indices),
         pretrained_filter_fn=_filter_fn,
         **kwargs,
-    )
+    )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -358,8 +360,8 @@     r"""VGG 11-layer model (configuration "A") from
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(**kwargs)
-    return _create_vgg('vgg11', pretrained=pretrained, **model_args)
+    model_args = dict(**kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg11', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -367,8 +369,8 @@     r"""VGG 11-layer model (configuration "A") with batch normalization
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)
-    return _create_vgg('vgg11_bn', pretrained=pretrained, **model_args)
+    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg11_bn', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -376,8 +378,8 @@     r"""VGG 13-layer model (configuration "B")
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(**kwargs)
-    return _create_vgg('vgg13', pretrained=pretrained, **model_args)
+    model_args = dict(**kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg13', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -385,8 +387,8 @@     r"""VGG 13-layer model (configuration "B") with batch normalization
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)
-    return _create_vgg('vgg13_bn', pretrained=pretrained, **model_args)
+    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg13_bn', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -394,8 +396,8 @@     r"""VGG 16-layer model (configuration "D")
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(**kwargs)
-    return _create_vgg('vgg16', pretrained=pretrained, **model_args)
+    model_args = dict(**kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg16', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -403,8 +405,8 @@     r"""VGG 16-layer model (configuration "D") with batch normalization
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)
-    return _create_vgg('vgg16_bn', pretrained=pretrained, **model_args)
+    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg16_bn', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -412,8 +414,8 @@     r"""VGG 19-layer model (configuration "E")
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(**kwargs)
-    return _create_vgg('vgg19', pretrained=pretrained, **model_args)
+    model_args = dict(**kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg19', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -421,5 +423,5 @@     r"""VGG 19-layer model (configuration 'E') with batch normalization
     `"Very Deep Convolutional Networks For Large-Scale Image Recognition" <https://arxiv.org/pdf/1409.1556.pdf>`._
     """
-    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)
-    return _create_vgg('vgg19_bn', pretrained=pretrained, **model_args)
+    model_args = dict(norm_layer=nn.BatchNorm2d, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return _create_vgg('vgg19_bn', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
