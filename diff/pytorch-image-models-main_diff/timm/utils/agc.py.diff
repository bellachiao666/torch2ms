--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Adaptive Gradient Clipping
 
 An impl of AGC, as per (https://arxiv.org/abs/2102.06171):
@@ -15,7 +20,7 @@ 
 Hacked together by / Copyright 2021 Ross Wightman
 """
-import torch
+# import torch
 
 
 def unitwise_norm(x, norm_type=2.0):
@@ -38,5 +43,5 @@         max_norm = unitwise_norm(p_data, norm_type=norm_type).clamp_(min=eps).mul_(clip_factor)
         grad_norm = unitwise_norm(g_data, norm_type=norm_type)
         clipped_grad = g_data * (max_norm / grad_norm.clamp(min=1e-6))
-        new_grads = torch.where(grad_norm < max_norm, g_data, clipped_grad)
+        new_grads = mint.where(grad_norm < max_norm, g_data, clipped_grad)
         p.grad.detach().copy_(new_grads)
