--- pytorch+++ mindspore@@ -1,4 +1,9 @@ #!/usr/bin/env python3
+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ ImageNet Validation Script
 
 This is intended to be a lean and easily modifiable ImageNet validation script for evaluating pretrained
@@ -18,9 +23,8 @@ from contextlib import suppress
 from functools import partial
 
-import torch
-import torch.nn as nn
-import torch.nn.parallel
+# import torch
+# import torch.nn as nn
 
 from timm.data import create_dataset, create_loader, resolve_data_config, RealLabelsImagenet
 from timm.layers import apply_test_time_pool, set_fast_norm
@@ -30,7 +34,7 @@ 
 
 try:
-    from functorch.compile import memory_efficient_fusion
+    # from functorch.compile import memory_efficient_fusion
     has_functorch = True
 except ImportError as e:
     has_functorch = False
@@ -178,7 +182,7 @@         torch.backends.cuda.matmul.allow_tf32 = True
         torch.backends.cudnn.benchmark = True
 
-    device = torch.device(args.device)
+    device = torch.device(args.device)  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if args.metrics_avg and not has_sklearn:
         _logger.warning(
@@ -193,13 +197,13 @@     # resolve AMP arguments based on PyTorch availability
     amp_autocast = suppress
     if args.amp:
-        assert model_dtype is None or model_dtype == torch.float32, 'float32 model dtype must be used with AMP'
+        assert model_dtype is None or model_dtype == ms.float32, 'float32 model dtype must be used with AMP'
         assert args.amp_dtype in ('float16', 'bfloat16')
-        amp_dtype = torch.bfloat16 if args.amp_dtype == 'bfloat16' else torch.float16
+        amp_dtype = ms.bfloat16 if args.amp_dtype == 'bfloat16' else ms.float16
         amp_autocast = partial(torch.autocast, device_type=device.type, dtype=amp_dtype)
         _logger.info('Validating in mixed precision with native PyTorch AMP.')
     else:
-        _logger.info(f'Validating in {model_dtype or torch.float32}. AMP not enabled.')
+        _logger.info(f'Validating in {model_dtype or ms.float32}. AMP not enabled.')
 
     if args.fuser:
         set_jit_fuser(args.fuser)
@@ -251,19 +255,19 @@         model = model.to(memory_format=torch.channels_last)
 
     if args.torchscript:
-        model = torch.jit.script(model)
+        model = torch.jit.script(model)  # 'torch.jit.script' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif args.torchcompile:
         assert has_compile, 'A version of torch w/ torch.compile() is required for --compile, possibly a nightly.'
-        torch._dynamo.reset()
-        model = torch.compile(model, backend=args.torchcompile, mode=args.torchcompile_mode)
+        torch._dynamo.reset()  # 'torch._dynamo.reset' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        model = torch.compile(model, backend=args.torchcompile, mode=args.torchcompile_mode)  # 'torch.compile' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif args.aot_autograd:
         assert has_functorch, "functorch is needed for --aot-autograd"
         model = memory_efficient_fusion(model)
 
     if args.num_gpu > 1:
-        model = torch.nn.DataParallel(model, device_ids=list(range(args.num_gpu)))
-
-    criterion = nn.CrossEntropyLoss().to(device)
+        model = torch.nn.DataParallel(model, device_ids=list(range(args.num_gpu)))  # 'torch.nn.DataParallel' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    criterion = nn.CrossEntropyLoss().to(device)  # 'torch.nn.CrossEntropyLoss.to' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     root_dir = args.data or args.data_dir
     if args.input_img_mode is None:
@@ -315,7 +319,7 @@             crop_border_pixels=args.crop_border_pixels,
             pin_memory=args.pin_mem,
             device=device,
-            img_dtype=model_dtype or torch.float32,
+            img_dtype=model_dtype or ms.float32,
             patch_size=model_patch_size or (16, 16),
             max_seq_len=args.naflex_max_seq_len,
         )
@@ -334,7 +338,7 @@             crop_border_pixels=args.crop_border_pixels,
             pin_memory=args.pin_mem,
             device=device,
-            img_dtype=model_dtype or torch.float32,
+            img_dtype=model_dtype or ms.float32,
             tf_preprocessing=args.tf_preprocessing,
         )
 
@@ -351,7 +355,7 @@     with torch.inference_mode():
         # warmup, reduce variability of first batch time, especially for comparing torchscript vs non
         if not args.naflex_loader:
-            input = torch.randn((args.batch_size,) + tuple(data_config['input_size'])).to(device=device, dtype=model_dtype)
+            input = mint.randn((args.batch_size,) + tuple(data_config['input_size'])).to(device=device, dtype=model_dtype)
             if args.channels_last:
                 input = input.contiguous(memory_format=torch.channels_last)
             with amp_autocast():
@@ -384,7 +388,7 @@             top5.update(acc5.item(), batch_size)
 
             if args.metrics_avg:
-                predictions = torch.argmax(output, dim=1)
+                predictions = mint.argmax(output)
                 all_preds.append(predictions.cpu())
                 all_targets.append(target.cpu())
 
@@ -417,8 +421,8 @@ 
     metric_results = {}
     if args.metrics_avg:
-        all_preds = torch.cat(all_preds).numpy()
-        all_targets = torch.cat(all_targets).numpy()
+        all_preds = mint.cat(all_preds).numpy()
+        all_targets = mint.cat(all_targets).numpy()
         precision = precision_score(all_targets, all_preds, average=args.metrics_avg, zero_division=0)
         recall = recall_score(all_targets, all_preds, average=args.metrics_avg, zero_division=0)
         f1 = f1_score(all_targets, all_preds, average=args.metrics_avg, zero_division=0)
@@ -461,9 +465,9 @@         args.batch_size = batch_size * args.num_gpu  # multiply by num-gpu for DataParallel case
         try:
             if 'cuda' in args.device and torch.cuda.is_available():
-                torch.cuda.empty_cache()
+                torch.cuda.empty_cache()  # 'torch.cuda.empty_cache' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif "npu" in args.device and torch.npu.is_available():
-                torch.npu.empty_cache()
+                torch.npu.empty_cache()  # 'torch.npu.empty_cache' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             results = validate(args)
             return results
         except RuntimeError as e:
