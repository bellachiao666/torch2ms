--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """NaFlex data loader for dynamic sequence length training.
 
 This module provides a specialized data loader for Vision Transformer models that supports:
@@ -15,7 +20,7 @@ from typing import Callable, Dict, Iterator, List, Optional, Tuple, Union
 
 
-import torch
+# import torch
 
 from .constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from .loader import _worker_init, adapt_to_chs
@@ -27,6 +32,9 @@ class NaFlexPrefetchLoader:
     """Data prefetcher for NaFlex format which normalizes patches."""
 
+    # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    # 'torch.dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     def __init__(
             self,
             loader: torch.utils.data.DataLoader,
@@ -56,16 +64,16 @@         """
         self.loader = loader
         self.device = device
-        self.img_dtype = img_dtype or torch.float32
+        self.img_dtype = img_dtype or ms.float32
 
         # Create mean/std tensors for normalization (will be applied to patches)
         mean = adapt_to_chs(mean, channels)
         std = adapt_to_chs(std, channels)
         normalization_shape = (1, 1, channels)
         self.channels = channels
-        self.mean = torch.tensor(
+        self.mean = ms.Tensor(
             [x * 255 for x in mean], device=device, dtype=self.img_dtype).view(normalization_shape)
-        self.std = torch.tensor(
+        self.std = ms.Tensor(
             [x * 255 for x in std], device=device, dtype=self.img_dtype).view(normalization_shape)
 
         if re_prob > 0.:
@@ -80,10 +88,10 @@             self.random_erasing = None
 
         # Check for CUDA/NPU availability
-        self.is_cuda = device.type == 'cuda' and torch.cuda.is_available()
-        self.is_npu = device.type == 'npu' and torch.npu.is_available()
-
-    def __iter__(self) -> Iterator[Tuple[Dict[str, torch.Tensor], torch.Tensor]]:
+        self.is_cuda = device.type == 'cuda' and torch.cuda.is_available()  # 'torch.cuda.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.is_npu = device.type == 'npu' and torch.npu.is_available()  # 'torch.npu.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def __iter__(self) -> Iterator[Tuple[Dict[str, ms.Tensor], ms.Tensor]]:
         """Iterate through the loader with prefetching and normalization.
 
         Yields:
@@ -91,10 +99,10 @@         """
         first = True
         if self.is_cuda:
-            stream = torch.cuda.Stream(device=self.device)
+            stream = torch.cuda.Stream(device=self.device)  # 'torch.cuda.Stream' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             stream_context = partial(torch.cuda.stream, stream=stream)
         elif self.is_npu:
-            stream = torch.npu.Stream(device=self.device)
+            stream = torch.npu.Stream(device=self.device)  # 'torch.npu.Stream' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             stream_context = partial(torch.npu.stream, stream=stream)
         else:
             stream = None
@@ -104,7 +112,7 @@             with stream_context():
                 # Move all tensors in input_dict to device
                 for k, v in next_input_dict.items():
-                    if isinstance(v, torch.Tensor):
+                    if isinstance(v, ms.Tensor):
                         dtype = self.img_dtype if k == 'patches' else None
                         next_input_dict[k] = next_input_dict[k].to(
                             device=self.device,
@@ -152,9 +160,9 @@ 
             if stream is not None:
                 if self.is_cuda:
-                    torch.cuda.current_stream(device=self.device).wait_stream(stream)
+                    torch.cuda.current_stream(device=self.device).wait_stream(stream)  # 'torch.cuda.current_stream' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.cuda.current_stream.wait_stream' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                 elif self.is_npu:
-                    torch.npu.current_stream(device=self.device).wait_stream(stream)
+                    torch.npu.current_stream(device=self.device).wait_stream(stream)  # 'torch.npu.current_stream' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.npu.current_stream.wait_stream' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
             input_dict = next_input_dict
             target = next_target
@@ -188,6 +196,9 @@         return self.loader.dataset
 
 
+# 'torch.dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+# 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+# 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def create_naflex_loader(
         dataset,
         patch_size: Optional[Union[Tuple[int, int], int]] = None,
@@ -231,7 +242,7 @@         epoch: int = 0,
         use_prefetcher: bool = True,
         pin_memory: bool = True,
-        img_dtype: torch.dtype = torch.float32,
+        img_dtype: torch.dtype = ms.float32,
         device: Union[str, torch.device] = torch.device('cuda'),
         persistent_workers: bool = True,
         worker_seeding: str = 'all',
@@ -352,7 +363,7 @@             pin_memory=pin_memory,
             worker_init_fn=partial(_worker_init, worker_seeding=worker_seeding),
             persistent_workers=persistent_workers
-        )
+        )  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if use_prefetcher:
             loader = NaFlexPrefetchLoader(
@@ -400,7 +411,7 @@             collate_fn=collate_fn,
             pin_memory=pin_memory,
             drop_last=False,
-        )
+        )  # 'torch.utils.data.DataLoader' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if use_prefetcher:
             loader = NaFlexPrefetchLoader(
