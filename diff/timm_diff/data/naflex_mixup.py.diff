--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """Variable‑size Mixup / CutMix utilities for NaFlex data loaders.
 
 This module provides:
@@ -17,17 +22,17 @@ import random
 from typing import Dict, List, Tuple, Union
 
-import torch
+# import torch
 
 
 def mix_batch_variable_size(
-        imgs: List[torch.Tensor],
+        imgs: List[ms.Tensor],
         *,
         mixup_alpha: float = 0.8,
         cutmix_alpha: float = 1.0,
         switch_prob: float = 0.5,
         local_shuffle: int = 4,
-) -> Tuple[List[torch.Tensor], List[float], Dict[int, int]]:
+) -> Tuple[List[ms.Tensor], List[float], Dict[int, int]]:
     """Apply Mixup or CutMix on a batch of variable-sized images.
 
     Sorts images by aspect ratio and pairs neighboring samples. Only the mutual
@@ -51,7 +56,7 @@ 
     # Decide augmentation mode and raw λ
     if mixup_alpha > 0.0 and cutmix_alpha > 0.0:
-        use_cutmix = torch.rand(()).item() < switch_prob
+        use_cutmix = mint.rand(()).item() < switch_prob
         alpha = cutmix_alpha if use_cutmix else mixup_alpha
     elif mixup_alpha > 0.0:
         use_cutmix = False
@@ -62,7 +67,7 @@     else:
         raise ValueError("Both mixup_alpha and cutmix_alpha are zero – nothing to do.")
 
-    lam_raw = torch.distributions.Beta(alpha, alpha).sample().item()
+    lam_raw = ms.Tensor.item()  # 'torch.distributions.Beta' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.distributions.Beta.sample' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     lam_raw = max(0.0, min(1.0, lam_raw))  # numerical safety
 
     # Pair images by nearest aspect ratio
@@ -78,7 +83,7 @@ 
     odd_one = order[-1] if len(imgs) % 2 else None
 
-    mixed_imgs: List[torch.Tensor] = [None] * len(imgs)
+    mixed_imgs: List[ms.Tensor] = [None] * len(imgs)
     lam_list: List[float] = [1.0] * len(imgs)
 
     for i in range(len(imgs)):
@@ -130,32 +135,28 @@ 
 
 def smoothed_sparse_target(
-        targets: torch.Tensor,
+        targets: ms.Tensor,
         *,
         num_classes: int,
         smoothing: float = 0.0,
-) -> torch.Tensor:
+) -> ms.Tensor:
     off_val = smoothing / num_classes
     on_val = 1.0 - smoothing + off_val
 
-    y_onehot = torch.full(
-        (targets.size(0), num_classes),
-        off_val,
-        dtype=torch.float32,
-        device=targets.device
-    )
+    y_onehot = mint.full(
+        size = ((targets.size(0), num_classes), off_val), dtype = ms.float32)  # 'torch.full':没有对应的mindspore参数 'device' (position 5);
     y_onehot.scatter_(1, targets.unsqueeze(1), on_val)
     return y_onehot
 
 
 def pairwise_mixup_target(
-        targets: torch.Tensor,
+        targets: ms.Tensor,
         pair_to: Dict[int, int],
         lam_list: List[float],
         *,
         num_classes: int,
         smoothing: float = 0.0,
-) -> torch.Tensor:
+) -> ms.Tensor:
     """Create soft targets that match the pixel‑level mixing performed.
 
     Args:
@@ -212,9 +213,9 @@ 
     def __call__(
             self,
-            imgs: List[torch.Tensor],
-            targets: torch.Tensor,
-    ) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:
+            imgs: List[ms.Tensor],
+            targets: ms.Tensor,
+    ) -> Tuple[List[ms.Tensor], List[ms.Tensor]]:
         """Apply the augmentation and generate matching targets.
 
         Args:
@@ -226,7 +227,7 @@             targets: Soft‑label tensor shaped (B, num_classes) suitable for cross‑entropy with soft targets.
         """
         if not isinstance(targets, torch.Tensor):
-            targets = torch.tensor(targets)
+            targets = ms.Tensor(targets)  # 'torch.tensor':默认参数名不一致(position 0): PyTorch=data, MindSpore=input_data;
 
         if random.random() > self.prob:
             targets = smoothed_sparse_target(targets, num_classes=self.num_classes, smoothing=self.smoothing)
