--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Random Erasing (Cutout)
 
 Originally inspired by impl at https://github.com/zhunzhong07/Random-Erasing, Apache 2.0
@@ -8,19 +13,17 @@ import random
 import math
 
-import torch
 
-
-def _get_pixels(per_pixel, rand_color, patch_size, dtype=torch.float32, device='cuda'):
+def _get_pixels(per_pixel, rand_color, patch_size, dtype=ms.float32, device='cuda'):
     # NOTE I've seen CUDA illegal memory access errors being caused by the normal_()
     # paths, flip the order so normal is run on CPU if this becomes a problem
     # Issue has been fixed in master https://github.com/pytorch/pytorch/issues/19508
     if per_pixel:
-        return torch.empty(patch_size, dtype=dtype, device=device).normal_()
+        return mint.empty(patch_size, dtype=dtype, device=device).normal_()
     elif rand_color:
-        return torch.empty((patch_size[0], 1, 1), dtype=dtype, device=device).normal_()
+        return mint.empty((patch_size[0], 1, 1), dtype=dtype, device=device).normal_()
     else:
-        return torch.zeros((patch_size[0], 1, 1), dtype=dtype, device=device)
+        return mint.zeros((patch_size[0], 1, 1), dtype=dtype, device=device)
 
 
 class RandomErasing:
