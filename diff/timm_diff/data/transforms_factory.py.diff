--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Transforms Factory
 Factory methods for building image transforms for use with TIMM (PyTorch Image Models)
 
@@ -5,9 +10,7 @@ """
 import math
 from typing import Optional, Tuple, Union
-
-import torch
-from torchvision import transforms
+# from torchvision import transforms
 
 from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, DEFAULT_CROP_PCT
 from timm.data.auto_augment import rand_augment_transform, augment_and_mix_transform, auto_augment_transform
@@ -42,8 +45,8 @@         # random interpolation not supported with no-aug
         interpolation = 'bilinear'
     tfl = [
-        transforms.Resize(img_size, interpolation=str_to_interp_mode(interpolation)),
-        transforms.CenterCrop(img_size)
+        ms.dataset.vision.Resize(img_size, interpolation = str_to_interp_mode(interpolation)),
+        ms.dataset.vision.CenterCrop(img_size)
     ]
     if use_prefetcher:
         # prefetcher and collate will handle tensor conversion and norm
@@ -55,11 +58,11 @@         tfl += [
             MaybeToTensor(),
             transforms.Normalize(
-                mean=torch.tensor(mean),
-                std=torch.tensor(std)
+                mean=ms.Tensor(mean),
+                std=ms.Tensor(std)
             )
-        ]
-    return transforms.Compose(tfl)
+        ]  # 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    return ms.dataset.transforms.Compose(tfl)
 
 
 def transforms_imagenet_train(
@@ -173,9 +176,9 @@             ]
 
     if hflip > 0.:
-        primary_tfl += [transforms.RandomHorizontalFlip(p=hflip)]
+        primary_tfl += [transforms.RandomHorizontalFlip(p=hflip)]  # 'torchvision.transforms.RandomHorizontalFlip' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     if vflip > 0.:
-        primary_tfl += [transforms.RandomVerticalFlip(p=vflip)]
+        primary_tfl += [transforms.RandomVerticalFlip(p=vflip)]  # 'torchvision.transforms.RandomVerticalFlip' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     secondary_tfl = []
     disable_color_jitter = False
@@ -214,25 +217,25 @@         if color_jitter_prob is not None:
             secondary_tfl += [
                 transforms.RandomApply([
-                        transforms.ColorJitter(*color_jitter),
+                        ms.dataset.vision.RandomColorAdjust(*color_jitter),
                     ],
                     p=color_jitter_prob
                 )
-            ]
-        else:
-            secondary_tfl += [transforms.ColorJitter(*color_jitter)]
+            ]  # 存在 *args/**kwargs，需手动确认参数映射;; 'torchvision.transforms.RandomApply' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        else:
+            secondary_tfl += [ms.dataset.vision.RandomColorAdjust(*color_jitter)]  # 存在 *args/**kwargs，需手动确认参数映射;
 
     if grayscale_prob:
-        secondary_tfl += [transforms.RandomGrayscale(p=grayscale_prob)]
+        secondary_tfl += [transforms.RandomGrayscale(p=grayscale_prob)]  # 'torchvision.transforms.RandomGrayscale' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if gaussian_blur_prob:
         secondary_tfl += [
             transforms.RandomApply([
-                    transforms.GaussianBlur(kernel_size=23),  # hardcoded for now
+                    ms.dataset.vision.GaussianBlur(kernel_size = 23),  # hardcoded for now
                 ],
                 p=gaussian_blur_prob,
             )
-        ]
+        ]  # 'torchvision.transforms.RandomApply' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     final_tfl = []
     if use_prefetcher:
@@ -245,10 +248,10 @@         final_tfl += [
             MaybeToTensor(),
             transforms.Normalize(
-                mean=torch.tensor(mean),
-                std=torch.tensor(std),
+                mean=ms.Tensor(mean),
+                std=ms.Tensor(std),
             ),
-        ]
+        ]  # 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if re_prob > 0.:
             final_tfl += [
                 RandomErasing(
@@ -264,9 +267,9 @@         final_tfl += [Patchify(patch_size=patch_size)]
 
     if separate:
-        return transforms.Compose(primary_tfl), transforms.Compose(secondary_tfl), transforms.Compose(final_tfl)
-    else:
-        return transforms.Compose(primary_tfl + secondary_tfl + final_tfl)
+        return ms.dataset.transforms.Compose(primary_tfl), ms.dataset.transforms.Compose(secondary_tfl), ms.dataset.transforms.Compose(final_tfl)
+    else:
+        return ms.dataset.transforms.Compose(primary_tfl + secondary_tfl + final_tfl)
 
 
 def transforms_imagenet_eval(
@@ -329,8 +332,8 @@             # squash mode scales each edge to 1/pct of target, then crops
             # aspect ratio is not preserved, no img lost if crop_pct == 1.0
             tfl += [
-                transforms.Resize(scale_size, interpolation=str_to_interp_mode(interpolation)),
-                transforms.CenterCrop(img_size),
+                ms.dataset.vision.Resize(scale_size, interpolation = str_to_interp_mode(interpolation)),
+                ms.dataset.vision.CenterCrop(img_size),
             ]
         elif crop_mode == 'border':
             # scale the longest edge of image to 1/pct of target edge, add borders to pad, then crop
@@ -346,12 +349,12 @@             if scale_size[0] == scale_size[1]:
                 # simple case, use torchvision built-in Resize w/ shortest edge mode (scalar size arg)
                 tfl += [
-                    transforms.Resize(scale_size[0], interpolation=str_to_interp_mode(interpolation))
+                    ms.dataset.vision.Resize(scale_size[0], interpolation = str_to_interp_mode(interpolation))
                 ]
             else:
                 # resize the shortest edge to matching target dim for non-square target
                 tfl += [ResizeKeepRatio(scale_size)]
-            tfl += [transforms.CenterCrop(img_size)]
+            tfl += [ms.dataset.vision.CenterCrop(img_size)]
 
     if use_prefetcher:
         # prefetcher and collate will handle tensor conversion and norm
@@ -363,15 +366,15 @@         tfl += [
             MaybeToTensor(),
             transforms.Normalize(
-                mean=torch.tensor(mean),
-                std=torch.tensor(std),
+                mean=ms.Tensor(mean),
+                std=ms.Tensor(std),
             ),
-        ]
+        ]  # 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if patchify:
         tfl += [Patchify(patch_size=patch_size)]
 
-    return transforms.Compose(tfl)
+    return ms.dataset.transforms.Compose(tfl)
 
 
 def create_transform(
