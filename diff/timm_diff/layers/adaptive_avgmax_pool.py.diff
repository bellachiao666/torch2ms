--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ PyTorch selectable adaptive pooling
 Adaptive pooling with the ability to select the type of pooling from:
     * 'avg' - Average pooling
@@ -10,10 +15,8 @@ Hacked together by / Copyright 2020 Ross Wightman
 """
 from typing import Optional, Tuple, Union
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch.nn as nn
+# import torch.nn.functional as F
 
 from .format import get_spatial_dim, get_channel_dim
 
@@ -28,66 +31,67 @@ 
 
 def adaptive_avgmax_pool2d(x, output_size: _int_tuple_2_t = 1):
-    x_avg = F.adaptive_avg_pool2d(x, output_size)
-    x_max = F.adaptive_max_pool2d(x, output_size)
+    x_avg = nn.functional.adaptive_avg_pool2d(x, output_size)
+    x_max = F.adaptive_max_pool2d(x, output_size)  # 'torch.nn.functional.adaptive_max_pool2d' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     return 0.5 * (x_avg + x_max)
 
 
 def adaptive_catavgmax_pool2d(x, output_size: _int_tuple_2_t = 1):
-    x_avg = F.adaptive_avg_pool2d(x, output_size)
-    x_max = F.adaptive_max_pool2d(x, output_size)
-    return torch.cat((x_avg, x_max), 1)
+    x_avg = nn.functional.adaptive_avg_pool2d(x, output_size)
+    x_max = F.adaptive_max_pool2d(x, output_size)  # 'torch.nn.functional.adaptive_max_pool2d' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    return mint.cat((x_avg, x_max), 1)
 
 
 def select_adaptive_pool2d(x, pool_type='avg', output_size: _int_tuple_2_t = 1):
     """Selectable global pooling function with dynamic input kernel size
     """
     if pool_type == 'avg':
-        x = F.adaptive_avg_pool2d(x, output_size)
+        x = nn.functional.adaptive_avg_pool2d(x, output_size)
     elif pool_type == 'avgmax':
         x = adaptive_avgmax_pool2d(x, output_size)
     elif pool_type == 'catavgmax':
         x = adaptive_catavgmax_pool2d(x, output_size)
     elif pool_type == 'max':
-        x = F.adaptive_max_pool2d(x, output_size)
+        x = F.adaptive_max_pool2d(x, output_size)  # 'torch.nn.functional.adaptive_max_pool2d' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         assert False, 'Invalid pool type: %s' % pool_type
     return x
 
 
-class FastAdaptiveAvgPool(nn.Module):
+class FastAdaptiveAvgPool(msnn.Cell):
+    # 'torch.nn.functional.F' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     def __init__(self, flatten: bool = False, input_fmt: F = 'NCHW'):
         super().__init__()
         self.flatten = flatten
         self.dim = get_spatial_dim(input_fmt)
 
-    def forward(self, x):
+    def construct(self, x):
         return x.mean(self.dim, keepdim=not self.flatten)
 
 
-class FastAdaptiveMaxPool(nn.Module):
+class FastAdaptiveMaxPool(msnn.Cell):
     def __init__(self, flatten: bool = False, input_fmt: str = 'NCHW'):
         super().__init__()
         self.flatten = flatten
         self.dim = get_spatial_dim(input_fmt)
 
-    def forward(self, x):
+    def construct(self, x):
         return x.amax(self.dim, keepdim=not self.flatten)
 
 
-class FastAdaptiveAvgMaxPool(nn.Module):
+class FastAdaptiveAvgMaxPool(msnn.Cell):
     def __init__(self, flatten: bool = False, input_fmt: str = 'NCHW'):
         super().__init__()
         self.flatten = flatten
         self.dim = get_spatial_dim(input_fmt)
 
-    def forward(self, x):
+    def construct(self, x):
         x_avg = x.mean(self.dim, keepdim=not self.flatten)
         x_max = x.amax(self.dim, keepdim=not self.flatten)
         return 0.5 * x_avg + 0.5 * x_max
 
 
-class FastAdaptiveCatAvgMaxPool(nn.Module):
+class FastAdaptiveCatAvgMaxPool(msnn.Cell):
     def __init__(self, flatten: bool = False, input_fmt: str = 'NCHW'):
         super().__init__()
         self.flatten = flatten
@@ -97,31 +101,31 @@         else:
             self.dim_cat = get_channel_dim(input_fmt)
 
-    def forward(self, x):
+    def construct(self, x):
         x_avg = x.mean(self.dim_reduce, keepdim=not self.flatten)
         x_max = x.amax(self.dim_reduce, keepdim=not self.flatten)
-        return torch.cat((x_avg, x_max), self.dim_cat)
+        return mint.cat((x_avg, x_max), self.dim_cat)
 
 
-class AdaptiveAvgMaxPool2d(nn.Module):
+class AdaptiveAvgMaxPool2d(msnn.Cell):
     def __init__(self, output_size: _int_tuple_2_t = 1):
         super().__init__()
         self.output_size = output_size
 
-    def forward(self, x):
+    def construct(self, x):
         return adaptive_avgmax_pool2d(x, self.output_size)
 
 
-class AdaptiveCatAvgMaxPool2d(nn.Module):
+class AdaptiveCatAvgMaxPool2d(msnn.Cell):
     def __init__(self, output_size: _int_tuple_2_t = 1):
         super().__init__()
         self.output_size = output_size
 
-    def forward(self, x):
+    def construct(self, x):
         return adaptive_catavgmax_pool2d(x, self.output_size)
 
 
-class SelectAdaptivePool2d(nn.Module):
+class SelectAdaptivePool2d(msnn.Cell):
     """Selectable global pooling layer with dynamic input kernel size
     """
     def __init__(
@@ -136,8 +140,8 @@         self.pool_type = pool_type or ''  # convert other falsy values to empty string for consistent TS typing
         pool_type = pool_type.lower()
         if not pool_type:
-            self.pool = nn.Identity()  # pass through
-            self.flatten = nn.Flatten(1) if flatten else nn.Identity()
+            self.pool = msnn.Identity()  # pass through
+            self.flatten = mint.flatten(1) if flatten else msnn.Identity()
         elif pool_type.startswith('fast') or input_fmt != 'NCHW':
             assert output_size == 1, 'Fast pooling and non NCHW input formats require output_size == 1.'
             if pool_type.endswith('catavgmax'):
@@ -150,7 +154,7 @@                 self.pool = FastAdaptiveAvgPool(flatten, input_fmt=input_fmt)
             else:
                 assert False, 'Invalid pool type: %s' % pool_type
-            self.flatten = nn.Identity()
+            self.flatten = msnn.Identity()
         else:
             assert input_fmt == 'NCHW'
             if pool_type == 'avgmax':
@@ -158,17 +162,17 @@             elif pool_type == 'catavgmax':
                 self.pool = AdaptiveCatAvgMaxPool2d(output_size)
             elif pool_type == 'max':
-                self.pool = nn.AdaptiveMaxPool2d(output_size)
+                self.pool = nn.AdaptiveMaxPool2d(output_size)  # 'torch.nn.AdaptiveMaxPool2d' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif pool_type == 'avg':
                 self.pool = nn.AdaptiveAvgPool2d(output_size)
             else:
                 assert False, 'Invalid pool type: %s' % pool_type
-            self.flatten = nn.Flatten(1) if flatten else nn.Identity()
+            self.flatten = mint.flatten(1) if flatten else msnn.Identity()
 
     def is_identity(self):
         return not self.pool_type
 
-    def forward(self, x):
+    def construct(self, x):
         x = self.pool(x)
         x = self.flatten(x)
         return x
