--- pytorch+++ mindspore@@ -1,8 +1,12 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Attention Factory
 
 Hacked together by / Copyright 2021 Ross Wightman
 """
-import torch
 from functools import partial
 
 from .bottleneck_attn import BottleneckAttn
@@ -20,7 +24,7 @@ 
 
 def get_attn(attn_type):
-    if isinstance(attn_type, torch.nn.Module):
+    if isinstance(attn_type, msnn.Cell):
         return attn_type
     module_cls = None
     if attn_type:
