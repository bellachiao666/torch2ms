--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ EvoNorm in PyTorch
 
 Based on `Evolving Normalization-Activation Layers` - https://arxiv.org/abs/2004.02967
@@ -24,10 +29,7 @@ Hacked together by / Copyright 2020 Ross Wightman
 """
 from typing import Optional, Sequence, Type, Union
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch.nn as nn
 
 from .create_act import create_act_layer
 from .trace_utils import _assert
@@ -96,7 +98,7 @@     return rms.expand(x.shape).reshape(B, C, H, W)
 
 
-class EvoNorm2dB0(nn.Module):
+class EvoNorm2dB0(msnn.Cell):
     def __init__(
             self,
             num_features: int,
@@ -112,20 +114,20 @@         self.apply_act = apply_act  # apply activation (non-linearity)
         self.momentum = momentum
         self.eps = eps
-        self.weight = nn.Parameter(torch.empty(num_features, **dd))
-        self.bias = nn.Parameter(torch.empty(num_features, **dd))
-        self.v = nn.Parameter(torch.empty(num_features, **dd)) if apply_act else None
-        self.register_buffer('running_var', torch.ones(num_features, **dd))
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        nn.init.ones_(self.weight)
-        nn.init.zeros_(self.bias)
+        self.weight = ms.Parameter(mint.empty(num_features, **dd))
+        self.bias = ms.Parameter(mint.empty(num_features, **dd))
+        self.v = ms.Parameter(mint.empty(num_features, **dd)) if apply_act else None
+        self.register_buffer('running_var', mint.ones(num_features, **dd))
+
+        self.reset_parameters()
+
+    def reset_parameters(self):
+        nn.init.ones_(self.weight)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        nn.init.zeros_(self.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if self.v is not None:
-            nn.init.ones_(self.v)
-
-    def forward(self, x):
+            nn.init.ones_(self.v)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         _assert(x.dim() == 4, 'expected 4D input')
         x_dtype = x.dtype
         v_shape = (1, -1, 1, 1)
@@ -146,7 +148,7 @@         return x * self.weight.to(x_dtype).view(v_shape) + self.bias.to(x_dtype).view(v_shape)
 
 
-class EvoNorm2dB1(nn.Module):
+class EvoNorm2dB1(msnn.Cell):
     def __init__(
             self,
             num_features: int,
@@ -162,17 +164,17 @@         self.apply_act = apply_act  # apply activation (non-linearity)
         self.momentum = momentum
         self.eps = eps
-        self.weight = nn.Parameter(torch.empty(num_features, **dd))
-        self.bias = nn.Parameter(torch.empty(num_features, **dd))
-        self.register_buffer('running_var', torch.ones(num_features, **dd))
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        nn.init.ones_(self.weight)
-        nn.init.zeros_(self.bias)
-
-    def forward(self, x):
+        self.weight = ms.Parameter(mint.empty(num_features, **dd))
+        self.bias = ms.Parameter(mint.empty(num_features, **dd))
+        self.register_buffer('running_var', mint.ones(num_features, **dd))
+
+        self.reset_parameters()
+
+    def reset_parameters(self):
+        nn.init.ones_(self.weight)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        nn.init.zeros_(self.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         _assert(x.dim() == 4, 'expected 4D input')
         x_dtype = x.dtype
         v_shape = (1, -1, 1, 1)
@@ -192,7 +194,7 @@         return x * self.weight.view(v_shape).to(x_dtype) + self.bias.view(v_shape).to(x_dtype)
 
 
-class EvoNorm2dB2(nn.Module):
+class EvoNorm2dB2(msnn.Cell):
     def __init__(
             self,
             num_features: int,
@@ -208,17 +210,17 @@         self.apply_act = apply_act  # apply activation (non-linearity)
         self.momentum = momentum
         self.eps = eps
-        self.weight = nn.Parameter(torch.empty(num_features, **dd))
-        self.bias = nn.Parameter(torch.empty(num_features, **dd))
-        self.register_buffer('running_var', torch.ones(num_features, **dd))
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        nn.init.ones_(self.weight)
-        nn.init.zeros_(self.bias)
-
-    def forward(self, x):
+        self.weight = ms.Parameter(mint.empty(num_features, **dd))
+        self.bias = ms.Parameter(mint.empty(num_features, **dd))
+        self.register_buffer('running_var', mint.ones(num_features, **dd))
+
+        self.reset_parameters()
+
+    def reset_parameters(self):
+        nn.init.ones_(self.weight)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        nn.init.zeros_(self.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         _assert(x.dim() == 4, 'expected 4D input')
         x_dtype = x.dtype
         v_shape = (1, -1, 1, 1)
@@ -238,7 +240,7 @@         return x * self.weight.view(v_shape).to(x_dtype) + self.bias.view(v_shape).to(x_dtype)
 
 
-class EvoNorm2dS0(nn.Module):
+class EvoNorm2dS0(msnn.Cell):
     def __init__(
             self,
             num_features: int,
@@ -259,19 +261,19 @@         else:
             self.groups = groups
         self.eps = eps
-        self.weight = nn.Parameter(torch.empty(num_features, **dd))
-        self.bias = nn.Parameter(torch.empty(num_features, **dd))
-        self.v = nn.Parameter(torch.empty(num_features, **dd)) if apply_act else None
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        nn.init.ones_(self.weight)
-        nn.init.zeros_(self.bias)
+        self.weight = ms.Parameter(mint.empty(num_features, **dd))
+        self.bias = ms.Parameter(mint.empty(num_features, **dd))
+        self.v = ms.Parameter(mint.empty(num_features, **dd)) if apply_act else None
+
+        self.reset_parameters()
+
+    def reset_parameters(self):
+        nn.init.ones_(self.weight)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        nn.init.zeros_(self.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if self.v is not None:
-            nn.init.ones_(self.v)
-
-    def forward(self, x):
+            nn.init.ones_(self.v)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         _assert(x.dim() == 4, 'expected 4D input')
         x_dtype = x.dtype
         v_shape = (1, -1, 1, 1)
@@ -315,14 +317,14 @@         return x * self.weight.view(v_shape).to(x_dtype) + self.bias.view(v_shape).to(x_dtype)
 
 
-class EvoNorm2dS1(nn.Module):
-    def __init__(
-            self,
-            num_features: int,
-            groups: int = 32,
-            group_size: Optional[int] = None,
-            apply_act: bool = True,
-            act_layer: Optional[Type[nn.Module]] = None,
+class EvoNorm2dS1(msnn.Cell):
+    def __init__(
+            self,
+            num_features: int,
+            groups: int = 32,
+            group_size: Optional[int] = None,
+            apply_act: bool = True,
+            act_layer: Optional[Type[msnn.Cell]] = None,
             eps: float = 1e-5,
             device=None,
             dtype=None,
@@ -335,7 +337,7 @@         if act_layer is not None and apply_act:
             self.act = create_act_layer(act_layer)
         else:
-            self.act = nn.Identity()
+            self.act = msnn.Identity()
         if group_size:
             assert num_features % group_size == 0
             self.groups = num_features // group_size
@@ -343,16 +345,16 @@             self.groups = groups
         self.eps = eps
         self.pre_act_norm = False
-        self.weight = nn.Parameter(torch.empty(num_features, **dd))
-        self.bias = nn.Parameter(torch.empty(num_features, **dd))
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        nn.init.ones_(self.weight)
-        nn.init.zeros_(self.bias)
-
-    def forward(self, x):
+        self.weight = ms.Parameter(mint.empty(num_features, **dd))
+        self.bias = ms.Parameter(mint.empty(num_features, **dd))
+
+        self.reset_parameters()
+
+    def reset_parameters(self):
+        nn.init.ones_(self.weight)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        nn.init.zeros_(self.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         _assert(x.dim() == 4, 'expected 4D input')
         x_dtype = x.dtype
         v_shape = (1, -1, 1, 1)
@@ -368,7 +370,7 @@             groups: int = 32,
             group_size: Optional[int] = None,
             apply_act: bool = True,
-            act_layer: Optional[Type[nn.Module]] = None,
+            act_layer: Optional[Type[msnn.Cell]] = None,
             eps: float = 1e-3,
             device=None,
             dtype=None,
@@ -393,14 +395,14 @@         return x * self.weight.view(v_shape).to(x_dtype) + self.bias.view(v_shape).to(x_dtype)
 
 
-class EvoNorm2dS2(nn.Module):
-    def __init__(
-            self,
-            num_features: int,
-            groups: int = 32,
-            group_size: Optional[int] = None,
-            apply_act: bool = True,
-            act_layer: Optional[Type[nn.Module]] = None,
+class EvoNorm2dS2(msnn.Cell):
+    def __init__(
+            self,
+            num_features: int,
+            groups: int = 32,
+            group_size: Optional[int] = None,
+            apply_act: bool = True,
+            act_layer: Optional[Type[msnn.Cell]] = None,
             eps: float = 1e-5,
             device=None,
             dtype=None,
@@ -413,23 +415,23 @@         if act_layer is not None and apply_act:
             self.act = create_act_layer(act_layer)
         else:
-            self.act = nn.Identity()
+            self.act = msnn.Identity()
         if group_size:
             assert num_features % group_size == 0
             self.groups = num_features // group_size
         else:
             self.groups = groups
         self.eps = eps
-        self.weight = nn.Parameter(torch.empty(num_features, **dd))
-        self.bias = nn.Parameter(torch.empty(num_features, **dd))
-
-        self.reset_parameters()
-
-    def reset_parameters(self):
-        nn.init.ones_(self.weight)
-        nn.init.zeros_(self.bias)
-
-    def forward(self, x):
+        self.weight = ms.Parameter(mint.empty(num_features, **dd))
+        self.bias = ms.Parameter(mint.empty(num_features, **dd))
+
+        self.reset_parameters()
+
+    def reset_parameters(self):
+        nn.init.ones_(self.weight)  # 'torch.nn.init.ones_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        nn.init.zeros_(self.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x):
         _assert(x.dim() == 4, 'expected 4D input')
         x_dtype = x.dtype
         v_shape = (1, -1, 1, 1)
@@ -445,7 +447,7 @@             groups: int = 32,
             group_size: Optional[int] = None,
             apply_act: bool = True,
-            act_layer: Optional[Type[nn.Module]] = None,
+            act_layer: Optional[Type[msnn.Cell]] = None,
             eps: float = 1e-3,
             device=None,
             dtype=None,
