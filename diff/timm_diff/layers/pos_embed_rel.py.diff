--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Relative position embedding modules and functions
 
 Hacked together by / Copyright 2022 Ross Wightman
@@ -6,9 +11,8 @@ import os
 from typing import Optional, Tuple
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch
+# import torch.nn as nn
 
 from .grid import ndgrid
 from .interpolate import RegularGridInterpolator
@@ -23,15 +27,15 @@         k_size: Optional[Tuple[int, int]] = None,
         class_token: bool = False,
         device=None,
-) -> torch.Tensor:
+) -> ms.Tensor:
     # Adapted with significant modifications from Swin / BeiT codebases
     # get pair-wise relative position index for each token inside the window
     assert k_size is None, 'Different q & k sizes not currently supported'  # FIXME
 
-    coords = torch.stack(ndgrid(
-        torch.arange(q_size[0], device=device),
-        torch.arange(q_size[1], device=device),
-    )).flatten(1)  # 2, Wh, Ww
+    coords = mint.stack(ndgrid(
+        mint.arange(q_size[0]),
+        mint.arange(q_size[1]),
+    )).flatten(1)  # 2, Wh, Ww; 'torch.arange':没有对应的mindspore参数 'device' (position 6);
     relative_coords = coords[:, :, None] - coords[:, None, :]  # 2, Wh*Ww, Wh*Ww
     relative_coords = relative_coords.permute(1, 2, 0)  # Qh*Qw, Kh*Kw, 2
     relative_coords[:, :, 0] += q_size[0] - 1  # shift to start from 0
@@ -66,7 +70,7 @@     if class_token:
         # handle cls to token & token 2 cls & cls to cls as per beit for rel pos bias
         # NOTE not intended or tested with MLP log-coords
-        relative_position_index = F.pad(relative_position_index, [1, 0, 1, 0])
+        relative_position_index = nn.functional.pad(relative_position_index, [1, 0, 1, 0])
         relative_position_index[0, 0:] = num_relative_distance
         relative_position_index[0:, 0] = num_relative_distance + 1
         relative_position_index[0, 0] = num_relative_distance + 2
@@ -86,12 +90,7 @@         num_attn_heads, src_h, src_w = rel_pos_bias.shape
         assert dst_h == dst_size[0] and dst_w == dst_size[1]
         if src_h != dst_h or src_w != dst_w:
-            rel_pos_bias = torch.nn.functional.interpolate(
-                rel_pos_bias.unsqueeze(0),
-                size=dst_size,
-                mode="bicubic",
-                align_corners=False,
-            ).squeeze(0)
+            rel_pos_bias = mint.squeeze(0)
     else:
         assert rel_pos_bias.ndim == 2
         # (num_pos, num_heads) (aka flat) bias shape
@@ -108,15 +107,10 @@             else:
                 extra_tokens = None
 
-            rel_pos_bias = torch.nn.functional.interpolate(
-                rel_pos_bias.transpose(1, 0).reshape((1, -1, src_size[0], src_size[1])),
-                size=dst_size,
-                mode="bicubic",
-                align_corners=False,
-            ).view(-1, dst_num_pos - num_extra_tokens).transpose(0, 1)
+            rel_pos_bias = mint.transpose(0, 1)  # 'torch.nn.functional.interpolate.view' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
             if extra_tokens is not None:
-                rel_pos_bias = torch.cat((rel_pos_bias, extra_tokens), dim=0)
+                rel_pos_bias = mint.cat((rel_pos_bias, extra_tokens), dim = 0)
 
     return rel_pos_bias
 
@@ -140,12 +134,8 @@         # bicubic interpolate relative_position_bias_table if not match
         S1 = int(L1 ** 0.5)
         S2 = int(L2 ** 0.5)
-        relative_position_bias_table_resized = F.interpolate(
-            position_bias_table.permute(1, 0).view(1, nH1, S1, S1),
-            size=(S2, S2),
-            mode=interpolation,
-            antialias=antialias,
-        )
+        relative_position_bias_table_resized = nn.functional.interpolate(
+            position_bias_table.permute(1, 0).view(1, nH1, S1, S1), size = (S2, S2), mode = interpolation)  # 'torch.nn.functional.interpolate':没有对应的mindspore参数 'antialias' (position 6);
         relative_position_bias_table_resized = relative_position_bias_table_resized.view(nH2, L2).permute(1, 0)
         relative_position_bias_table_resized.to(orig_dtype)
         return relative_position_bias_table_resized
@@ -225,13 +215,13 @@ 
         y = _calc(src_size[0], dst_size[0])
         x = _calc(src_size[1], dst_size[1])
-        yx = [torch.tensor(y), torch.tensor(x)]
+        yx = [ms.Tensor(y), ms.Tensor(x)]  # 'torch.tensor':默认参数名不一致(position 0): PyTorch=data, MindSpore=input_data;
         # print("Original positions = %s" % str(x))
 
         ty = dst_size[0] // 2.0
         tx = dst_size[1] // 2.0
-        dy = torch.arange(-ty, ty + 0.1, 1.0)
-        dx = torch.arange(-tx, tx + 0.1, 1.0)
+        dy = mint.arange(-ty, ty + 0.1, 1.0)
+        dx = mint.arange(-tx, tx + 0.1, 1.0)
         dyx = ndgrid(dy, dx)
         # print("Target positions = %s" % str(dx))
 
@@ -245,7 +235,7 @@             if _USE_SCIPY:
                 # Original beit code uses scipy w/ cubic interpolation
                 f = interpolate.interp2d(x, y, z.numpy(), kind='cubic')
-                r = torch.Tensor(f(dx, dy)).contiguous().to(rel_pos_bias.device)
+                r = ms.Tensor(f(dx, dy)).contiguous().to(rel_pos_bias.device)
             else:
                 # Without scipy dependency, I've found a reasonably simple impl
                 # that supports uneven spaced interpolation pts with 'linear' interp.
@@ -258,18 +248,18 @@             all_rel_pos_bias.append(r)
 
         if has_flat_shape:
-            rel_pos_bias = torch.cat(all_rel_pos_bias, dim=-1)
+            rel_pos_bias = mint.cat(all_rel_pos_bias, dim = -1)
         else:
-            rel_pos_bias = torch.cat(all_rel_pos_bias, dim=0)
+            rel_pos_bias = mint.cat(all_rel_pos_bias, dim = 0)
 
         if extra_tokens is not None:
             assert has_flat_shape
-            rel_pos_bias = torch.cat((rel_pos_bias, extra_tokens), dim=0)
+            rel_pos_bias = mint.cat((rel_pos_bias, extra_tokens), dim = 0)
 
     return rel_pos_bias
 
 
-class RelPosBias(nn.Module):
+class RelPosBias(msnn.Cell):
     """ Relative Position Bias
     Adapted from Swin-V1 relative position bias impl, modularized.
     """
@@ -290,7 +280,7 @@         self.bias_shape = (self.window_area + prefix_tokens,) * 2 + (num_heads,)
 
         num_relative_distance = (2 * window_size[0] - 1) * (2 * window_size[1] - 1) + 3 * prefix_tokens
-        self.relative_position_bias_table = nn.Parameter(torch.empty(num_relative_distance, num_heads, **dd))
+        self.relative_position_bias_table = ms.Parameter(mint.empty(num_relative_distance, num_heads, **dd))
         self.register_buffer(
             "relative_position_index",
             gen_relative_position_index(self.window_size, class_token=prefix_tokens > 0, device=device).view(-1),
@@ -302,13 +292,13 @@     def init_weights(self):
         trunc_normal_(self.relative_position_bias_table, std=.02)
 
-    def get_bias(self) -> torch.Tensor:
+    def get_bias(self) -> ms.Tensor:
         relative_position_bias = self.relative_position_bias_table[self.relative_position_index]
         # win_h * win_w, win_h * win_w, num_heads
         relative_position_bias = relative_position_bias.view(self.bias_shape).permute(2, 0, 1)
         return relative_position_bias.unsqueeze(0).contiguous()
 
-    def forward(self, attn, shared_rel_pos: Optional[torch.Tensor] = None):
+    def construct(self, attn, shared_rel_pos: Optional[torch.Tensor] = None):
         return attn + self.get_bias()
 
 
@@ -321,9 +311,9 @@ ):
     assert mode in ('swin', 'cr')
     # as per official swin-v2 impl, supporting timm specific 'cr' log coords as well
-    relative_coords_h = torch.arange(-(win_size[0] - 1), win_size[0], device=device).to(torch.float32)
-    relative_coords_w = torch.arange(-(win_size[1] - 1), win_size[1], device=device).to(torch.float32)
-    relative_coords_table = torch.stack(ndgrid(relative_coords_h, relative_coords_w))
+    relative_coords_h = mint.arange(-(win_size[0] - 1), win_size[0]).to(ms.float32)  # 'torch.arange':没有对应的mindspore参数 'device' (position 6);
+    relative_coords_w = mint.arange(-(win_size[1] - 1), win_size[1]).to(ms.float32)  # 'torch.arange':没有对应的mindspore参数 'device' (position 6);
+    relative_coords_table = mint.stack(ndgrid(relative_coords_h, relative_coords_w))
     relative_coords_table = relative_coords_table.permute(1, 2, 0).contiguous()  # 2*Wh-1, 2*Ww-1, 2
     if mode == 'swin':
         if pretrained_win_size[0] > 0:
@@ -333,17 +323,17 @@             relative_coords_table[:, :, 0] /= (win_size[0] - 1)
             relative_coords_table[:, :, 1] /= (win_size[1] - 1)
         relative_coords_table *= 8  # normalize to -8, 8
-        relative_coords_table = torch.sign(relative_coords_table) * torch.log2(
+        relative_coords_table = mint.sign(relative_coords_table) * mint.log2(
             1.0 + relative_coords_table.abs()) / math.log2(8)
     else:
         # mode == 'cr'
-        relative_coords_table = torch.sign(relative_coords_table) * torch.log(
+        relative_coords_table = mint.sign(relative_coords_table) * mint.log(
             1.0 + relative_coords_table.abs())
 
     return relative_coords_table.to(dtype)
 
 
-class RelPosMlp(nn.Module):
+class RelPosMlp(msnn.Cell):
     """ Log-Coordinate Relative Position MLP
     Based on ideas presented in Swin-V2 paper (https://arxiv.org/abs/2111.09883)
 
@@ -372,7 +362,7 @@             self.bias_gain = 16
             mlp_bias = (True, False)
         else:
-            self.bias_act = nn.Identity()
+            self.bias_act = msnn.Identity()
             self.bias_gain = None
             mlp_bias = True
 
@@ -399,7 +389,7 @@             persistent=False,
         )
 
-    def get_bias(self) -> torch.Tensor:
+    def get_bias(self) -> ms.Tensor:
         relative_position_bias = self.mlp(self.rel_coords_log)
         if self.relative_position_index is not None:
             relative_position_bias = relative_position_bias.view(-1, self.num_heads)[self.relative_position_index]
@@ -409,10 +399,10 @@         if self.bias_gain is not None:
             relative_position_bias = self.bias_gain * relative_position_bias
         if self.prefix_tokens:
-            relative_position_bias = F.pad(relative_position_bias, [self.prefix_tokens, 0, self.prefix_tokens, 0])
+            relative_position_bias = nn.functional.pad(relative_position_bias, [self.prefix_tokens, 0, self.prefix_tokens, 0])
         return relative_position_bias.unsqueeze(0).contiguous()
 
-    def forward(self, attn, shared_rel_pos: Optional[torch.Tensor] = None):
+    def construct(self, attn, shared_rel_pos: Optional[torch.Tensor] = None):
         return attn + self.get_bias()
 
 
@@ -437,7 +427,7 @@         max_relative_position = length - 1
     # Return the cached lookup tensor, otherwise compute it and cache it.
     vocab_size = 2 * max_relative_position + 1
-    ret = torch.zeros(length, length, vocab_size, device=device, dtype=dtype)
+    ret = mint.zeros(size = (length, length, vocab_size), dtype = dtype)  # 'torch.zeros':没有对应的mindspore参数 'device' (position 4);
     for i in range(length):
         for x in range(length):
             v = x - i + max_relative_position
@@ -451,9 +441,9 @@         relative_position_tensor,
         height: int,
         width: int,
-        height_lookup: torch.Tensor,
-        width_lookup: torch.Tensor,
-) -> torch.Tensor:
+        height_lookup: ms.Tensor,
+        width_lookup: ms.Tensor,
+) -> ms.Tensor:
     """Reindex 2d relative position bias with 2 independent einsum lookups.
 
     Adapted from:
@@ -470,13 +460,13 @@         reindexed_tensor: a Tensor of shape
             [..., height * width, height * width, ...]
     """
-    reindexed_tensor = torch.einsum('nhw,ixh->nixw', relative_position_tensor, height_lookup)
-    reindexed_tensor = torch.einsum('nixw,jyw->nijxy', reindexed_tensor, width_lookup)
+    reindexed_tensor = mint.einsum('nhw,ixh->nixw', relative_position_tensor, height_lookup)
+    reindexed_tensor = mint.einsum('nixw,jyw->nijxy', reindexed_tensor, width_lookup)
     area = height * width
     return reindexed_tensor.reshape(relative_position_tensor.shape[0], area, area)
 
 
-class RelPosBiasTf(nn.Module):
+class RelPosBiasTf(msnn.Cell):
     """ Relative Position Bias Impl (Compatible with Tensorflow MaxViT models)
     Adapted from:
      https://github.com/google-research/maxvit/blob/2e06a7f1f70c76e64cd3dabe5cd1b8c1a23c9fb7/maxvit/models/attention_utils.py
@@ -499,15 +489,15 @@         vocab_height = 2 * window_size[0] - 1
         vocab_width = 2 * window_size[1] - 1
         self.bias_shape = (self.num_heads, vocab_height, vocab_width)
-        self.relative_position_bias_table = nn.Parameter(torch.empty(self.bias_shape, **dd))
+        self.relative_position_bias_table = ms.Parameter(mint.empty(self.bias_shape, **dd))
         self.register_buffer('height_lookup', generate_lookup_tensor(window_size[0], **dd), persistent=False)
         self.register_buffer('width_lookup', generate_lookup_tensor(window_size[1], **dd), persistent=False)
         self.init_weights()
 
     def init_weights(self):
-        nn.init.normal_(self.relative_position_bias_table, std=.02)
-
-    def get_bias(self) -> torch.Tensor:
+        nn.init.normal_(self.relative_position_bias_table, std=.02)  # 'torch.nn.init.normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def get_bias(self) -> ms.Tensor:
         # FIXME change to not use one-hot/einsum?
         return reindex_2d_einsum_lookup(
             self.relative_position_bias_table,
@@ -517,5 +507,5 @@             self.width_lookup
         )
 
-    def forward(self, attn, shared_rel_pos: Optional[torch.Tensor] = None):
+    def construct(self, attn, shared_rel_pos: Optional[torch.Tensor] = None):
         return attn + self.get_bias()
