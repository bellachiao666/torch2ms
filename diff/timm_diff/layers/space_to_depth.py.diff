--- pytorch+++ mindspore@@ -1,8 +1,12 @@-import torch
-import torch.nn as nn
+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
+# import torch
 
 
-class SpaceToDepth(nn.Module):
+class SpaceToDepth(msnn.Cell):
     bs: torch.jit.Final[int]
 
     def __init__(self, block_size: int = 4):
@@ -10,7 +14,7 @@         assert block_size == 4
         self.bs = block_size
 
-    def forward(self, x):
+    def construct(self, x):
         N, C, H, W = x.size()
         x = x.view(N, C, H // self.bs, self.bs, W // self.bs, self.bs)  # (N, C, H//bs, bs, W//bs, bs)
         x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # (N, bs, bs, C, H//bs, W//bs)
@@ -18,13 +22,13 @@         return x
 
 
-class DepthToSpace(nn.Module):
+class DepthToSpace(msnn.Cell):
 
     def __init__(self, block_size):
         super().__init__()
         self.bs = block_size
 
-    def forward(self, x):
+    def construct(self, x):
         N, C, H, W = x.size()
         x = x.view(N, self.bs, self.bs, C // (self.bs ** 2), H, W)  # (N, bs, bs, C//bs^2, H, W)
         x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # (N, C//bs^2, H, bs, W, bs)
