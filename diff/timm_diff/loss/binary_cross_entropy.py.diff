--- pytorch+++ mindspore@@ -1,15 +1,19 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Binary Cross Entropy w/ a few extras
 
 Hacked together by / Copyright 2021 Ross Wightman
 """
 from typing import Optional, Union
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch
+# import torch.nn as nn
 
 
-class BinaryCrossEntropy(nn.Module):
+class BinaryCrossEntropy(msnn.Cell):
     """ BCE with optional one-hot from dense targets, label smoothing, thresholding
     NOTE for experiments comparing CE to BCE /w label smoothing, may remove
     """
@@ -17,16 +21,16 @@             self,
             smoothing=0.1,
             target_threshold: Optional[float] = None,
-            weight: Optional[torch.Tensor] = None,
+            weight: Optional[ms.Tensor] = None,
             reduction: str = 'mean',
             sum_classes: bool = False,
-            pos_weight: Optional[Union[torch.Tensor, float]] = None,
+            pos_weight: Optional[Union[ms.Tensor, float]] = None,
     ):
         super(BinaryCrossEntropy, self).__init__()
         assert 0. <= smoothing < 1.0
         if pos_weight is not None:
             if not isinstance(pos_weight, torch.Tensor):
-                pos_weight = torch.tensor(pos_weight)
+                pos_weight = ms.Tensor(pos_weight)  # 'torch.tensor':默认参数名不一致(position 0): PyTorch=data, MindSpore=input_data;
         self.smoothing = smoothing
         self.target_threshold = target_threshold
         self.reduction = 'none' if sum_classes else reduction
@@ -34,7 +38,7 @@         self.register_buffer('weight', weight)
         self.register_buffer('pos_weight', pos_weight)
 
-    def forward(self, x: torch.Tensor, target: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor, target: ms.Tensor) -> ms.Tensor:
         batch_size = x.shape[0]
         assert batch_size == target.shape[0]
 
@@ -45,21 +49,15 @@             off_value = self.smoothing / num_classes
             on_value = 1. - self.smoothing + off_value
             target = target.long().view(-1, 1)
-            target = torch.full(
-                (batch_size, num_classes),
-                off_value,
-                device=x.device, dtype=x.dtype).scatter_(1, target, on_value)
+            target = mint.full(
+                size = ((batch_size, num_classes), off_value), dtype = x.dtype).scatter_(1, target, on_value)  # 'torch.full':没有对应的mindspore参数 'device' (position 5);
 
         if self.target_threshold is not None:
             # Make target 0, or 1 if threshold set
             target = target.gt(self.target_threshold).to(dtype=target.dtype)
 
-        loss = F.binary_cross_entropy_with_logits(
-            x, target,
-            self.weight,
-            pos_weight=self.pos_weight,
-            reduction=self.reduction,
-        )
+        loss = nn.functional.binary_cross_entropy_with_logits(
+            x, target, self.weight, reduction = self.reduction, pos_weight = self.pos_weight)
         if self.sum_classes:
             loss = loss.sum(-1).mean()
         return loss
