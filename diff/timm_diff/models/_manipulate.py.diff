--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import collections.abc
 import math
 import re
@@ -5,10 +10,9 @@ from itertools import chain
 from typing import Any, Callable, Dict, Iterator, Optional, Tuple, Type, Union
 
-import torch
-import torch.utils.checkpoint
-from torch import nn as nn
-from torch import Tensor
+# import torch
+# from torch import nn as nn
+# from torch import Tensor
 
 from timm.layers import use_reentrant_ckpt
 
@@ -17,6 +21,7 @@            'group_with_matcher', 'group_modules', 'group_parameters', 'flatten_modules', 'checkpoint_seq', 'checkpoint']
 
 
+# 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def model_parameters(model: nn.Module, exclude_head: bool = False):
     if exclude_head:
         # FIXME this a bit of a quick and dirty hack to skip classifier head params based on ordering
@@ -25,6 +30,7 @@         return model.parameters()
 
 
+# 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def named_apply(
         fn: Callable,
         module: nn.Module, name='',
@@ -41,6 +47,7 @@     return module
 
 
+# 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def named_modules(
         module: nn.Module,
         name: str = '',
@@ -57,6 +64,7 @@         yield name, module
 
 
+# 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def named_modules_with_params(
         module: nn.Module,
         name: str = '',
@@ -137,6 +145,7 @@     return layer_id_to_param
 
 
+# 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def group_parameters(
         module: nn.Module,
         group_matcher,
@@ -147,6 +156,7 @@         module.named_parameters(), group_matcher, return_values=return_values, reverse=reverse)
 
 
+# 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 def group_modules(
         module: nn.Module,
         group_matcher,
@@ -206,7 +216,7 @@         *args,
         use_reentrant=use_reentrant,
         **kwargs,
-    )
+    )  # 'torch.utils.checkpoint.checkpoint' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
 def checkpoint_seq(
@@ -279,13 +289,13 @@             run_function(start, end, functions),
             x,
             use_reentrant=use_reentrant,
-        )
+        )  # 'torch.utils.checkpoint.checkpoint' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     if skip_last:
         return run_function(end + 1, len(functions) - 1, functions)(x)
     return x
 
 
-def adapt_input_conv(in_chans: int, conv_weight: Tensor) -> Tensor:
+def adapt_input_conv(in_chans: int, conv_weight: ms.Tensor) -> ms.Tensor:
     conv_type = conv_weight.dtype
     conv_weight = conv_weight.float()  # Some weights are in torch.half, ensure it's float for sum on CPU
     O, I, J, K = conv_weight.shape
