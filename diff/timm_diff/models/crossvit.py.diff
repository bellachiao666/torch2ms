--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ CrossViT Model
 
 @inproceedings{
@@ -23,8 +28,8 @@ from functools import partial
 from typing import List, Optional, Tuple, Type, Union
 
-import torch
-import torch.nn as nn
+# import torch
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import DropPath, calculate_drop_path_rates, to_2tuple, trunc_normal_, _assert
@@ -36,7 +41,7 @@ __all__ = ['CrossVit']  # model_registry will add each entrypoint fn to this
 
 
-class PatchEmbed(nn.Module):
+class PatchEmbed(msnn.Cell):
     """ Image to Patch Embedding
     """
 
@@ -60,25 +65,25 @@         self.num_patches = num_patches
         if multi_conv:
             if patch_size[0] == 12:
-                self.proj = nn.Sequential(
+                self.proj = msnn.SequentialCell(
                     nn.Conv2d(in_chans, embed_dim // 4, kernel_size=7, stride=4, padding=3, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 4, embed_dim // 2, kernel_size=3, stride=3, padding=0, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 2, embed_dim, kernel_size=3, stride=1, padding=1, **dd),
-                )
+                )  # 存在 *args/**kwargs，需手动确认参数映射;; 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
             elif patch_size[0] == 16:
-                self.proj = nn.Sequential(
+                self.proj = msnn.SequentialCell(
                     nn.Conv2d(in_chans, embed_dim // 4, kernel_size=7, stride=4, padding=3, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 4, embed_dim // 2, kernel_size=3, stride=2, padding=1, **dd),
-                    nn.ReLU(inplace=True),
+                    nn.ReLU(),
                     nn.Conv2d(embed_dim // 2, embed_dim, kernel_size=3, stride=2, padding=1, **dd),
-                )
+                )  # 存在 *args/**kwargs，需手动确认参数映射;; 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
         else:
-            self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, **dd)
-
-    def forward(self, x):
+            self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+
+    def construct(self, x):
         B, C, H, W = x.shape
         # FIXME look at relaxing size constraints
         _assert(H == self.img_size[0],
@@ -89,7 +94,7 @@         return x
 
 
-class CrossAttention(nn.Module):
+class CrossAttention(msnn.Cell):
     def __init__(
             self,
             dim: int,
@@ -107,14 +112,14 @@         # NOTE scale factor was wrong in my original version, can set manually to be compat with prev weights
         self.scale = head_dim ** -0.5
 
-        self.wq = nn.Linear(dim, dim, bias=qkv_bias, **dd)
-        self.wk = nn.Linear(dim, dim, bias=qkv_bias, **dd)
-        self.wv = nn.Linear(dim, dim, bias=qkv_bias, **dd)
+        self.wq = nn.Linear(dim, dim, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.wk = nn.Linear(dim, dim, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.wv = nn.Linear(dim, dim, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.attn_drop = nn.Dropout(attn_drop)
-        self.proj = nn.Linear(dim, dim, **dd)
+        self.proj = nn.Linear(dim, dim, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.proj_drop = nn.Dropout(proj_drop)
 
-    def forward(self, x):
+    def construct(self, x):
         B, N, C = x.shape
         # B1C -> B1H(C/H) -> BH1(C/H)
         q = self.wq(x[:, 0:1, ...]).reshape(B, 1, self.num_heads, C // self.num_heads).permute(0, 2, 1, 3)
@@ -133,7 +138,7 @@         return x
 
 
-class CrossAttentionBlock(nn.Module):
+class CrossAttentionBlock(msnn.Cell):
 
     def __init__(
             self,
@@ -144,14 +149,14 @@             proj_drop: float = 0.,
             attn_drop: float = 0.,
             drop_path: float = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             device=None,
             dtype=None,
     ):
         dd = {'device': device, 'dtype': dtype}
         super().__init__()
-        self.norm1 = norm_layer(dim, **dd)
+        self.norm1 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.attn = CrossAttention(
             dim,
             num_heads=num_heads,
@@ -159,16 +164,16 @@             attn_drop=attn_drop,
             proj_drop=proj_drop,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         # NOTE: drop path for stochastic depth, we shall see if this is better than dropout here
-        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x):
+        self.drop_path = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x):
         x = x[:, 0:1, ...] + self.drop_path(self.attn(self.norm1(x)))
         return x
 
 
-class MultiScaleBlock(nn.Module):
+class MultiScaleBlock(msnn.Cell):
 
     def __init__(
             self,
@@ -181,8 +186,8 @@             proj_drop: float = 0.,
             attn_drop: float = 0.,
             drop_path: Union[List[float], float] = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             device=None,
             dtype=None,
     ):
@@ -191,7 +196,7 @@         num_branches = len(dim)
         self.num_branches = num_branches
         # different branch could have different embedding size, the first one is the base
-        self.blocks = nn.ModuleList()
+        self.blocks = msnn.CellList()
         for d in range(num_branches):
             tmp = []
             for i in range(depth[d]):
@@ -205,22 +210,22 @@                     drop_path=drop_path[i],
                     norm_layer=norm_layer,
                     **dd,
-                ))
+                ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             if len(tmp) != 0:
-                self.blocks.append(nn.Sequential(*tmp))
+                self.blocks.append(msnn.SequentialCell(*tmp))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         if len(self.blocks) == 0:
             self.blocks = None
 
-        self.projs = nn.ModuleList()
+        self.projs = msnn.CellList()
         for d in range(num_branches):
             if dim[d] == dim[(d + 1) % num_branches] and False:
-                tmp = [nn.Identity()]
+                tmp = [msnn.Identity()]
             else:
-                tmp = [norm_layer(dim[d], **dd), act_layer(), nn.Linear(dim[d], dim[(d + 1) % num_branches], **dd)]
-            self.projs.append(nn.Sequential(*tmp))
-
-        self.fusion = nn.ModuleList()
+                tmp = [norm_layer(dim[d], **dd), act_layer(), nn.Linear(dim[d], dim[(d + 1) % num_branches], **dd)]  # 存在 *args/**kwargs，未转换，需手动确认参数映射;; 存在 *args/**kwargs，需手动确认参数映射;
+            self.projs.append(msnn.SequentialCell(*tmp))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        self.fusion = msnn.CellList()
         for d in range(num_branches):
             d_ = (d + 1) % num_branches
             nh = num_heads[d_]
@@ -236,7 +241,7 @@                         drop_path=drop_path[-1],
                         norm_layer=norm_layer,
                         **dd,
-                    ))
+                    ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             else:
                 tmp = []
                 for _ in range(depth[-1]):
@@ -250,36 +255,36 @@                         drop_path=drop_path[-1],
                         norm_layer=norm_layer,
                         **dd,
-                    ))
-                self.fusion.append(nn.Sequential(*tmp))
-
-        self.revert_projs = nn.ModuleList()
+                    ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+                self.fusion.append(msnn.SequentialCell(*tmp))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        self.revert_projs = msnn.CellList()
         for d in range(num_branches):
             if dim[(d + 1) % num_branches] == dim[d] and False:
-                tmp = [nn.Identity()]
+                tmp = [msnn.Identity()]
             else:
                 tmp = [norm_layer(dim[(d + 1) % num_branches], **dd), act_layer(),
-                       nn.Linear(dim[(d + 1) % num_branches], dim[d], **dd)]
-            self.revert_projs.append(nn.Sequential(*tmp))
-
-    def forward(self, x: List[torch.Tensor]) -> List[torch.Tensor]:
+                       nn.Linear(dim[(d + 1) % num_branches], dim[d], **dd)]  # 存在 *args/**kwargs，未转换，需手动确认参数映射;; 存在 *args/**kwargs，需手动确认参数映射;
+            self.revert_projs.append(msnn.SequentialCell(*tmp))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+    def construct(self, x: List[ms.Tensor]) -> List[ms.Tensor]:
 
         outs_b = []
         for i, block in enumerate(self.blocks):
             outs_b.append(block(x[i]))
 
         # only take the cls token out
-        proj_cls_token = torch.jit.annotate(List[torch.Tensor], [])
+        proj_cls_token = torch.jit.annotate(List[ms.Tensor], [])  # 'torch.jit.annotate' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         for i, proj in enumerate(self.projs):
             proj_cls_token.append(proj(outs_b[i][:, 0:1, ...]))
 
         # cross attention
         outs = []
         for i, (fusion, revert_proj) in enumerate(zip(self.fusion, self.revert_projs)):
-            tmp = torch.cat((proj_cls_token[i], outs_b[(i + 1) % self.num_branches][:, 1:, ...]), dim=1)
+            tmp = mint.cat((proj_cls_token[i], outs_b[(i + 1) % self.num_branches][:, 1:, ...]), dim=1)
             tmp = fusion(tmp)
             reverted_proj_cls_token = revert_proj(tmp[:, 0:1, ...])
-            tmp = torch.cat((reverted_proj_cls_token, outs_b[i][:, 1:, ...]), dim=1)
+            tmp = mint.cat((reverted_proj_cls_token, outs_b[i][:, 1:, ...]), dim=1)
             outs.append(tmp)
         return outs
 
@@ -305,11 +310,11 @@             cu, cl = int(round((H - ss[0]) / 2.)), int(round((W - ss[1]) / 2.))
             x = x[:, :, cu:cu + ss[0], cl:cl + ss[1]]
         else:
-            x = torch.nn.functional.interpolate(x, size=ss, mode='bicubic', align_corners=False)
+            x = nn.functional.interpolate(x, size = ss, mode = 'bicubic', align_corners = False)
     return x
 
 
-class CrossVit(nn.Module):
+class CrossVit(msnn.Cell):
     """ Vision Transformer with support for patch or hybrid CNN input stage
     """
 
@@ -332,7 +337,7 @@             proj_drop_rate: float = 0.,
             attn_drop_rate: float = 0.,
             drop_path_rate: float = 0.,
-            norm_layer: Type[nn.Module] = partial(nn.LayerNorm, eps=1e-6),
+            norm_layer: Type[msnn.Cell] = partial(nn.LayerNorm, eps=1e-6),
             global_pool: str = 'token',
             device=None,
             dtype=None,
@@ -351,12 +356,12 @@         self.num_branches = len(patch_size)
         self.embed_dim = embed_dim
         self.num_features = self.head_hidden_size = sum(embed_dim)
-        self.patch_embed = nn.ModuleList()
+        self.patch_embed = msnn.CellList()
 
         # hard-coded for torch jit script
         for i in range(self.num_branches):
-            setattr(self, f'pos_embed_{i}', nn.Parameter(torch.zeros(1, 1 + num_patches[i], embed_dim[i], **dd)))
-            setattr(self, f'cls_token_{i}', nn.Parameter(torch.zeros(1, 1, embed_dim[i], **dd)))
+            setattr(self, f'pos_embed_{i}', ms.Parameter(mint.zeros(1, 1 + num_patches[i], embed_dim[i], **dd)))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+            setattr(self, f'cls_token_{i}', ms.Parameter(mint.zeros(1, 1, embed_dim[i], **dd)))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         for im_s, p, d in zip(self.img_size_scaled, patch_size, embed_dim):
             self.patch_embed.append(
@@ -367,14 +372,14 @@                     embed_dim=d,
                     multi_conv=multi_conv,
                     **dd,
-                ))
-
-        self.pos_drop = nn.Dropout(p=pos_drop_rate)
+                ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        self.pos_drop = nn.Dropout(p = pos_drop_rate)
 
         total_depth = sum([sum(x[-2:]) for x in depth])
         dpr = calculate_drop_path_rates(drop_path_rate, total_depth)  # stochastic depth decay rule
         dpr_ptr = 0
-        self.blocks = nn.ModuleList()
+        self.blocks = msnn.CellList()
         for idx, block_cfg in enumerate(depth):
             curr_depth = max(block_cfg[:-1]) + block_cfg[-1]
             dpr_ = dpr[dpr_ptr:dpr_ptr + curr_depth]
@@ -390,15 +395,15 @@                 drop_path=dpr_,
                 norm_layer=norm_layer,
                 **dd,
-            )
+            )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             dpr_ptr += curr_depth
             self.blocks.append(blk)
 
-        self.norm = nn.ModuleList([norm_layer(embed_dim[i], **dd) for i in range(self.num_branches)])
+        self.norm = msnn.CellList([norm_layer(embed_dim[i], **dd) for i in range(self.num_branches)])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.head_drop = nn.Dropout(drop_rate)
-        self.head = nn.ModuleList([
-            nn.Linear(embed_dim[i], num_classes, **dd) if num_classes > 0 else nn.Identity()
-            for i in range(self.num_branches)])
+        self.head = msnn.CellList([
+            nn.Linear(embed_dim[i], num_classes, **dd) if num_classes > 0 else msnn.Identity()
+            for i in range(self.num_branches)])  # 存在 *args/**kwargs，需手动确认参数映射;
 
         for i in range(self.num_branches):
             trunc_normal_(getattr(self, f'pos_embed_{i}'), std=.02)
@@ -410,12 +415,12 @@         if isinstance(m, nn.Linear):
             trunc_normal_(m.weight, std=.02)
             if isinstance(m, nn.Linear) and m.bias is not None:
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         elif isinstance(m, nn.LayerNorm):
-            nn.init.constant_(m.bias, 0)
-            nn.init.constant_(m.weight, 1.0)
-
-    @torch.jit.ignore
+            nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            nn.init.constant_(m.weight, 1.0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    @ms.jit
     def no_weight_decay(self):
         out = set()
         for i in range(self.num_branches):
@@ -425,19 +430,19 @@                 out.add(f'pos_embed_{i}')
         return out
 
-    @torch.jit.ignore
+    @ms.jit
     def group_matcher(self, coarse=False):
         return dict(
             stem=r'^cls_token|pos_embed|patch_embed',  # stem and embed
             blocks=[(r'^blocks\.(\d+)', None), (r'^norm', (99999,))]
         )
 
-    @torch.jit.ignore
+    @ms.jit
     def set_grad_checkpointing(self, enable=True):
         assert not enable, 'gradient checkpointing not supported'
 
-    @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    @ms.jit
+    def get_classifier(self) -> msnn.Cell:
         return self.head
 
     def reset_classifier(self, num_classes: int, global_pool: Optional[str] = None):
@@ -448,12 +453,12 @@         device = self.head[0].weight.device if hasattr(self.head[0], 'weight') else None
         dtype = self.head[0].weight.dtype if hasattr(self.head[0], 'weight') else None
         dd = {'device': device, 'dtype': dtype}
-        self.head = nn.ModuleList([
-            nn.Linear(self.embed_dim[i], num_classes, **dd) if num_classes > 0 else nn.Identity()
+        self.head = msnn.CellList([
+            nn.Linear(self.embed_dim[i], num_classes, **dd) if num_classes > 0 else msnn.Identity()
             for i in range(self.num_branches)
-        ])
-
-    def forward_features(self, x) -> List[torch.Tensor]:
+        ])  # 存在 *args/**kwargs，需手动确认参数映射;
+
+    def forward_features(self, x) -> List[ms.Tensor]:
         B = x.shape[0]
         xs = []
         for i, patch_embed in enumerate(self.patch_embed):
@@ -463,7 +468,7 @@             x_ = patch_embed(x_)
             cls_tokens = self.cls_token_0 if i == 0 else self.cls_token_1  # hard-coded for torch jit script
             cls_tokens = cls_tokens.expand(B, -1, -1)
-            x_ = torch.cat((cls_tokens, x_), dim=1)
+            x_ = mint.cat((cls_tokens, x_), dim=1)
             pos_embed = self.pos_embed_0 if i == 0 else self.pos_embed_1  # hard-coded for torch jit script
             x_ = x_ + pos_embed
             x_ = self.pos_drop(x_)
@@ -476,14 +481,14 @@         xs = [norm(xs[i]) for i, norm in enumerate(self.norm)]
         return xs
 
-    def forward_head(self, xs: List[torch.Tensor], pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, xs: List[ms.Tensor], pre_logits: bool = False) -> ms.Tensor:
         xs = [x[:, 1:].mean(dim=1) for x in xs] if self.global_pool == 'avg' else [x[:, 0] for x in xs]
         xs = [self.head_drop(x) for x in xs]
-        if pre_logits or isinstance(self.head[0], nn.Identity):
-            return torch.cat([x for x in xs], dim=1)
-        return torch.mean(torch.stack([head(xs[i]) for i, head in enumerate(self.head)], dim=0), dim=0)
-
-    def forward(self, x):
+        if pre_logits or isinstance(self.head[0], msnn.Identity):
+            return mint.cat([x for x in xs], dim=1)
+        return mint.mean(mint.stack([head(xs[i]) for i, head in enumerate(self.head)], dim=0), dim=0)
+
+    def construct(self, x):
         xs = self.forward_features(x)
         x = self.forward_head(xs)
         return x
@@ -509,7 +514,7 @@         pretrained,
         pretrained_filter_fn=pretrained_filter_fn,
         **kwargs,
-    )
+    )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _cfg(url='', **kwargs):
@@ -559,7 +564,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[96, 192], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],
         num_heads=[3, 3], mlp_ratio=[4, 4, 1])
-    model = _create_crossvit(variant='crossvit_tiny_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_tiny_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -568,7 +573,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],
         num_heads=[6, 6], mlp_ratio=[4, 4, 1])
-    model = _create_crossvit(variant='crossvit_small_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_small_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -577,7 +582,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[384, 768], depth=[[1, 4, 0], [1, 4, 0], [1, 4, 0]],
         num_heads=[12, 12], mlp_ratio=[4, 4, 1])
-    model = _create_crossvit(variant='crossvit_base_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_base_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -586,7 +591,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[128, 256], depth=[[1, 3, 0], [1, 3, 0], [1, 3, 0]],
         num_heads=[4, 4], mlp_ratio=[3, 3, 1])
-    model = _create_crossvit(variant='crossvit_9_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_9_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -595,7 +600,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],
         num_heads=[6, 6], mlp_ratio=[3, 3, 1])
-    model = _create_crossvit(variant='crossvit_15_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_15_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -603,8 +608,8 @@ def crossvit_18_240(pretrained=False, **kwargs) -> CrossVit:
     model_args = dict(
         img_scale=(1.0, 224 / 240), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],
-        num_heads=[7, 7], mlp_ratio=[3, 3, 1], **kwargs)
-    model = _create_crossvit(variant='crossvit_18_240', pretrained=pretrained, **dict(model_args, **kwargs))
+        num_heads=[7, 7], mlp_ratio=[3, 3, 1], **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_crossvit(variant='crossvit_18_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -613,7 +618,7 @@     model_args = dict(
         img_scale=(1.0, 224 / 240), patch_size=[12, 16], embed_dim=[128, 256], depth=[[1, 3, 0], [1, 3, 0], [1, 3, 0]],
         num_heads=[4, 4], mlp_ratio=[3, 3, 1], multi_conv=True)
-    model = _create_crossvit(variant='crossvit_9_dagger_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_9_dagger_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -622,7 +627,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],
         num_heads=[6, 6], mlp_ratio=[3, 3, 1], multi_conv=True)
-    model = _create_crossvit(variant='crossvit_15_dagger_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_15_dagger_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -631,7 +636,7 @@     model_args = dict(
         img_scale=(1.0, 384/408), patch_size=[12, 16], embed_dim=[192, 384], depth=[[1, 5, 0], [1, 5, 0], [1, 5, 0]],
         num_heads=[6, 6], mlp_ratio=[3, 3, 1], multi_conv=True)
-    model = _create_crossvit(variant='crossvit_15_dagger_408', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_15_dagger_408', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -640,7 +645,7 @@     model_args = dict(
         img_scale=(1.0, 224/240), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],
         num_heads=[7, 7], mlp_ratio=[3, 3, 1], multi_conv=True)
-    model = _create_crossvit(variant='crossvit_18_dagger_240', pretrained=pretrained, **dict(model_args, **kwargs))
+    model = _create_crossvit(variant='crossvit_18_dagger_240', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -649,5 +654,5 @@     model_args = dict(
         img_scale=(1.0, 384/408), patch_size=[12, 16], embed_dim=[224, 448], depth=[[1, 6, 0], [1, 6, 0], [1, 6, 0]],
         num_heads=[7, 7], mlp_ratio=[3, 3, 1], multi_conv=True)
-    model = _create_crossvit(variant='crossvit_18_dagger_408', pretrained=pretrained, **dict(model_args, **kwargs))
-    return model
+    model = _create_crossvit(variant='crossvit_18_dagger_408', pretrained=pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    return model
