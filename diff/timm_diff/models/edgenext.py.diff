--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ EdgeNeXt
 
 Paper: `EdgeNeXt: Efficiently Amalgamated CNN-Transformer Architecture for Mobile Vision Applications`
@@ -11,9 +16,8 @@ from functools import partial
 from typing import List, Optional, Tuple, Type, Union
 
-import torch
-import torch.nn.functional as F
-from torch import nn
+# import torch
+# from torch import nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import (
@@ -37,7 +41,7 @@ 
 
 @register_notrace_module  # reason: FX can't symbolically trace torch.arange in forward method
-class PositionalEncodingFourier(nn.Module):
+class PositionalEncodingFourier(msnn.Cell):
     def __init__(
             self,
             hidden_dim: int = 32,
@@ -54,34 +58,34 @@         self.hidden_dim = hidden_dim
         self.dim = dim
 
-    def forward(self, shape: Tuple[int, int, int]):
+    def construct(self, shape: Tuple[int, int, int]):
         device = self.token_projection.weight.device
         dtype = self.token_projection.weight.dtype
-        inv_mask = ~torch.zeros(shape).to(device=device, dtype=torch.bool)
-        y_embed = inv_mask.cumsum(1, dtype=torch.float32)
-        x_embed = inv_mask.cumsum(2, dtype=torch.float32)
+        inv_mask = ~mint.zeros(shape).to(device=device, dtype=ms.bool)
+        y_embed = inv_mask.cumsum(1, dtype=ms.float32)
+        x_embed = inv_mask.cumsum(2, dtype=ms.float32)
         eps = 1e-6
         y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale
         x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale
 
-        dim_t = torch.arange(self.hidden_dim, dtype=torch.int64, device=device).to(torch.float32)
-        dim_t = self.temperature ** (2 * torch.div(dim_t, 2, rounding_mode='floor') / self.hidden_dim)
+        dim_t = mint.arange(self.hidden_dim, dtype = ms.int64).to(ms.float32)  # 'torch.arange':没有对应的mindspore参数 'device' (position 6);
+        dim_t = self.temperature ** (2 * mint.div(dim_t, 2, rounding_mode = 'floor') / self.hidden_dim)
 
         pos_x = x_embed[:, :, :, None] / dim_t
         pos_y = y_embed[:, :, :, None] / dim_t
-        pos_x = torch.stack(
+        pos_x = mint.stack(
             (pos_x[:, :, :, 0::2].sin(),
-             pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)
-        pos_y = torch.stack(
+             pos_x[:, :, :, 1::2].cos()), dim = 4).flatten(3)
+        pos_y = mint.stack(
             (pos_y[:, :, :, 0::2].sin(),
-             pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)
-        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)
+             pos_y[:, :, :, 1::2].cos()), dim = 4).flatten(3)
+        pos = mint.cat((pos_y, pos_x), dim = 3).permute(0, 3, 1, 2)
         pos = self.token_projection(pos.to(dtype))
 
         return pos
 
 
-class ConvBlock(nn.Module):
+class ConvBlock(msnn.Cell):
     def __init__(
             self,
             dim: int,
@@ -118,10 +122,10 @@             act_layer=act_layer,
             **dd,
         )
-        self.gamma = nn.Parameter(ls_init_value * torch.ones(dim_out, **dd)) if ls_init_value > 0 else None
-        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x):
+        self.gamma = ms.Parameter(ls_init_value * mint.ones(dim_out, **dd)) if ls_init_value > 0 else None
+        self.drop_path = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x):
         shortcut = x
         x = self.conv_dw(x)
         if self.shortcut_after_dw:
@@ -138,7 +142,7 @@         return x
 
 
-class CrossCovarianceAttn(nn.Module):
+class CrossCovarianceAttn(msnn.Cell):
     def __init__(
             self,
             dim: int,
@@ -152,20 +156,20 @@         dd = {'device': device, 'dtype': dtype}
         super().__init__()
         self.num_heads = num_heads
-        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1, **dd))
+        self.temperature = ms.Parameter(mint.ones(num_heads, 1, 1, **dd))
 
         self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias, **dd)
         self.attn_drop = nn.Dropout(attn_drop)
         self.proj = nn.Linear(dim, dim, **dd)
         self.proj_drop = nn.Dropout(proj_drop)
 
-    def forward(self, x):
+    def construct(self, x):
         B, N, C = x.shape
         qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, -1).permute(2, 0, 3, 4, 1)
         q, k, v = qkv.unbind(0)
 
         # NOTE, this is NOT spatial attn, q, k, v are B, num_heads, C, L -->  C x C attn map
-        attn = (F.normalize(q, dim=-1) @ F.normalize(k, dim=-1).transpose(-2, -1)) * self.temperature
+        attn = (nn.functional.normalize(q, dim = -1) @ mint.transpose(-2, -1)) * self.temperature
         attn = attn.softmax(dim=-1)
         attn = self.attn_drop(attn)
         x = (attn @ v)
@@ -180,7 +184,7 @@         return {'temperature'}
 
 
-class SplitTransposeBlock(nn.Module):
+class SplitTransposeBlock(msnn.Cell):
     def __init__(
             self,
             dim: int,
@@ -208,13 +212,13 @@         convs = []
         for i in range(self.num_scales):
             convs.append(create_conv2d(width, width, kernel_size=3, depthwise=True, bias=conv_bias, **dd))
-        self.convs = nn.ModuleList(convs)
+        self.convs = msnn.CellList(convs)
 
         self.pos_embd = None
         if use_pos_emb:
             self.pos_embd = PositionalEncodingFourier(dim=dim, **dd)
         self.norm_xca = norm_layer(dim, **dd)
-        self.gamma_xca = nn.Parameter(ls_init_value * torch.ones(dim, **dd)) if ls_init_value > 0 else None
+        self.gamma_xca = ms.Parameter(ls_init_value * mint.ones(dim, **dd)) if ls_init_value > 0 else None
         self.xca = CrossCovarianceAttn(
             dim,
             num_heads=num_heads,
@@ -231,10 +235,10 @@             act_layer=act_layer,
             **dd,
         )
-        self.gamma = nn.Parameter(ls_init_value * torch.ones(dim, **dd)) if ls_init_value > 0 else None
-        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x):
+        self.gamma = ms.Parameter(ls_init_value * mint.ones(dim, **dd)) if ls_init_value > 0 else None
+        self.drop_path = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x):
         shortcut = x
 
         # scales code re-written for torchscript as per my res2net fixes -rw
@@ -248,7 +252,7 @@             sp = conv(sp)
             spo.append(sp)
         spo.append(spx[-1])
-        x = torch.cat(spo, 1)
+        x = mint.cat(spo, 1)
 
         # XCA
         B, C, H, W = x.shape
@@ -270,7 +274,7 @@         return x
 
 
-class EdgeNeXtStage(nn.Module):
+class EdgeNeXtStage(msnn.Cell):
     def __init__(
             self,
             in_chs: int,
@@ -298,12 +302,13 @@         self.grad_checkpointing = False
 
         if downsample_block or stride == 1:
-            self.downsample = nn.Identity()
+            self.downsample = msnn.Identity()
         else:
-            self.downsample = nn.Sequential(
+            self.downsample = msnn.SequentialCell(
+                [
                 norm_layer(in_chs, **dd),
                 nn.Conv2d(in_chs, out_chs, kernel_size=2, stride=2, bias=conv_bias, **dd)
-            )
+            ])
             in_chs = out_chs
 
         stage_blocks = []
@@ -341,9 +346,11 @@                     )
                 )
             in_chs = out_chs
-        self.blocks = nn.Sequential(*stage_blocks)
-
-    def forward(self, x):
+        self.blocks = msnn.SequentialCell([
+            stage_blocks
+        ])
+
+    def construct(self, x):
         x = self.downsample(x)
         if self.grad_checkpointing and not torch.jit.is_scripting():
             x = checkpoint_seq(self.blocks, x)
@@ -352,7 +359,7 @@         return x
 
 
-class EdgeNeXt(nn.Module):
+class EdgeNeXt(msnn.Cell):
     def __init__(
             self,
             in_chans: int = 3,
@@ -389,15 +396,17 @@ 
         assert stem_type in ('patch', 'overlap')
         if stem_type == 'patch':
-            self.stem = nn.Sequential(
+            self.stem = msnn.SequentialCell(
+                [
                 nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4, bias=conv_bias, **dd,),
-                norm_layer(dims[0], **dd),
-            )
+                norm_layer(dims[0], **dd)
+            ])
         else:
-            self.stem = nn.Sequential(
+            self.stem = msnn.SequentialCell(
+                [
                 nn.Conv2d(in_chans, dims[0], kernel_size=9, stride=4, padding=9 // 2, bias=conv_bias, **dd),
-                norm_layer(dims[0], **dd),
-            )
+                norm_layer(dims[0], **dd)
+            ])
 
         curr_stride = 4
         stages = []
@@ -431,7 +440,9 @@             in_chs = dims[i]
             self.feature_info += [dict(num_chs=in_chs, reduction=curr_stride, module=f'stages.{i}')]
 
-        self.stages = nn.Sequential(*stages)
+        self.stages = msnn.SequentialCell([
+            stages
+        ])
 
         self.num_features = self.head_hidden_size = dims[-1]
         if head_norm_first:
@@ -444,7 +455,7 @@                 **dd,
             )
         else:
-            self.norm_pre = nn.Identity()
+            self.norm_pre = msnn.Identity()
             self.head = NormMlpClassifierHead(
                 self.num_features,
                 num_classes,
@@ -472,6 +483,7 @@         for s in self.stages:
             s.grad_checkpointing = enable
 
+    # 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     @torch.jit.ignore
     def get_classifier(self) -> nn.Module:
         return self.head.fc
@@ -482,7 +494,7 @@ 
     def forward_intermediates(
             self,
-            x: torch.Tensor,
+            x: ms.Tensor,
             indices: Optional[Union[int, List[int]]] = None,
             norm: bool = False,
             stop_early: bool = False,
@@ -541,7 +553,7 @@         take_indices, max_index = feature_take_indices(len(self.stages), indices)
         self.stages = self.stages[:max_index + 1]  # truncate blocks w/ stem as idx 0
         if prune_norm:
-            self.norm_pre = nn.Identity()
+            self.norm_pre = msnn.Identity()
         if prune_head:
             self.reset_classifier(0, '')
         return take_indices
@@ -555,7 +567,7 @@     def forward_head(self, x, pre_logits: bool = False):
         return self.head(x, pre_logits=True) if pre_logits else self.head(x)
 
-    def forward(self, x):
+    def construct(self, x):
         x = self.forward_features(x)
         x = self.forward_head(x)
         return x
@@ -565,10 +577,10 @@     if isinstance(module, nn.Conv2d):
         trunc_normal_tf_(module.weight, std=.02)
         if module.bias is not None:
-            nn.init.zeros_(module.bias)
+            nn.init.zeros_(module.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     elif isinstance(module, nn.Linear):
         trunc_normal_tf_(module.weight, std=.02)
-        nn.init.zeros_(module.bias)
+        nn.init.zeros_(module.bias)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if name and 'head.' in name:
             module.weight.data.mul_(head_init_scale)
             module.bias.data.mul_(head_init_scale)
