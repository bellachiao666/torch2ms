--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ HRNet
 
 Copied from https://github.com/HRNet/HRNet-Image-Classification
@@ -11,8 +16,8 @@ import logging
 from typing import Dict, List, Type, Optional, Tuple
 
-import torch
-import torch.nn as nn
+# import torch
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import create_classifier
@@ -354,7 +359,7 @@ )
 
 
-class HighResolutionModule(nn.Module):
+class HighResolutionModule(msnn.Cell):
     def __init__(
             self,
             num_branches: int,
@@ -391,7 +396,7 @@             **dd,
         )
         self.fuse_layers = self._make_fuse_layers(**dd)
-        self.fuse_act = nn.ReLU(False)
+        self.fuse_act = nn.ReLU()  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
 
     def _check_branches(self, num_branches, block_types, num_blocks, num_in_chs, num_channels):
         error_msg = ''
@@ -409,7 +414,8 @@         dd = {'device': device, 'dtype': dtype}
         downsample = None
         if stride != 1 or self.num_in_chs[branch_index] != num_channels[branch_index] * block_type.expansion:
-            downsample = nn.Sequential(
+            downsample = msnn.SequentialCell(
+                [
                 nn.Conv2d(
                     self.num_in_chs[branch_index],
                     num_channels[branch_index] * block_type.expansion,
@@ -418,15 +424,17 @@                     bias=False,
                     **dd,
                 ),
-                nn.BatchNorm2d(num_channels[branch_index] * block_type.expansion, momentum=_BN_MOMENTUM, **dd),
-            )
+                nn.BatchNorm2d(num_channels[branch_index] * block_type.expansion, momentum=_BN_MOMENTUM, **dd)
+            ])
 
         layers = [block_type(self.num_in_chs[branch_index], num_channels[branch_index], stride, downsample, **dd)]
         self.num_in_chs[branch_index] = num_channels[branch_index] * block_type.expansion
         for i in range(1, num_blocks[branch_index]):
             layers.append(block_type(self.num_in_chs[branch_index], num_channels[branch_index], **dd))
 
-        return nn.Sequential(*layers)
+        return msnn.SequentialCell([
+            layers
+        ])
 
     def _make_branches(self, num_branches, block_type, num_blocks, num_channels, device=None, dtype=None):
         dd = {'device': device, 'dtype': dtype}
@@ -434,12 +442,12 @@         for i in range(num_branches):
             branches.append(self._make_one_branch(i, block_type, num_blocks, num_channels, **dd))
 
-        return nn.ModuleList(branches)
+        return msnn.CellList(branches)
 
     def _make_fuse_layers(self, device=None, dtype=None):
         dd = {'device': device, 'dtype': dtype}
         if self.num_branches == 1:
-            return nn.Identity()
+            return msnn.Identity()
 
         num_branches = self.num_branches
         num_in_chs = self.num_in_chs
@@ -448,37 +456,43 @@             fuse_layer = []
             for j in range(num_branches):
                 if j > i:
-                    fuse_layer.append(nn.Sequential(
+                    fuse_layer.append(msnn.SequentialCell(
+                        [
                         nn.Conv2d(num_in_chs[j], num_in_chs[i], 1, 1, 0, bias=False, **dd),
                         nn.BatchNorm2d(num_in_chs[i], momentum=_BN_MOMENTUM, **dd),
-                        nn.Upsample(scale_factor=2 ** (j - i), mode='nearest')))
+                        nn.Upsample(scale_factor = 2 ** (j - i), mode = 'nearest')
+                    ]))
                 elif j == i:
-                    fuse_layer.append(nn.Identity())
+                    fuse_layer.append(msnn.Identity())
                 else:
                     conv3x3s = []
                     for k in range(i - j):
                         if k == i - j - 1:
                             num_out_chs_conv3x3 = num_in_chs[i]
-                            conv3x3s.append(nn.Sequential(
+                            conv3x3s.append(msnn.SequentialCell(
+                                [
                                 nn.Conv2d(num_in_chs[j], num_out_chs_conv3x3, 3, 2, 1, bias=False, **dd),
                                 nn.BatchNorm2d(num_out_chs_conv3x3, momentum=_BN_MOMENTUM, **dd)
-                            ))
+                            ]))
                         else:
                             num_out_chs_conv3x3 = num_in_chs[j]
-                            conv3x3s.append(nn.Sequential(
+                            conv3x3s.append(msnn.SequentialCell(
+                                [
                                 nn.Conv2d(num_in_chs[j], num_out_chs_conv3x3, 3, 2, 1, bias=False, **dd),
                                 nn.BatchNorm2d(num_out_chs_conv3x3, momentum=_BN_MOMENTUM, **dd),
-                                nn.ReLU(False)
-                            ))
-                    fuse_layer.append(nn.Sequential(*conv3x3s))
-            fuse_layers.append(nn.ModuleList(fuse_layer))
-
-        return nn.ModuleList(fuse_layers)
+                                nn.ReLU()
+                            ]))  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
+                    fuse_layer.append(msnn.SequentialCell([
+                        conv3x3s
+                    ]))
+            fuse_layers.append(msnn.CellList(fuse_layer))
+
+        return msnn.CellList(fuse_layers)
 
     def get_num_in_chs(self):
         return self.num_in_chs
 
-    def forward(self, x: List[torch.Tensor]) -> List[torch.Tensor]:
+    def construct(self, x: List[torch.Tensor]) -> List[torch.Tensor]:
         if self.num_branches == 1:
             return [self.branches[0](x[0])]
 
@@ -497,7 +511,7 @@         return x_fuse
 
 
-class SequentialList(nn.Sequential):
+class SequentialList(msnn.SequentialCell):
 
     def __init__(self, *args):
         super().__init__(*args)
@@ -519,8 +533,8 @@ 
 
 @torch.jit.interface
-class ModuleInterface(torch.nn.Module):
-    def forward(self, input: torch.Tensor) -> torch.Tensor: # `input` has a same name in Sequential forward
+class ModuleInterface(msnn.Cell):
+    def construct(self, input: ms.Tensor) -> ms.Tensor: # `input` has a same name in Sequential forward
         pass
 
 
@@ -530,7 +544,7 @@ }
 
 
-class HighResolutionNet(nn.Module):
+class HighResolutionNet(msnn.Cell):
 
     def __init__(
             self,
@@ -554,10 +568,10 @@         stem_width = cfg['stem_width']
         self.conv1 = nn.Conv2d(in_chans, stem_width, kernel_size=3, stride=2, padding=1, bias=False, **dd)
         self.bn1 = nn.BatchNorm2d(stem_width, momentum=_BN_MOMENTUM, **dd)
-        self.act1 = nn.ReLU(inplace=True)
+        self.act1 = nn.ReLU()  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
         self.conv2 = nn.Conv2d(stem_width, 64, kernel_size=3, stride=2, padding=1, bias=False, **dd)
         self.bn2 = nn.BatchNorm2d(64, momentum=_BN_MOMENTUM, **dd)
-        self.act2 = nn.ReLU(inplace=True)
+        self.act2 = nn.ReLU()  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
 
         self.stage1_cfg = cfg['stage1']
         num_channels = self.stage1_cfg['num_channels'][0]
@@ -612,9 +626,9 @@             else:
                 self.num_features = self.head_hidden_size = 256
                 self.incre_modules = None
-            self.global_pool = nn.Identity()
-            self.head_drop = nn.Identity()
-            self.classifier = nn.Identity()
+            self.global_pool = msnn.Identity()
+            self.head_drop = msnn.Identity()
+            self.classifier = msnn.Identity()
 
         curr_stride = 2
         # module names aren't actually valid here, hook or FeatureNet based extraction would not work
@@ -636,7 +650,7 @@         incre_modules = []
         for i, channels in enumerate(pre_stage_channels):
             incre_modules.append(self._make_layer(head_block_type, channels, self.head_channels[i], 1, stride=1, **dd))
-        incre_modules = nn.ModuleList(incre_modules)
+        incre_modules = msnn.CellList(incre_modules)
         if incre_only:
             return incre_modules, None, None
 
@@ -645,7 +659,8 @@         for i in range(len(pre_stage_channels) - 1):
             in_channels = self.head_channels[i] * head_block_type.expansion
             out_channels = self.head_channels[i + 1] * head_block_type.expansion
-            downsamp_module = nn.Sequential(
+            downsamp_module = msnn.SequentialCell(
+                [
                 nn.Conv2d(
                     in_channels=in_channels,
                     out_channels=out_channels,
@@ -656,12 +671,13 @@                     **dd,
                 ),
                 nn.BatchNorm2d(out_channels, momentum=_BN_MOMENTUM, **dd),
-                nn.ReLU(inplace=True)
-            )
+                nn.ReLU()
+            ])  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
             downsamp_modules.append(downsamp_module)
-        downsamp_modules = nn.ModuleList(downsamp_modules)
-
-        final_layer = nn.Sequential(
+        downsamp_modules = msnn.CellList(downsamp_modules)
+
+        final_layer = msnn.SequentialCell(
+            [
             nn.Conv2d(
                 in_channels=self.head_channels[3] * head_block_type.expansion,
                 out_channels=self.num_features,
@@ -672,8 +688,8 @@                 **dd,
             ),
             nn.BatchNorm2d(self.num_features, momentum=_BN_MOMENTUM, **dd),
-            nn.ReLU(inplace=True)
-        )
+            nn.ReLU()
+        ])  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
 
         return incre_modules, downsamp_modules, final_layer
 
@@ -686,40 +702,49 @@         for i in range(num_branches_cur):
             if i < num_branches_pre:
                 if num_channels_cur_layer[i] != num_channels_pre_layer[i]:
-                    transition_layers.append(nn.Sequential(
+                    transition_layers.append(msnn.SequentialCell(
+                        [
                         nn.Conv2d(num_channels_pre_layer[i], num_channels_cur_layer[i], 3, 1, 1, bias=False, **dd),
                         nn.BatchNorm2d(num_channels_cur_layer[i], momentum=_BN_MOMENTUM, **dd),
-                        nn.ReLU(inplace=True)))
+                        nn.ReLU()
+                    ]))  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
                 else:
-                    transition_layers.append(nn.Identity())
+                    transition_layers.append(msnn.Identity())
             else:
                 conv3x3s = []
                 for j in range(i + 1 - num_branches_pre):
                     _in_chs = num_channels_pre_layer[-1]
                     _out_chs = num_channels_cur_layer[i] if j == i - num_branches_pre else _in_chs
-                    conv3x3s.append(nn.Sequential(
+                    conv3x3s.append(msnn.SequentialCell(
+                        [
                         nn.Conv2d(_in_chs, _out_chs, 3, 2, 1, bias=False, **dd),
                         nn.BatchNorm2d(_out_chs, momentum=_BN_MOMENTUM, **dd),
-                        nn.ReLU(inplace=True)))
-                transition_layers.append(nn.Sequential(*conv3x3s))
-
-        return nn.ModuleList(transition_layers)
+                        nn.ReLU()
+                    ]))  # 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
+                transition_layers.append(msnn.SequentialCell([
+                    conv3x3s
+                ]))
+
+        return msnn.CellList(transition_layers)
 
     def _make_layer(self, block_type, inplanes, planes, block_types, stride=1, device=None, dtype=None):
         dd = {'device': device, 'dtype': dtype}
         downsample = None
         if stride != 1 or inplanes != planes * block_type.expansion:
-            downsample = nn.Sequential(
+            downsample = msnn.SequentialCell(
+                [
                 nn.Conv2d(inplanes, planes * block_type.expansion, kernel_size=1, stride=stride, bias=False, **dd),
-                nn.BatchNorm2d(planes * block_type.expansion, momentum=_BN_MOMENTUM, **dd),
-            )
+                nn.BatchNorm2d(planes * block_type.expansion, momentum=_BN_MOMENTUM, **dd)
+            ])
 
         layers = [block_type(inplanes, planes, stride, downsample, **dd)]
         inplanes = planes * block_type.expansion
         for i in range(1, block_types):
             layers.append(block_type(inplanes, planes, **dd))
 
-        return nn.Sequential(*layers)
+        return msnn.SequentialCell([
+            layers
+        ])
 
     def _make_stage(self, layer_config, num_in_chs, multi_scale_output=True, device=None, dtype=None):
         num_modules = layer_config['num_modules']
@@ -753,10 +778,10 @@         for m in self.modules():
             if isinstance(m, nn.Conv2d):
                 nn.init.kaiming_normal_(
-                    m.weight, mode='fan_out', nonlinearity='relu')
+                    m.weight, mode='fan_out', nonlinearity='relu')  # 'torch.nn.init.kaiming_normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.BatchNorm2d):
-                nn.init.constant_(m.weight, 1)
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.weight, 1)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     @torch.jit.ignore
     def group_matcher(self, coarse=False):
@@ -774,6 +799,7 @@     def set_grad_checkpointing(self, enable=True):
         assert not enable, "gradient checkpointing not supported"
 
+    # 类型标注 'torch.nn.Module' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     @torch.jit.ignore
     def get_classifier(self) -> nn.Module:
         return self.classifier
@@ -827,7 +853,7 @@         x = self.head_drop(x)
         return x if pre_logits else self.classifier(x)
 
-    def forward(self, x):
+    def construct(self, x):
         y = self.forward_features(x)
         x = self.forward_head(y)
         return x
