--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """PyTorch ResNet
 
 This started as a copy of https://github.com/pytorch/vision 'resnet.py' (BSD-3-Clause) with
@@ -11,9 +16,8 @@ from functools import partial
 from typing import Any, Dict, List, Optional, Tuple, Type, Union
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import DropBlock2d, DropPath, AvgPool2dSame, BlurPool2d, LayerType, create_attn, \
@@ -31,7 +35,7 @@     return padding
 
 
-class BasicBlock(nn.Module):
+class BasicBlock(msnn.Cell):
     """Basic residual block for ResNet.
 
     This is the standard residual block used in ResNet-18 and ResNet-34.
@@ -43,18 +47,18 @@             inplanes: int,
             planes: int,
             stride: int = 1,
-            downsample: Optional[nn.Module] = None,
+            downsample: Optional[msnn.Cell] = None,
             cardinality: int = 1,
             base_width: int = 64,
             reduce_first: int = 1,
             dilation: int = 1,
             first_dilation: Optional[int] = None,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            norm_layer: Type[nn.Module] = nn.BatchNorm2d,
-            attn_layer: Optional[Type[nn.Module]] = None,
-            aa_layer: Optional[Type[nn.Module]] = None,
-            drop_block: Optional[Type[nn.Module]] = None,
-            drop_path: Optional[nn.Module] = None,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            norm_layer: Type[msnn.Cell] = nn.BatchNorm2d,
+            attn_layer: Optional[Type[msnn.Cell]] = None,
+            aa_layer: Optional[Type[msnn.Cell]] = None,
+            drop_block: Optional[Type[msnn.Cell]] = None,
+            drop_path: Optional[msnn.Cell] = None,
             device=None,
             dtype=None,
     ) -> None:
@@ -95,11 +99,11 @@             dilation=first_dilation,
             bias=False,
             **dd,
-        )
-        self.bn1 = norm_layer(first_planes, **dd)
-        self.drop_block = drop_block() if drop_block is not None else nn.Identity()
+        )  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn1 = norm_layer(first_planes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_block = drop_block() if drop_block is not None else msnn.Identity()
         self.act1 = act_layer(inplace=True)
-        self.aa = create_aa(aa_layer, channels=first_planes, stride=stride, enable=use_aa, **dd)
+        self.aa = create_aa(aa_layer, channels=first_planes, stride=stride, enable=use_aa, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.conv2 = nn.Conv2d(
             first_planes,
@@ -109,10 +113,10 @@             dilation=dilation,
             bias=False,
             **dd,
-        )
-        self.bn2 = norm_layer(outplanes, **dd)
-
-        self.se = create_attn(attn_layer, outplanes, **dd)
+        )  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn2 = norm_layer(outplanes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        self.se = create_attn(attn_layer, outplanes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.act2 = act_layer(inplace=True)
         self.downsample = downsample
@@ -123,9 +127,9 @@     def zero_init_last(self) -> None:
         """Initialize the last batch norm layer weights to zero for better convergence."""
         if getattr(self.bn2, 'weight', None) is not None:
-            nn.init.zeros_(self.bn2.weight)
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+            nn.init.zeros_(self.bn2.weight)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         shortcut = x
 
         x = self.conv1(x)
@@ -151,7 +155,7 @@         return x
 
 
-class Bottleneck(nn.Module):
+class Bottleneck(msnn.Cell):
     """Bottleneck residual block for ResNet.
 
     This is the bottleneck block used in ResNet-50, ResNet-101, and ResNet-152.
@@ -163,18 +167,18 @@             inplanes: int,
             planes: int,
             stride: int = 1,
-            downsample: Optional[nn.Module] = None,
+            downsample: Optional[msnn.Cell] = None,
             cardinality: int = 1,
             base_width: int = 64,
             reduce_first: int = 1,
             dilation: int = 1,
             first_dilation: Optional[int] = None,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            norm_layer: Type[nn.Module] = nn.BatchNorm2d,
-            attn_layer: Optional[Type[nn.Module]] = None,
-            aa_layer: Optional[Type[nn.Module]] = None,
-            drop_block: Optional[Type[nn.Module]] = None,
-            drop_path: Optional[nn.Module] = None,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            norm_layer: Type[msnn.Cell] = nn.BatchNorm2d,
+            attn_layer: Optional[Type[msnn.Cell]] = None,
+            aa_layer: Optional[Type[msnn.Cell]] = None,
+            drop_block: Optional[Type[msnn.Cell]] = None,
+            drop_path: Optional[msnn.Cell] = None,
             device=None,
             dtype=None,
     ) -> None:
@@ -205,8 +209,8 @@         first_dilation = first_dilation or dilation
         use_aa = aa_layer is not None and (stride == 2 or first_dilation != dilation)
 
-        self.conv1 = nn.Conv2d(inplanes, first_planes, kernel_size=1, bias=False, **dd)
-        self.bn1 = norm_layer(first_planes, **dd)
+        self.conv1 = nn.Conv2d(inplanes, first_planes, kernel_size=1, bias=False, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn1 = norm_layer(first_planes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.act1 = act_layer(inplace=True)
 
         self.conv2 = nn.Conv2d(
@@ -219,16 +223,16 @@             groups=cardinality,
             bias=False,
             **dd,
-        )
-        self.bn2 = norm_layer(width, **dd)
-        self.drop_block = drop_block() if drop_block is not None else nn.Identity()
+        )  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn2 = norm_layer(width, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_block = drop_block() if drop_block is not None else msnn.Identity()
         self.act2 = act_layer(inplace=True)
-        self.aa = create_aa(aa_layer, channels=width, stride=stride, enable=use_aa, **dd)
-
-        self.conv3 = nn.Conv2d(width, outplanes, kernel_size=1, bias=False, **dd)
-        self.bn3 = norm_layer(outplanes, **dd)
-
-        self.se = create_attn(attn_layer, outplanes, **dd)
+        self.aa = create_aa(aa_layer, channels=width, stride=stride, enable=use_aa, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        self.conv3 = nn.Conv2d(width, outplanes, kernel_size=1, bias=False, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn3 = norm_layer(outplanes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        self.se = create_attn(attn_layer, outplanes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.act3 = act_layer(inplace=True)
         self.downsample = downsample
@@ -239,9 +243,9 @@     def zero_init_last(self) -> None:
         """Initialize the last batch norm layer weights to zero for better convergence."""
         if getattr(self.bn3, 'weight', None) is not None:
-            nn.init.zeros_(self.bn3.weight)
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+            nn.init.zeros_(self.bn3.weight)  # 'torch.nn.init.zeros_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         shortcut = x
 
         x = self.conv1(x)
@@ -278,17 +282,17 @@         stride: int = 1,
         dilation: int = 1,
         first_dilation: Optional[int] = None,
-        norm_layer: Optional[Type[nn.Module]] = None,
+        norm_layer: Optional[Type[msnn.Cell]] = None,
         device=None,
         dtype=None,
-) -> nn.Module:
+) -> msnn.Cell:
     dd = {'device': device, 'dtype': dtype}
     norm_layer = norm_layer or nn.BatchNorm2d
     kernel_size = 1 if stride == 1 and dilation == 1 else kernel_size
     first_dilation = (first_dilation or dilation) if kernel_size > 1 else 1
     p = get_padding(kernel_size, stride, first_dilation)
 
-    return nn.Sequential(*[
+    return msnn.SequentialCell(*[
         nn.Conv2d(
             in_channels,
             out_channels,
@@ -300,7 +304,7 @@             **dd
         ),
         norm_layer(out_channels, **dd)
-    ])
+    ])  # 存在 *args/**kwargs，需手动确认参数映射;; 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def downsample_avg(
@@ -310,24 +314,24 @@         stride: int = 1,
         dilation: int = 1,
         first_dilation: Optional[int] = None,
-        norm_layer: Optional[Type[nn.Module]] = None,
+        norm_layer: Optional[Type[msnn.Cell]] = None,
         device=None,
         dtype=None,
-) -> nn.Module:
+) -> msnn.Cell:
     dd = {'device': device, 'dtype': dtype}
     norm_layer = norm_layer or nn.BatchNorm2d
     avg_stride = stride if dilation == 1 else 1
     if stride == 1 and dilation == 1:
-        pool = nn.Identity()
+        pool = msnn.Identity()
     else:
         avg_pool_fn = AvgPool2dSame if avg_stride == 1 and dilation > 1 else nn.AvgPool2d
         pool = avg_pool_fn(2, avg_stride, ceil_mode=True, count_include_pad=False)
 
-    return nn.Sequential(*[
+    return msnn.SequentialCell(*[
         pool,
         nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False, **dd),
         norm_layer(out_channels, **dd)
-    ])
+    ])  # 存在 *args/**kwargs，需手动确认参数映射;; 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def drop_blocks(drop_prob: float = 0.) -> List[Optional[partial]]:
@@ -359,7 +363,7 @@         device=None,
         dtype=None,
         **kwargs,
-) -> Tuple[List[Tuple[str, nn.Module]], List[Dict[str, Any]]]:
+) -> Tuple[List[Tuple[str, msnn.Cell]], List[Dict[str, Any]]]:
     """Create ResNet stages with specified block configurations.
 
     Args:
@@ -405,10 +409,10 @@                 first_dilation=prev_dilation,
                 norm_layer=kwargs.get('norm_layer'),
                 **dd,
-            )
-            downsample = downsample_avg(**down_kwargs) if avg_down else downsample_conv(**down_kwargs)
-
-        block_kwargs = dict(reduce_first=reduce_first, dilation=dilation, drop_block=db, **kwargs)
+            )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+            downsample = downsample_avg(**down_kwargs) if avg_down else downsample_conv(**down_kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+        block_kwargs = dict(reduce_first=reduce_first, dilation=dilation, drop_block=db, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         blocks = []
         for block_idx in range(num_blocks):
             downsample = downsample if block_idx == 0 else None
@@ -423,18 +427,18 @@                 drop_path=DropPath(block_dpr) if block_dpr > 0. else None,
                 **block_kwargs,
                 **dd,
-            ))
+            ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             prev_dilation = dilation
             inplanes = planes * block_fn.expansion
             net_block_idx += 1
 
-        stages.append((stage_name, nn.Sequential(*blocks)))
+        stages.append((stage_name, msnn.SequentialCell(*blocks)))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         feature_info.append(dict(num_chs=inplanes, reduction=net_stride, module=stage_name))
 
     return stages, feature_info
 
 
-class ResNet(nn.Module):
+class ResNet(msnn.Cell):
     """ResNet / ResNeXt / SE-ResNeXt / SE-Net
 
     This class implements all variants of ResNet, ResNeXt, SE-ResNeXt, and SENet that
@@ -485,7 +489,7 @@             channels: Optional[Tuple[int, ...]] = (64, 128, 256, 512),
             act_layer: LayerType = nn.ReLU,
             norm_layer: LayerType = nn.BatchNorm2d,
-            aa_layer: Optional[Type[nn.Module]] = None,
+            aa_layer: Optional[Type[msnn.Cell]] = None,
             drop_rate: float = 0.0,
             drop_path_rate: float = 0.,
             drop_block_rate: float = 0.,
@@ -542,38 +546,38 @@             stem_chs = (stem_width, stem_width)
             if 'tiered' in stem_type:
                 stem_chs = (3 * (stem_width // 4), stem_width)
-            self.conv1 = nn.Sequential(*[
+            self.conv1 = msnn.SequentialCell(*[
                 nn.Conv2d(in_chans, stem_chs[0], 3, stride=2, padding=1, bias=False, **dd),
                 norm_layer(stem_chs[0], **dd),
                 act_layer(inplace=True),
                 nn.Conv2d(stem_chs[0], stem_chs[1], 3, stride=1, padding=1, bias=False, **dd),
                 norm_layer(stem_chs[1], **dd),
                 act_layer(inplace=True),
-                nn.Conv2d(stem_chs[1], inplanes, 3, stride=1, padding=1, bias=False, **dd)])
+                nn.Conv2d(stem_chs[1], inplanes, 3, stride=1, padding=1, bias=False, **dd)])  # 存在 *args/**kwargs，需手动确认参数映射;; 存在 *args/**kwargs，未转换，需手动确认参数映射;
         else:
-            self.conv1 = nn.Conv2d(in_chans, inplanes, kernel_size=7, stride=2, padding=3, bias=False, **dd)
-        self.bn1 = norm_layer(inplanes, **dd)
+            self.conv1 = nn.Conv2d(in_chans, inplanes, kernel_size=7, stride=2, padding=3, bias=False, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.bn1 = norm_layer(inplanes, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.act1 = act_layer(inplace=True)
         self.feature_info = [dict(num_chs=inplanes, reduction=2, module='act1')]
 
         # Stem pooling. The name 'maxpool' remains for weight compatibility.
         if replace_stem_pool:
-            self.maxpool = nn.Sequential(*filter(None, [
+            self.maxpool = msnn.SequentialCell(*filter(None, [
                 nn.Conv2d(inplanes, inplanes, 3, stride=1 if aa_layer else 2, padding=1, bias=False, **dd),
                 create_aa(aa_layer, channels=inplanes, stride=2, **dd) if aa_layer is not None else None,
                 norm_layer(inplanes, **dd),
                 act_layer(inplace=True),
-            ]))
+            ]))  # 存在 *args/**kwargs，需手动确认参数映射;; 存在 *args/**kwargs，未转换，需手动确认参数映射;
         else:
             if aa_layer is not None:
                 if issubclass(aa_layer, nn.AvgPool2d):
                     self.maxpool = aa_layer(2)
                 else:
-                    self.maxpool = nn.Sequential(*[
-                        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),
-                        aa_layer(channels=inplanes, stride=2, **dd)])
+                    self.maxpool = msnn.SequentialCell(*[
+                        nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),
+                        aa_layer(channels=inplanes, stride=2, **dd)])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             else:
-                self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)
+                self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)
 
         # Feature Blocks
         block_fns = to_ntuple(len(channels))(block)
@@ -595,18 +599,18 @@             drop_path_rate=drop_path_rate,
             **block_args,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         for stage in stage_modules:
-            self.add_module(*stage)  # layer1, layer2, etc
+            self.add_module(*stage)  # layer1, layer2, etc; 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.feature_info.extend(stage_feature_info)
 
         # Head (Pooling and Classifier)
         self.num_features = self.head_hidden_size = channels[-1] * block_fns[-1].expansion
-        self.global_pool, self.fc = create_classifier(self.num_features, self.num_classes, pool_type=global_pool, **dd)
+        self.global_pool, self.fc = create_classifier(self.num_features, self.num_classes, pool_type=global_pool, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         self.init_weights(zero_init_last=zero_init_last)
 
-    @torch.jit.ignore
+    @ms.jit
     def init_weights(self, zero_init_last: bool = True) -> None:
         """Initialize model weights.
 
@@ -615,13 +619,13 @@         """
         for n, m in self.named_modules():
             if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')  # 'torch.nn.init.kaiming_normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if zero_init_last:
             for m in self.modules():
                 if hasattr(m, 'zero_init_last'):
                     m.zero_init_last()
 
-    @torch.jit.ignore
+    @ms.jit
     def group_matcher(self, coarse: bool = False) -> Dict[str, str]:
         """Create regex patterns for parameter grouping.
 
@@ -634,7 +638,7 @@         matcher = dict(stem=r'^conv1|bn1|maxpool', blocks=r'^layer(\d+)' if coarse else r'^layer(\d+)\.(\d+)')
         return matcher
 
-    @torch.jit.ignore
+    @ms.jit
     def set_grad_checkpointing(self, enable: bool = True) -> None:
         """Enable or disable gradient checkpointing.
 
@@ -643,8 +647,8 @@         """
         self.grad_checkpointing = enable
 
-    @torch.jit.ignore
-    def get_classifier(self, name_only: bool = False) -> Union[str, nn.Module]:
+    @ms.jit
+    def get_classifier(self, name_only: bool = False) -> Union[str, msnn.Cell]:
         """Get the classifier module.
 
         Args:
@@ -667,13 +671,13 @@ 
     def forward_intermediates(
             self,
-            x: torch.Tensor,
+            x: ms.Tensor,
             indices: Optional[Union[int, List[int]]] = None,
             norm: bool = False,
             stop_early: bool = False,
             output_fmt: str = 'NCHW',
             intermediates_only: bool = False,
-    ) -> Union[List[torch.Tensor], Tuple[torch.Tensor, List[torch.Tensor]]]:
+    ) -> Union[List[ms.Tensor], Tuple[ms.Tensor, List[ms.Tensor]]]:
         """Forward features that returns intermediates.
 
         Args:
@@ -734,12 +738,12 @@         layer_names = ('layer1', 'layer2', 'layer3', 'layer4')
         layer_names = layer_names[max_index:]
         for n in layer_names:
-            setattr(self, n, nn.Identity())
+            setattr(self, n, msnn.Identity())
         if prune_head:
             self.reset_classifier(0, '')
         return take_indices
 
-    def forward_features(self, x: torch.Tensor) -> torch.Tensor:
+    def forward_features(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through feature extraction layers."""
         x = self.conv1(x)
         x = self.bn1(x)
@@ -755,7 +759,7 @@             x = self.layer4(x)
         return x
 
-    def forward_head(self, x: torch.Tensor, pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, x: ms.Tensor, pre_logits: bool = False) -> ms.Tensor:
         """Forward pass through classifier head.
 
         Args:
@@ -767,10 +771,10 @@         """
         x = self.global_pool(x)
         if self.drop_rate:
-            x = F.dropout(x, p=float(self.drop_rate), training=self.training)
+            x = nn.functional.dropout(x, p = float(self.drop_rate), training = self.training)
         return x if pre_logits else self.fc(x)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass."""
         x = self.forward_features(x)
         x = self.forward_head(x)
@@ -788,7 +792,7 @@     Returns:
         ResNet model instance.
     """
-    return build_model_with_cfg(ResNet, variant, pretrained, **kwargs)
+    return build_model_with_cfg(ResNet, variant, pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _cfg(url: str = '', **kwargs) -> Dict[str, Any]:
@@ -806,7 +810,7 @@ 
 def _tcfg(url: str = '', **kwargs) -> Dict[str, Any]:
     """Create a configuration with bicubic interpolation."""
-    return _cfg(url=url, **dict({'interpolation': 'bicubic'}, **kwargs))
+    return _cfg(url=url, **dict({'interpolation': 'bicubic'}, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _ttcfg(url: str = '', **kwargs) -> Dict[str, Any]:
@@ -814,7 +818,7 @@     return _cfg(url=url, **dict({
         'interpolation': 'bicubic', 'test_input_size': (3, 288, 288), 'test_crop_pct': 0.95,
         'origin_url': 'https://github.com/huggingface/pytorch-image-models',
-    }, **kwargs))
+    }, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _rcfg(url: str = '', **kwargs) -> Dict[str, Any]:
@@ -822,7 +826,7 @@     return _cfg(url=url, **dict({
         'interpolation': 'bicubic', 'crop_pct': 0.95, 'test_input_size': (3, 288, 288), 'test_crop_pct': 1.0,
         'origin_url': 'https://github.com/huggingface/pytorch-image-models', 'paper_ids': 'arXiv:2110.00476'
-    }, **kwargs))
+    }, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _r3cfg(url: str = '', **kwargs) -> Dict[str, Any]:
@@ -831,7 +835,7 @@         'interpolation': 'bicubic', 'input_size': (3, 160, 160), 'pool_size': (5, 5),
         'crop_pct': 0.95, 'test_input_size': (3, 224, 224), 'test_crop_pct': 0.95,
         'origin_url': 'https://github.com/huggingface/pytorch-image-models', 'paper_ids': 'arXiv:2110.00476',
-    }, **kwargs))
+    }, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _gcfg(url: str = '', **kwargs) -> Dict[str, Any]:
@@ -839,7 +843,7 @@     return _cfg(url=url, **dict({
         'interpolation': 'bicubic',
         'origin_url': 'https://cv.gluon.ai/model_zoo/classification.html',
-    }, **kwargs))
+    }, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 default_cfgs = generate_default_cfgs({
@@ -1477,7 +1481,7 @@     """Constructs a ResNet-10-T model.
     """
     model_args = dict(block=BasicBlock, layers=(1, 1, 1, 1), stem_width=32, stem_type='deep_tiered', avg_down=True)
-    return _create_resnet('resnet10t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet10t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1485,7 +1489,7 @@     """Constructs a ResNet-14-T model.
     """
     model_args = dict(block=Bottleneck, layers=(1, 1, 1, 1), stem_width=32, stem_type='deep_tiered', avg_down=True)
-    return _create_resnet('resnet14t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet14t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1493,7 +1497,7 @@     """Constructs a ResNet-18 model.
     """
     model_args = dict(block=BasicBlock, layers=(2, 2, 2, 2))
-    return _create_resnet('resnet18', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet18', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1501,7 +1505,7 @@     """Constructs a ResNet-18-D model.
     """
     model_args = dict(block=BasicBlock, layers=(2, 2, 2, 2), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet18d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet18d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1509,7 +1513,7 @@     """Constructs a ResNet-34 model.
     """
     model_args = dict(block=BasicBlock, layers=(3, 4, 6, 3))
-    return _create_resnet('resnet34', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet34', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1517,7 +1521,7 @@     """Constructs a ResNet-34-D model.
     """
     model_args = dict(block=BasicBlock, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet34d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet34d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1525,7 +1529,7 @@     """Constructs a ResNet-26 model.
     """
     model_args = dict(block=Bottleneck, layers=(2, 2, 2, 2))
-    return _create_resnet('resnet26', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet26', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1533,7 +1537,7 @@     """Constructs a ResNet-26-T model.
     """
     model_args = dict(block=Bottleneck, layers=(2, 2, 2, 2), stem_width=32, stem_type='deep_tiered', avg_down=True)
-    return _create_resnet('resnet26t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet26t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1541,7 +1545,7 @@     """Constructs a ResNet-26-D model.
     """
     model_args = dict(block=Bottleneck, layers=(2, 2, 2, 2), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet26d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet26d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1549,7 +1553,7 @@     """Constructs a ResNet-50 model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3))
-    return _create_resnet('resnet50', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet50', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1557,7 +1561,7 @@     """Constructs a ResNet-50-C model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep')
-    return _create_resnet('resnet50c', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet50c', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1565,7 +1569,7 @@     """Constructs a ResNet-50-D model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet50d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet50d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1573,7 +1577,7 @@     """Constructs a ResNet-50-S model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), stem_width=64, stem_type='deep')
-    return _create_resnet('resnet50s', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet50s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1581,7 +1585,7 @@     """Constructs a ResNet-50-T model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep_tiered', avg_down=True)
-    return _create_resnet('resnet50t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet50t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1589,7 +1593,7 @@     """Constructs a ResNet-101 model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3))
-    return _create_resnet('resnet101', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet101', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1597,7 +1601,7 @@     """Constructs a ResNet-101-C model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), stem_width=32, stem_type='deep')
-    return _create_resnet('resnet101c', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet101c', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1605,7 +1609,7 @@     """Constructs a ResNet-101-D model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet101d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet101d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1613,7 +1617,7 @@     """Constructs a ResNet-101-S model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), stem_width=64, stem_type='deep')
-    return _create_resnet('resnet101s', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet101s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1621,7 +1625,7 @@     """Constructs a ResNet-152 model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 8, 36, 3))
-    return _create_resnet('resnet152', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet152', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1629,7 +1633,7 @@     """Constructs a ResNet-152-C model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 8, 36, 3), stem_width=32, stem_type='deep')
-    return _create_resnet('resnet152c', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet152c', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1637,7 +1641,7 @@     """Constructs a ResNet-152-D model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 8, 36, 3), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet152d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet152d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1645,7 +1649,7 @@     """Constructs a ResNet-152-S model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 8, 36, 3), stem_width=64, stem_type='deep')
-    return _create_resnet('resnet152s', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet152s', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1653,7 +1657,7 @@     """Constructs a ResNet-200 model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 24, 36, 3))
-    return _create_resnet('resnet200', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet200', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1661,7 +1665,7 @@     """Constructs a ResNet-200-D model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 24, 36, 3), stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnet200d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet200d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1673,7 +1677,7 @@     channels, and in Wide ResNet-50-2 has 2048-1024-2048.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), base_width=128)
-    return _create_resnet('wide_resnet50_2', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('wide_resnet50_2', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1684,7 +1688,7 @@     convolutions is the same.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), base_width=128)
-    return _create_resnet('wide_resnet101_2', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('wide_resnet101_2', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1692,7 +1696,7 @@     """Constructs a ResNet-50 model w/ GroupNorm
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), norm_layer='groupnorm')
-    return _create_resnet('resnet50_gn', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnet50_gn', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1700,7 +1704,7 @@     """Constructs a ResNeXt50-32x4d model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), cardinality=32, base_width=4)
-    return _create_resnet('resnext50_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext50_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1710,7 +1714,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3),  cardinality=32, base_width=4,
         stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnext50d_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext50d_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1718,7 +1722,7 @@     """Constructs a ResNeXt-101 32x4d model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=4)
-    return _create_resnet('resnext101_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext101_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1726,7 +1730,7 @@     """Constructs a ResNeXt-101 32x8d model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=8)
-    return _create_resnet('resnext101_32x8d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext101_32x8d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1734,7 +1738,7 @@     """Constructs a ResNeXt-101 32x16d model
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=16)
-    return _create_resnet('resnext101_32x16d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext101_32x16d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1742,7 +1746,7 @@     """Constructs a ResNeXt-101 32x32d model
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=32)
-    return _create_resnet('resnext101_32x32d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext101_32x32d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1750,7 +1754,7 @@     """Constructs a ResNeXt101-64x4d model.
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), cardinality=64, base_width=4)
-    return _create_resnet('resnext101_64x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnext101_64x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1762,7 +1766,7 @@     model_args = dict(
         block=Bottleneck, layers=(2, 2, 2, 2), stem_width=32,
         stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet26t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet26t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1772,7 +1776,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet50d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet50d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1783,7 +1787,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet50d_pruned', pretrained, pruned=True, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet50d_pruned', pretrained, pruned=True, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1794,7 +1798,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32,
         stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet50t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet50t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1804,7 +1808,7 @@     model_args = dict(
         block=Bottleneck, layers=(1, 1, 11, 3), stem_width=32, avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnetlight', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnetlight', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1814,7 +1818,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet101d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet101d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1825,7 +1829,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet101d_pruned', pretrained, pruned=True, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet101d_pruned', pretrained, pruned=True, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1835,7 +1839,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 24, 36, 3), stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet200d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet200d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1845,7 +1849,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 30, 48, 8), stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnet269d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnet269d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1857,7 +1861,7 @@     model_args = dict(
         block=Bottleneck, layers=(2, 2, 2, 2), cardinality=32, base_width=4, stem_width=32,
         stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnext26t_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnext26t_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1869,25 +1873,25 @@     model_args = dict(
         block=Bottleneck, layers=(2, 2, 2, 2), cardinality=32, base_width=4, stem_width=32,
         stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='eca'))
-    return _create_resnet('ecaresnext50t_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('ecaresnext50t_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def seresnet18(pretrained: bool = False, **kwargs) -> ResNet:
     model_args = dict(block=BasicBlock, layers=(2, 2, 2, 2), block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet18', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet18', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def seresnet34(pretrained: bool = False, **kwargs) -> ResNet:
     model_args = dict(block=BasicBlock, layers=(3, 4, 6, 3), block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet34', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet34', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def seresnet50(pretrained: bool = False, **kwargs) -> ResNet:
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet50', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet50', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1895,19 +1899,19 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3),  stem_width=32, stem_type='deep_tiered',
         avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet50t', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet50t', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def seresnet101(pretrained: bool = False, **kwargs) -> ResNet:
     model_args = dict(block=Bottleneck, layers=(3, 4, 23, 3), block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet101', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet101', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def seresnet152(pretrained: bool = False, **kwargs) -> ResNet:
     model_args = dict(block=Bottleneck, layers=(3, 8, 36, 3), block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet152', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet152', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1915,7 +1919,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 8, 36, 3), stem_width=32, stem_type='deep',
         avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet152d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet152d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1925,7 +1929,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 24, 36, 3), stem_width=32, stem_type='deep',
         avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet200d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet200d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1935,7 +1939,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 30, 48, 8), stem_width=32, stem_type='deep',
         avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnet269d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnet269d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1947,7 +1951,7 @@     model_args = dict(
         block=Bottleneck, layers=(2, 2, 2, 2), cardinality=32, base_width=4, stem_width=32,
         stem_type='deep', avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext26d_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext26d_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1959,7 +1963,7 @@     model_args = dict(
         block=Bottleneck, layers=(2, 2, 2, 2), cardinality=32, base_width=4, stem_width=32,
         stem_type='deep_tiered', avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext26t_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext26t_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1967,7 +1971,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), cardinality=32, base_width=4,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext50_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext50_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1975,7 +1979,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=4,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext101_32x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext101_32x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1983,7 +1987,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=8,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext101_32x8d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext101_32x8d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -1992,7 +1996,7 @@         block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=8,
         stem_width=32, stem_type='deep', avg_down=True,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext101d_32x8d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext101d_32x8d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2000,7 +2004,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), cardinality=64, base_width=4,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnext101_64x4d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnext101_64x4d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2008,7 +2012,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 8, 36, 3), cardinality=64, base_width=4, stem_type='deep',
         down_kernel_size=3, block_reduce_first=2, block_args=dict(attn_layer='se'))
-    return _create_resnet('senet154', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('senet154', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2016,7 +2020,7 @@     """Constructs a ResNet-18 model with blur anti-aliasing
     """
     model_args = dict(block=BasicBlock, layers=(2, 2, 2, 2), aa_layer=BlurPool2d)
-    return _create_resnet('resnetblur18', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetblur18', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2024,7 +2028,7 @@     """Constructs a ResNet-50 model with blur anti-aliasing
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), aa_layer=BlurPool2d)
-    return _create_resnet('resnetblur50', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetblur50', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2034,7 +2038,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), aa_layer=BlurPool2d,
         stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnetblur50d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetblur50d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2044,7 +2048,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), aa_layer=BlurPool2d,
         stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnetblur101d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetblur101d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2053,7 +2057,7 @@     """
     model_args = dict(
         block=BasicBlock, layers=(3, 4, 6, 3),  aa_layer=nn.AvgPool2d, stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnetaa34d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetaa34d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2061,7 +2065,7 @@     """Constructs a ResNet-50 model with avgpool anti-aliasing
     """
     model_args = dict(block=Bottleneck, layers=(3, 4, 6, 3), aa_layer=nn.AvgPool2d)
-    return _create_resnet('resnetaa50', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetaa50', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2071,7 +2075,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), aa_layer=nn.AvgPool2d,
         stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnetaa50d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetaa50d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2081,7 +2085,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), aa_layer=nn.AvgPool2d,
         stem_width=32, stem_type='deep', avg_down=True)
-    return _create_resnet('resnetaa101d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetaa101d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2091,7 +2095,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), aa_layer=nn.AvgPool2d,
         stem_width=32, stem_type='deep', avg_down=True, block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnetaa50d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnetaa50d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2102,7 +2106,7 @@         block=Bottleneck, layers=(3, 4, 23, 3), cardinality=32, base_width=8,
         stem_width=32, stem_type='deep', avg_down=True, aa_layer=nn.AvgPool2d,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnextaa101d_32x8d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnextaa101d_32x8d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2113,7 +2117,7 @@         block=Bottleneck, layers=(3, 24, 36, 4), cardinality=32, base_width=8,
         stem_width=64, stem_type='deep', avg_down=True, aa_layer=nn.AvgPool2d,
         block_args=dict(attn_layer='se'))
-    return _create_resnet('seresnextaa201d_32x8d', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('seresnextaa201d_32x8d', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2126,7 +2130,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 6, 3), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs50', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs50', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2139,7 +2143,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 4, 23, 3), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs101', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs101', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2152,7 +2156,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 8, 36, 3), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs152', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs152', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2165,7 +2169,7 @@     model_args = dict(
         block=Bottleneck, layers=(3, 24, 36, 3), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs200', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs200', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2178,7 +2182,7 @@     model_args = dict(
         block=Bottleneck, layers=(4, 29, 53, 4), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs270', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs270', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 
@@ -2192,7 +2196,7 @@     model_args = dict(
         block=Bottleneck, layers=(4, 36, 72, 4), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs350', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs350', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2205,7 +2209,7 @@     model_args = dict(
         block=Bottleneck, layers=(4, 44, 87, 4), stem_width=32, stem_type='deep', replace_stem_pool=True,
         avg_down=True,  block_args=dict(attn_layer=attn_layer))
-    return _create_resnet('resnetrs420', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('resnetrs420', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
@@ -2215,7 +2219,7 @@     model_args = dict(
         block=[BasicBlock, BasicBlock, Bottleneck, BasicBlock], layers=(1, 1, 1, 1),
         stem_width=16, stem_type='deep', avg_down=True, channels=(32, 48, 48, 96))
-    return _create_resnet('test_resnet', pretrained, **dict(model_args, **kwargs))
+    return _create_resnet('test_resnet', pretrained, **dict(model_args, **kwargs))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 register_model_deprecations(__name__, {
