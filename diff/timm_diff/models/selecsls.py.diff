--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """PyTorch SelecSLS Net example for ImageNet Classification
 License: CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/legalcode)
 Author: Dushyant Mehta (@mehtadushy)
@@ -11,8 +16,8 @@ """
 from typing import List, Type
 
-import torch
-import torch.nn as nn
+# import torch
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import create_classifier
@@ -22,10 +27,10 @@ __all__ = ['SelecSls']  # model_registry will add each entrypoint fn to this
 
 
-class SequentialList(nn.Sequential):
+class SequentialList(msnn.SequentialCell):
 
     def __init__(self, *args):
-        super().__init__(*args)
+        super().__init__(*args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
     @torch.jit._overload_method  # noqa: F811
     def forward(self, x):
@@ -37,47 +42,47 @@         # type: (torch.Tensor) -> (List[torch.Tensor])
         pass
 
-    def forward(self, x) -> List[torch.Tensor]:
+    def forward(self, x) -> List[ms.Tensor]:
         for module in self:
             x = module(x)
         return x
 
 
-class SelectSeq(nn.Module):
+class SelectSeq(msnn.Cell):
     def __init__(self, mode='index', index=0):
         super().__init__()
         self.mode = mode
         self.index = index
 
     @torch.jit._overload_method  # noqa: F811
-    def forward(self, x):
+    def construct(self, x):
         # type: (List[torch.Tensor]) -> (torch.Tensor)
         pass
 
     @torch.jit._overload_method  # noqa: F811
-    def forward(self, x):
+    def construct(self, x):
         # type: (Tuple[torch.Tensor]) -> (torch.Tensor)
         pass
 
-    def forward(self, x) -> torch.Tensor:
+    def construct(self, x) -> ms.Tensor:
         if self.mode == 'index':
             return x[self.index]
         else:
-            return torch.cat(x, dim=1)
+            return mint.cat(x, dim=1)
 
 
 def conv_bn(in_chs, out_chs, k=3, stride=1, padding=None, dilation=1, device=None, dtype=None):
     dd = {'device': device, 'dtype': dtype}
     if padding is None:
         padding = ((stride - 1) + dilation * (k - 1)) // 2
-    return nn.Sequential(
+    return msnn.SequentialCell(
         nn.Conv2d(in_chs, out_chs, k, stride, padding=padding, dilation=dilation, bias=False, **dd),
         nn.BatchNorm2d(out_chs, **dd),
-        nn.ReLU(inplace=True)
-    )
-
-
-class SelecSlsBlock(nn.Module):
+        nn.ReLU()
+    )  # 存在 *args/**kwargs，需手动确认参数映射;; 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
+
+
+class SelecSlsBlock(msnn.Cell):
     def __init__(
             self,
             in_chs: int,
@@ -97,14 +102,14 @@         assert stride in [1, 2]
 
         # Process input with 4 conv blocks with the same number of input and output channels
-        self.conv1 = conv_bn(in_chs, mid_chs, 3, stride, dilation=dilation, **dd)
-        self.conv2 = conv_bn(mid_chs, mid_chs, 1, **dd)
-        self.conv3 = conv_bn(mid_chs, mid_chs // 2, 3, **dd)
-        self.conv4 = conv_bn(mid_chs // 2, mid_chs, 1, **dd)
-        self.conv5 = conv_bn(mid_chs, mid_chs // 2, 3, **dd)
-        self.conv6 = conv_bn(2 * mid_chs + (0 if is_first else skip_chs), out_chs, 1, **dd)
-
-    def forward(self, x: List[torch.Tensor]) -> List[torch.Tensor]:
+        self.conv1 = conv_bn(in_chs, mid_chs, 3, stride, dilation=dilation, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.conv2 = conv_bn(mid_chs, mid_chs, 1, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.conv3 = conv_bn(mid_chs, mid_chs // 2, 3, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.conv4 = conv_bn(mid_chs // 2, mid_chs, 1, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.conv5 = conv_bn(mid_chs, mid_chs // 2, 3, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.conv6 = conv_bn(2 * mid_chs + (0 if is_first else skip_chs), out_chs, 1, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+
+    def construct(self, x: List[ms.Tensor]) -> List[ms.Tensor]:
         if not isinstance(x, list):
             x = [x]
         assert len(x) in [1, 2]
@@ -113,13 +118,13 @@         d2 = self.conv3(self.conv2(d1))
         d3 = self.conv5(self.conv4(d2))
         if self.is_first:
-            out = self.conv6(torch.cat([d1, d2, d3], 1))
+            out = self.conv6(mint.cat([d1, d2, d3], 1))
             return [out, out]
         else:
-            return [self.conv6(torch.cat([d1, d2, d3, x[1]], 1)), x[1]]
-
-
-class SelecSls(nn.Module):
+            return [self.conv6(mint.cat([d1, d2, d3, x[1]], 1)), x[1]]
+
+
+class SelecSls(msnn.Cell):
     """SelecSls42 / SelecSls60 / SelecSls84
 
     Parameters
@@ -149,10 +154,10 @@         super().__init__()
         dd = {'device': device, 'dtype': dtype}
 
-        self.stem = conv_bn(in_chans, 32, stride=2, **dd)
-        self.features = SequentialList(*[cfg['block'](*block_args, **dd) for block_args in cfg['features']])
+        self.stem = conv_bn(in_chans, 32, stride=2, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.features = SequentialList(*[cfg['block'](*block_args, **dd) for block_args in cfg['features']])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.from_seq = SelectSeq()  # from List[tensor] -> Tensor in module compatible way
-        self.head = nn.Sequential(*[conv_bn(*conv_args, **dd) for conv_args in cfg['head']])
+        self.head = msnn.SequentialCell(*[conv_bn(*conv_args, **dd) for conv_args in cfg['head']])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.num_features = self.head_hidden_size = cfg['num_features']
         self.feature_info = cfg['feature_info']
 
@@ -162,13 +167,13 @@             pool_type=global_pool,
             drop_rate=drop_rate,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         for n, m in self.named_modules():
             if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
-
-    @torch.jit.ignore
+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')  # 'torch.nn.init.kaiming_normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    @ms.jit
     def group_matcher(self, coarse=False):
         return dict(
             stem=r'^stem',
@@ -176,12 +181,12 @@             blocks_head=r'^head'
         )
 
-    @torch.jit.ignore
+    @ms.jit
     def set_grad_checkpointing(self, enable=True):
         assert not enable, 'gradient checkpointing not supported'
 
-    @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    @ms.jit
+    def get_classifier(self) -> msnn.Cell:
         return self.fc
 
     def reset_classifier(self, num_classes: int, global_pool: str = 'avg'):
@@ -205,7 +210,7 @@         x = self.head_drop(x)
         return x if pre_logits else self.fc(x)
 
-    def forward(self, x):
+    def construct(self, x):
         x = self.forward_features(x)
         x = self.forward_head(x)
         return x
@@ -341,7 +346,7 @@         model_cfg=cfg,
         feature_cfg=dict(out_indices=(0, 1, 2, 3, 4), flatten_sequential=True),
         **kwargs,
-    )
+    )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _cfg(url='', **kwargs):
@@ -377,32 +382,32 @@ def selecsls42(pretrained=False, **kwargs) -> SelecSls:
     """Constructs a SelecSls42 model.
     """
-    return _create_selecsls('selecsls42', pretrained, **kwargs)
+    return _create_selecsls('selecsls42', pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def selecsls42b(pretrained=False, **kwargs) -> SelecSls:
     """Constructs a SelecSls42_B model.
     """
-    return _create_selecsls('selecsls42b', pretrained, **kwargs)
+    return _create_selecsls('selecsls42b', pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def selecsls60(pretrained=False, **kwargs) -> SelecSls:
     """Constructs a SelecSls60 model.
     """
-    return _create_selecsls('selecsls60', pretrained, **kwargs)
+    return _create_selecsls('selecsls60', pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def selecsls60b(pretrained=False, **kwargs) -> SelecSls:
     """Constructs a SelecSls60_B model.
     """
-    return _create_selecsls('selecsls60b', pretrained, **kwargs)
+    return _create_selecsls('selecsls60b', pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 @register_model
 def selecsls84(pretrained=False, **kwargs) -> SelecSls:
     """Constructs a SelecSls84 model.
     """
-    return _create_selecsls('selecsls84', pretrained, **kwargs)
+    return _create_selecsls('selecsls84', pretrained, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
