--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """VGG
 
 Adapted from https://github.com/pytorch/vision 'vgg.py' (BSD-3-Clause) with a few changes for
@@ -7,9 +12,8 @@ """
 from typing import Any, Dict, List, Optional, Type, Union, cast
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch
+# import torch.nn as nn
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import ClassifierHead
@@ -29,7 +33,7 @@ 
 
 @register_notrace_module  # reason: FX can't symbolically trace control flow in forward method
-class ConvMlp(nn.Module):
+class ConvMlp(msnn.Cell):
     """Convolutional MLP block for VGG head.
 
     Replaces traditional Linear layers with Conv2d layers in the classifier.
@@ -42,8 +46,8 @@             kernel_size: int = 7,
             mlp_ratio: float = 1.0,
             drop_rate: float = 0.2,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            conv_layer: Type[nn.Module] = nn.Conv2d,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            conv_layer: Type[msnn.Cell] = nn.Conv2d,
             device=None,
             dtype=None,
     ) -> None:
@@ -68,7 +72,7 @@         self.fc2 = conv_layer(mid_features, out_features, 1, bias=True, **dd)
         self.act2 = act_layer(True)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -80,7 +84,7 @@         if x.shape[-2] < self.input_kernel_size or x.shape[-1] < self.input_kernel_size:
             # keep the input size >= 7x7
             output_size = (max(self.input_kernel_size, x.shape[-2]), max(self.input_kernel_size, x.shape[-1]))
-            x = F.adaptive_avg_pool2d(x, output_size)
+            x = nn.functional.adaptive_avg_pool2d(x, output_size)
         x = self.fc1(x)
         x = self.act1(x)
         x = self.drop(x)
@@ -89,7 +93,7 @@         return x
 
 
-class VGG(nn.Module):
+class VGG(msnn.Cell):
     """VGG model architecture.
 
     Based on `Very Deep Convolutional Networks for Large-Scale Image Recognition`
@@ -103,9 +107,9 @@             in_chans: int = 3,
             output_stride: int = 32,
             mlp_ratio: float = 1.0,
-            act_layer: Type[nn.Module] = nn.ReLU,
-            conv_layer: Type[nn.Module] = nn.Conv2d,
-            norm_layer: Optional[Type[nn.Module]] = None,
+            act_layer: Type[msnn.Cell] = nn.ReLU,
+            conv_layer: Type[msnn.Cell] = nn.Conv2d,
+            norm_layer: Optional[Type[msnn.Cell]] = None,
             global_pool: str = 'avg',
             drop_rate: float = 0.,
             device=None,
@@ -137,12 +141,12 @@         prev_chs = in_chans
         net_stride = 1
         pool_layer = nn.MaxPool2d
-        layers: List[nn.Module] = []
+        layers: List[msnn.Cell] = []
         for v in cfg:
             last_idx = len(layers) - 1
             if v == 'M':
                 self.feature_info.append(dict(num_chs=prev_chs, reduction=net_stride, module=f'features.{last_idx}'))
-                layers += [pool_layer(kernel_size=2, stride=2)]
+                layers += [nn.MaxPool2d(kernel_size = 2, stride = 2)]
                 net_stride *= 2
             else:
                 v = cast(int, v)
@@ -152,7 +156,9 @@                 else:
                     layers += [conv2d, act_layer(inplace=True)]
                 prev_chs = v
-        self.features = nn.Sequential(*layers)
+        self.features = msnn.SequentialCell([
+            layers
+        ])
         self.feature_info.append(dict(num_chs=prev_chs, reduction=net_stride, module=f'features.{len(layers) - 1}'))
 
         self.num_features = prev_chs
@@ -200,7 +206,7 @@         assert not enable, 'gradient checkpointing not supported'
 
     @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    def get_classifier(self) -> msnn.Cell:
         """Get the classifier module.
 
         Returns:
@@ -218,7 +224,7 @@         self.num_classes = num_classes
         self.head.reset(num_classes, global_pool)
 
-    def forward_features(self, x: torch.Tensor) -> torch.Tensor:
+    def forward_features(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through feature extraction layers.
 
         Args:
@@ -230,7 +236,7 @@         x = self.features(x)
         return x
 
-    def forward_head(self, x: torch.Tensor, pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, x: ms.Tensor, pre_logits: bool = False) -> ms.Tensor:
         """Forward pass through head.
 
         Args:
@@ -243,7 +249,7 @@         x = self.pre_logits(x)
         return self.head(x, pre_logits=pre_logits) if pre_logits else self.head(x)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -260,18 +266,18 @@         """Initialize model weights."""
         for m in self.modules():
             if isinstance(m, nn.Conv2d):
-                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
+                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')  # 'torch.nn.init.kaiming_normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
                 if m.bias is not None:
-                    nn.init.constant_(m.bias, 0)
+                    nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.BatchNorm2d):
-                nn.init.constant_(m.weight, 1)
-                nn.init.constant_(m.bias, 0)
+                nn.init.constant_(m.weight, 1)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             elif isinstance(m, nn.Linear):
-                nn.init.normal_(m.weight, 0, 0.01)
-                nn.init.constant_(m.bias, 0)
-
-
-def _filter_fn(state_dict: dict) -> Dict[str, torch.Tensor]:
+                nn.init.normal_(m.weight, 0, 0.01)  # 'torch.nn.init.normal_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+
+def _filter_fn(state_dict: dict) -> Dict[str, ms.Tensor]:
     """Convert patch embedding weight from manual patchify + linear proj to conv.
 
     Args:
