--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Vision OutLOoker (VOLO) implementation
 
 Paper: `VOLO: Vision Outlooker for Visual Recognition` - https://arxiv.org/abs/2106.13112
@@ -22,9 +27,9 @@ import math
 from typing import Any, Callable, Dict, List, Optional, Tuple, Union, Type
 
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
+# import torch
+# import torch.nn as nn
+# import torch.nn.functional as F
 
 from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD
 from timm.layers import DropPath, Mlp, to_2tuple, to_ntuple, trunc_normal_, use_fused_attn
@@ -36,7 +41,7 @@ __all__ = ['VOLO']  # model_registry will add each entrypoint fn to this
 
 
-class OutlookAttention(nn.Module):
+class OutlookAttention(msnn.Cell):
     """Outlook attention mechanism for VOLO models."""
 
     def __init__(
@@ -73,17 +78,17 @@         self.stride = stride
         self.scale = head_dim ** -0.5
 
-        self.v = nn.Linear(dim, dim, bias=qkv_bias, **dd)
-        self.attn = nn.Linear(dim, kernel_size ** 4 * num_heads, **dd)
+        self.v = nn.Linear(dim, dim, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.attn = nn.Linear(dim, kernel_size ** 4 * num_heads, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
 
         self.attn_drop = nn.Dropout(attn_drop)
-        self.proj = nn.Linear(dim, dim, **dd)
+        self.proj = nn.Linear(dim, dim, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.proj_drop = nn.Dropout(proj_drop)
 
-        self.unfold = nn.Unfold(kernel_size=kernel_size, padding=padding, stride=stride)
-        self.pool = nn.AvgPool2d(kernel_size=stride, stride=stride, ceil_mode=True)
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+        self.unfold = nn.Unfold(kernel_size = kernel_size, padding = padding, stride = stride)
+        self.pool = nn.AvgPool2d(kernel_size = stride, stride = stride, ceil_mode = True)
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -110,7 +115,7 @@         attn = self.attn_drop(attn)
 
         x = (attn @ v).permute(0, 1, 4, 3, 2).reshape(B, C * self.kernel_size * self.kernel_size, h * w)
-        x = F.fold(x, output_size=(H, W), kernel_size=self.kernel_size, padding=self.padding, stride=self.stride)
+        x = nn.functional.fold(x, output_size = (H, W), kernel_size = self.kernel_size, padding = self.padding, stride = self.stride)
 
         x = self.proj(x.permute(0, 2, 3, 1))
         x = self.proj_drop(x)
@@ -118,7 +123,7 @@         return x
 
 
-class Outlooker(nn.Module):
+class Outlooker(msnn.Cell):
     """Outlooker block that combines outlook attention with MLP."""
 
     def __init__(
@@ -131,8 +136,8 @@             mlp_ratio: float = 3.,
             attn_drop: float = 0.,
             drop_path: float = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             qkv_bias: bool = False,
             device=None,
             dtype=None,
@@ -154,7 +159,7 @@         """
         dd = {'device': device, 'dtype': dtype}
         super().__init__()
-        self.norm1 = norm_layer(dim, **dd)
+        self.norm1 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.attn = OutlookAttention(
             dim,
             num_heads,
@@ -164,19 +169,19 @@             qkv_bias=qkv_bias,
             attn_drop=attn_drop,
             **dd,
-        )
-        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-        self.norm2 = norm_layer(dim, **dd)
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+        self.norm2 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.mlp = Mlp(
             in_features=dim,
             hidden_features=int(dim * mlp_ratio),
             act_layer=act_layer,
             **dd,
-        )
-        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -190,9 +195,9 @@         return x
 
 
-class Attention(nn.Module):
+class Attention(msnn.Cell):
     """Multi-head self-attention module."""
-    fused_attn: torch.jit.Final[bool]
+    fused_attn: torch.jit.Final[bool]  # 'torch.jit.Final' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     def __init__(
             self,
@@ -220,12 +225,12 @@         self.scale = head_dim ** -0.5
         self.fused_attn = use_fused_attn()
 
-        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias, **dd)
+        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.attn_drop = nn.Dropout(attn_drop)
-        self.proj = nn.Linear(dim, dim, **dd)
+        self.proj = nn.Linear(dim, dim, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.proj_drop = nn.Dropout(proj_drop)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -243,7 +248,7 @@             x = F.scaled_dot_product_attention(
                 q, k, v,
                 dropout_p=self.attn_drop.p if self.training else 0.,
-            )
+            )  # 'torch.nn.functional.scaled_dot_product_attention' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
             q = q * self.scale
             attn = q @ k.transpose(-2, -1)
@@ -258,7 +263,7 @@         return x
 
 
-class Transformer(nn.Module):
+class Transformer(msnn.Cell):
     """Transformer block with multi-head self-attention and MLP."""
 
     def __init__(
@@ -269,8 +274,8 @@             qkv_bias: bool = False,
             attn_drop: float = 0.,
             drop_path: float = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             device=None,
             dtype=None,
     ):
@@ -288,15 +293,15 @@         """
         dd = {'device': device, 'dtype': dtype}
         super().__init__()
-        self.norm1 = norm_layer(dim, **dd)
-        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, **dd)
-        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-        self.norm2 = norm_layer(dim, **dd)
-        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio), act_layer=act_layer, **dd)
-        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+        self.norm1 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.attn = Attention(dim, num_heads=num_heads, qkv_bias=qkv_bias, attn_drop=attn_drop, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+        self.norm2 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio), act_layer=act_layer, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -310,7 +315,7 @@         return x
 
 
-class ClassAttention(nn.Module):
+class ClassAttention(msnn.Cell):
     """Class attention mechanism for class token interaction."""
 
     def __init__(
@@ -344,13 +349,13 @@             self.head_dim = head_dim
         self.scale = head_dim ** -0.5
 
-        self.kv = nn.Linear(dim, self.head_dim * self.num_heads * 2, bias=qkv_bias, **dd)
-        self.q = nn.Linear(dim, self.head_dim * self.num_heads, bias=qkv_bias, **dd)
+        self.kv = nn.Linear(dim, self.head_dim * self.num_heads * 2, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+        self.q = nn.Linear(dim, self.head_dim * self.num_heads, bias=qkv_bias, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.attn_drop = nn.Dropout(attn_drop)
-        self.proj = nn.Linear(self.head_dim * self.num_heads, dim, **dd)
+        self.proj = nn.Linear(self.head_dim * self.num_heads, dim, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
         self.proj_drop = nn.Dropout(proj_drop)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -375,7 +380,7 @@         return cls_embed
 
 
-class ClassBlock(nn.Module):
+class ClassBlock(msnn.Cell):
     """Class block that combines class attention with MLP."""
 
     def __init__(
@@ -388,8 +393,8 @@             drop: float = 0.,
             attn_drop: float = 0.,
             drop_path: float = 0.,
-            act_layer: Type[nn.Module] = nn.GELU,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            act_layer: Type[msnn.Cell] = nn.GELU,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             device=None,
             dtype=None,
     ):
@@ -409,7 +414,7 @@         """
         dd = {'device': device, 'dtype': dtype}
         super().__init__()
-        self.norm1 = norm_layer(dim, **dd)
+        self.norm1 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.attn = ClassAttention(
             dim,
             num_heads=num_heads,
@@ -418,20 +423,20 @@             attn_drop=attn_drop,
             proj_drop=drop,
             **dd,
-        )
-        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-        self.norm2 = norm_layer(dim, **dd)
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_path1 = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+        self.norm2 = norm_layer(dim, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         self.mlp = Mlp(
             in_features=dim,
             hidden_features=int(dim * mlp_ratio),
             act_layer=act_layer,
             drop=drop,
             **dd,
-        )
-        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.drop_path2 = DropPath(drop_path) if drop_path > 0. else msnn.Identity()
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -443,10 +448,10 @@         cls_embed = x[:, :1]
         cls_embed = cls_embed + self.drop_path1(self.attn(self.norm1(x)))
         cls_embed = cls_embed + self.drop_path2(self.mlp(self.norm2(cls_embed)))
-        return torch.cat([cls_embed, x[:, 1:]], dim=1)
-
-
-def get_block(block_type: str, **kwargs: Any) -> nn.Module:
+        return mint.cat([cls_embed, x[:, 1:]], dim=1)
+
+
+def get_block(block_type: str, **kwargs: Any) -> msnn.Cell:
     """Get block based on type.
 
     Args:
@@ -457,7 +462,7 @@         The requested block module.
     """
     if block_type == 'ca':
-        return ClassBlock(**kwargs)
+        return ClassBlock(**kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     else:
         assert False, f'Invalid block type: {block_type}'
 
@@ -477,25 +482,25 @@     """
     W = size[1] // scale
     H = size[2] // scale
-    W_t = torch.tensor(W, dtype=torch.float32)
-    H_t = torch.tensor(H, dtype=torch.float32)
-    cut_rat = torch.sqrt(1. - lam)
+    W_t = ms.Tensor(W, dtype=ms.float32)
+    H_t = ms.Tensor(H, dtype=ms.float32)
+    cut_rat = mint.sqrt(1. - lam)
     cut_w = (W_t * cut_rat).int()
     cut_h = (H_t * cut_rat).int()
 
     # uniform
-    cx = torch.randint(0, W, (1,))
-    cy = torch.randint(0, H, (1,))
-
-    bbx1 = torch.clamp(cx - cut_w // 2, 0, W)
-    bby1 = torch.clamp(cy - cut_h // 2, 0, H)
-    bbx2 = torch.clamp(cx + cut_w // 2, 0, W)
-    bby2 = torch.clamp(cy + cut_h // 2, 0, H)
+    cx = mint.randint(0, W, (1,))
+    cy = mint.randint(0, H, (1,))
+
+    bbx1 = mint.clamp(cx - cut_w // 2, 0, W)
+    bby1 = mint.clamp(cy - cut_h // 2, 0, H)
+    bbx2 = mint.clamp(cx + cut_w // 2, 0, W)
+    bby2 = mint.clamp(cy + cut_h // 2, 0, H)
 
     return bbx1.item(), bby1.item(), bbx2.item(), bby2.item()
 
 
-class PatchEmbed(nn.Module):
+class PatchEmbed(msnn.Cell):
     """Image to patch embedding with multi-layer convolution."""
 
     def __init__(
@@ -527,17 +532,18 @@         super().__init__()
         assert patch_size in [4, 8, 16]
         if stem_conv:
-            self.conv = nn.Sequential(
+            self.conv = msnn.SequentialCell(
+                [
                 nn.Conv2d(in_chans, hidden_dim, kernel_size=7, stride=stem_stride, padding=3, bias=False, **dd),
                 nn.BatchNorm2d(hidden_dim, **dd),
-                nn.ReLU(inplace=True),
+                nn.ReLU(),
                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1, bias=False, **dd),
                 nn.BatchNorm2d(hidden_dim, **dd),
-                nn.ReLU(inplace=True),
+                nn.ReLU(),
                 nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=1, padding=1, bias=False, **dd),
                 nn.BatchNorm2d(hidden_dim, **dd),
-                nn.ReLU(inplace=True),
-            )
+                nn.ReLU()
+            ])  # 存在 *args/**kwargs，需手动确认参数映射;; 'torch.nn.ReLU':没有对应的mindspore参数 'inplace' (position 0);
         else:
             self.conv = None
 
@@ -547,10 +553,10 @@             kernel_size=patch_size // stem_stride,
             stride=patch_size // stem_stride,
             **dd,
-        )
+        )  # 存在 *args/**kwargs，需手动确认参数映射;
         self.num_patches = (img_size // patch_size) * (img_size // patch_size)
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -565,7 +571,7 @@         return x
 
 
-class Downsample(nn.Module):
+class Downsample(msnn.Cell):
     """Downsampling module between stages."""
 
     def __init__(
@@ -585,9 +591,9 @@         """
         super().__init__()
         dd = {'device': device, 'dtype': dtype}
-        self.proj = nn.Conv2d(in_embed_dim, out_embed_dim, kernel_size=patch_size, stride=patch_size, **dd)
-
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+        self.proj = nn.Conv2d(in_embed_dim, out_embed_dim, kernel_size=patch_size, stride=patch_size, **dd)  # 存在 *args/**kwargs，需手动确认参数映射;
+
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass.
 
         Args:
@@ -618,7 +624,7 @@         device=None,
         dtype=None,
         **kwargs: Any,
-) -> nn.Sequential:
+) -> msnn.SequentialCell:
     """Generate outlooker layers for stage 1.
 
     Args:
@@ -655,8 +661,8 @@             device=device,
             dtype=dtype,
             **kwargs,
-        ))
-    blocks = nn.Sequential(*blocks)
+        ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    blocks = msnn.SequentialCell(*blocks)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return blocks
 
 
@@ -671,7 +677,7 @@         attn_drop: float = 0,
         drop_path_rate: float = 0.,
         **kwargs: Any,
-) -> nn.Sequential:
+) -> msnn.SequentialCell:
     """Generate transformer layers for stage 2.
 
     Args:
@@ -700,12 +706,12 @@             attn_drop=attn_drop,
             drop_path=block_dpr,
             **kwargs,
-        ))
-    blocks = nn.Sequential(*blocks)
+        ))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    blocks = msnn.SequentialCell(*blocks)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return blocks
 
 
-class VOLO(nn.Module):
+class VOLO(msnn.Cell):
     """Vision Outlooker (VOLO) model."""
 
     def __init__(
@@ -727,7 +733,7 @@             pos_drop_rate: float = 0.,
             attn_drop_rate: float = 0.,
             drop_path_rate: float = 0.,
-            norm_layer: Type[nn.Module] = nn.LayerNorm,
+            norm_layer: Type[msnn.Cell] = nn.LayerNorm,
             post_layers: Optional[Tuple[str, ...]] = ('ca', 'ca'),
             use_aux_head: bool = True,
             use_mix_token: bool = False,
@@ -785,13 +791,13 @@             hidden_dim=stem_hidden_dim,
             embed_dim=embed_dims[0],
             **dd,
-        )
+        )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
         r = patch_size
 
         # initial positional encoding, we add positional encoding after outlooker blocks
         patch_grid = (img_size[0] // patch_size // pooling_scale, img_size[1] // patch_size // pooling_scale)
-        self.pos_embed = nn.Parameter(torch.zeros(1, patch_grid[0], patch_grid[1], embed_dims[-1], **dd))
-        self.pos_drop = nn.Dropout(p=pos_drop_rate)
+        self.pos_embed = ms.Parameter(mint.zeros(1, patch_grid[0], patch_grid[1], embed_dims[-1], **dd))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+        self.pos_drop = nn.Dropout(p = pos_drop_rate)
 
         # set the main block in network
         self.stage_ends = []
@@ -812,7 +818,7 @@                     attn_drop=attn_drop_rate,
                     norm_layer=norm_layer,
                     **dd,
-                )
+                )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             else:
                 # stage 2
                 stage = transformer_blocks(
@@ -827,23 +833,23 @@                     attn_drop=attn_drop_rate,
                     norm_layer=norm_layer,
                     **dd,
-                )
+                )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             network.append(stage)
             self.stage_ends.append(block_idx)
             self.feature_info.append(dict(num_chs=embed_dims[i], reduction=r, module=f'network.{block_idx}'))
             block_idx += 1
             if downsamples[i]:
                 # downsampling between two stages
-                network.append(Downsample(embed_dims[i], embed_dims[i + 1], 2, **dd))
+                network.append(Downsample(embed_dims[i], embed_dims[i + 1], 2, **dd))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
                 r *= 2
                 block_idx += 1
 
-        self.network = nn.ModuleList(network)
+        self.network = msnn.CellList(network)
 
         # set post block, for example, class attention layers
         self.post_network = None
         if post_layers is not None:
-            self.post_network = nn.ModuleList([
+            self.post_network = msnn.CellList([
                 get_block(
                     post_layers[i],
                     dim=embed_dims[-1],
@@ -856,25 +862,25 @@                     **dd,
                 )
                 for i in range(len(post_layers))
-            ])
-            self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dims[-1], **dd))
+            ])  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+            self.cls_token = ms.Parameter(mint.zeros(1, 1, embed_dims[-1], **dd))  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
             trunc_normal_(self.cls_token, std=.02)
 
         # set output type
         if use_aux_head:
-            self.aux_head = nn.Linear(self.num_features, num_classes, **dd) if num_classes > 0 else nn.Identity()
+            self.aux_head = nn.Linear(self.num_features, num_classes, **dd) if num_classes > 0 else msnn.Identity()  # 存在 *args/**kwargs，需手动确认参数映射;
         else:
             self.aux_head = None
-        self.norm = norm_layer(self.num_features, **dd)
+        self.norm = norm_layer(self.num_features, **dd)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
         # Classifier head
         self.head_drop = nn.Dropout(drop_rate)
-        self.head = nn.Linear(self.num_features, num_classes, **dd) if num_classes > 0 else nn.Identity()
+        self.head = nn.Linear(self.num_features, num_classes, **dd) if num_classes > 0 else msnn.Identity()  # 存在 *args/**kwargs，需手动确认参数映射;
 
         trunc_normal_(self.pos_embed, std=.02)
         self.apply(self._init_weights)
 
-    def _init_weights(self, m: nn.Module) -> None:
+    def _init_weights(self, m: msnn.Cell) -> None:
         """Initialize weights for modules.
 
         Args:
@@ -883,9 +889,9 @@         if isinstance(m, nn.Linear):
             trunc_normal_(m.weight, std=.02)
             if isinstance(m, nn.Linear) and m.bias is not None:
-                nn.init.constant_(m.bias, 0)
-
-    @torch.jit.ignore
+                nn.init.constant_(m.bias, 0)  # 'torch.nn.init.constant_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    @ms.jit
     def no_weight_decay(self) -> set:
         """Get set of parameters that should not have weight decay.
 
@@ -894,7 +900,7 @@         """
         return {'pos_embed', 'cls_token'}
 
-    @torch.jit.ignore
+    @ms.jit
     def group_matcher(self, coarse: bool = False) -> Dict[str, Any]:
         """Get parameter grouping for optimizer.
 
@@ -917,7 +923,7 @@             ],
         )
 
-    @torch.jit.ignore
+    @ms.jit
     def set_grad_checkpointing(self, enable: bool = True) -> None:
         """Set gradient checkpointing.
 
@@ -926,8 +932,8 @@         """
         self.grad_checkpointing = enable
 
-    @torch.jit.ignore
-    def get_classifier(self) -> nn.Module:
+    @ms.jit
+    def get_classifier(self) -> msnn.Cell:
         """Get classifier module.
 
         Returns:
@@ -948,12 +954,12 @@         device = self.head.weight.device if hasattr(self.head, 'weight') else None
         dtype = self.head.weight.dtype if hasattr(self.head, 'weight') else None
         self.head = nn.Linear(
-            self.num_features, num_classes, device=device, dtype=dtype) if num_classes > 0 else nn.Identity()
+            self.num_features, num_classes, dtype = dtype) if num_classes > 0 else msnn.Identity()  # 'torch.nn.Linear':没有对应的mindspore参数 'device' (position 3);
         if self.aux_head is not None:
             self.aux_head = nn.Linear(
-                self.num_features, num_classes, device=device, dtype=dtype) if num_classes > 0 else nn.Identity()
-
-    def forward_tokens(self, x: torch.Tensor) -> torch.Tensor:
+                self.num_features, num_classes, dtype = dtype) if num_classes > 0 else msnn.Identity()  # 'torch.nn.Linear':没有对应的mindspore参数 'device' (position 3);
+
+    def forward_tokens(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through token processing stages.
 
         Args:
@@ -967,6 +973,7 @@                 # add positional encoding after outlooker blocks
                 x = x + self.pos_embed
                 x = self.pos_drop(x)
+            # 'torch.jit.is_scripting' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             if self.grad_checkpointing and not torch.jit.is_scripting():
                 x = checkpoint(block, x)
             else:
@@ -976,7 +983,7 @@         x = x.reshape(B, -1, C)
         return x
 
-    def forward_cls(self, x: torch.Tensor) -> torch.Tensor:
+    def forward_cls(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through class attention blocks.
 
         Args:
@@ -987,15 +994,16 @@         """
         B, N, C = x.shape
         cls_tokens = self.cls_token.expand(B, -1, -1)
-        x = torch.cat([cls_tokens, x], dim=1)
+        x = mint.cat([cls_tokens, x], dim=1)
         for block in self.post_network:
+            # 'torch.jit.is_scripting' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             if self.grad_checkpointing and not torch.jit.is_scripting():
                 x = checkpoint(block, x)
             else:
                 x = block(x)
         return x
 
-    def forward_train(self, x: torch.Tensor) -> Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor, Tuple[int, int, int, int]]]:
+    def forward_train(self, x: ms.Tensor) -> Union[ms.Tensor, Tuple[ms.Tensor, ms.Tensor, Tuple[int, int, int, int]]]:
         """Forward pass for training with mix token support.
 
         Args:
@@ -1013,7 +1021,7 @@ 
         # mix token, see token labeling for details.
         if self.mix_token and self.training:
-            lam = torch.distributions.Beta(self.beta, self.beta).sample()
+            lam = torch.distributions.Beta(self.beta, self.beta).sample()  # 'torch.distributions.Beta' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.distributions.Beta.sample' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             patch_h, patch_w = x.shape[1] // self.pooling_scale, x.shape[2] // self.pooling_scale
             bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam, scale=self.pooling_scale)
             temp_x = x.clone()
@@ -1058,13 +1066,13 @@ 
     def forward_intermediates(
             self,
-            x: torch.Tensor,
+            x: ms.Tensor,
             indices: Optional[Union[int, List[int]]] = None,
             norm: bool = False,
             stop_early: bool = False,
             output_fmt: str = 'NCHW',
             intermediates_only: bool = False,
-    ) -> Union[List[torch.Tensor], Tuple[torch.Tensor, List[torch.Tensor]]]:
+    ) -> Union[List[ms.Tensor], Tuple[ms.Tensor, List[ms.Tensor]]]:
         """ Forward features that returns intermediates.
 
         Args:
@@ -1088,6 +1096,7 @@         x = self.patch_embed(x).permute(0, 2, 3, 1)  # B,C,H,W-> B,H,W,C
 
         # step2: tokens learning in the two stages
+        # 'torch.jit.is_scripting' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         if torch.jit.is_scripting() or not stop_early:  # can't slice blocks in torchscript
             network = self.network
         else:
@@ -1097,6 +1106,7 @@                 # add positional encoding after outlooker blocks
                 x = x + self.pos_embed
                 x = self.pos_drop(x)
+            # 'torch.jit.is_scripting' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             if self.grad_checkpointing and not torch.jit.is_scripting():
                 x = checkpoint(block, x)
             else:
@@ -1143,13 +1153,13 @@         max_index = self.stage_ends[max_index]
         self.network = self.network[:max_index + 1]  # truncate blocks
         if prune_norm:
-            self.norm = nn.Identity()
+            self.norm = msnn.Identity()
         if prune_head:
-            self.post_network = nn.ModuleList()  # prune token blocks with head
+            self.post_network = msnn.CellList()  # prune token blocks with head
             self.reset_classifier(0, '')
         return take_indices
 
-    def forward_features(self, x: torch.Tensor) -> torch.Tensor:
+    def forward_features(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass through feature extraction.
 
         Args:
@@ -1169,7 +1179,7 @@         x = self.norm(x)
         return x
 
-    def forward_head(self, x: torch.Tensor, pre_logits: bool = False) -> torch.Tensor:
+    def forward_head(self, x: ms.Tensor, pre_logits: bool = False) -> ms.Tensor:
         """Forward pass through classification head.
 
         Args:
@@ -1195,7 +1205,7 @@             out = out + 0.5 * aux.max(1)[0]
         return out
 
-    def forward(self, x: torch.Tensor) -> torch.Tensor:
+    def construct(self, x: ms.Tensor) -> ms.Tensor:
         """Forward pass (simplified, without mix token training).
 
         Args:
@@ -1228,7 +1238,7 @@         pretrained,
         feature_cfg=dict(out_indices=out_indices, feature_cls='getter'),
         **kwargs,
-    )
+    )  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
 
 
 def _cfg(url: str = '', **kwargs: Any) -> Dict[str, Any]:
@@ -1303,64 +1313,64 @@ @register_model
 def volo_d1_224(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D1 model, Params: 27M."""
-    model_args = dict(layers=(4, 4, 8, 2), embed_dims=(192, 384, 384, 384), num_heads=(6, 12, 12, 12), **kwargs)
-    model = _create_volo('volo_d1_224', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(4, 4, 8, 2), embed_dims=(192, 384, 384, 384), num_heads=(6, 12, 12, 12), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d1_224', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d1_384(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D1 model, Params: 27M."""
-    model_args = dict(layers=(4, 4, 8, 2), embed_dims=(192, 384, 384, 384), num_heads=(6, 12, 12, 12), **kwargs)
-    model = _create_volo('volo_d1_384', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(4, 4, 8, 2), embed_dims=(192, 384, 384, 384), num_heads=(6, 12, 12, 12), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d1_384', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d2_224(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D2 model, Params: 59M."""
-    model_args = dict(layers=(6, 4, 10, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)
-    model = _create_volo('volo_d2_224', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(6, 4, 10, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d2_224', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d2_384(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D2 model, Params: 59M."""
-    model_args = dict(layers=(6, 4, 10, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)
-    model = _create_volo('volo_d2_384', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(6, 4, 10, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d2_384', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d3_224(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D3 model, Params: 86M."""
-    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)
-    model = _create_volo('volo_d3_224', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d3_224', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d3_448(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D3 model, Params: 86M."""
-    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)
-    model = _create_volo('volo_d3_448', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(256, 512, 512, 512), num_heads=(8, 16, 16, 16), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d3_448', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d4_224(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D4 model, Params: 193M."""
-    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16), **kwargs)
-    model = _create_volo('volo_d4_224', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d4_224', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
 @register_model
 def volo_d4_448(pretrained: bool = False, **kwargs: Any) -> VOLO:
     """VOLO-D4 model, Params: 193M."""
-    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16), **kwargs)
-    model = _create_volo('volo_d4_448', pretrained=pretrained, **model_args)
+    model_args = dict(layers=(8, 8, 16, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16), **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d4_448', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -1372,8 +1382,8 @@     """
     model_args = dict(
         layers=(12, 12, 20, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16),
-        mlp_ratio=4, stem_hidden_dim=128, **kwargs)
-    model = _create_volo('volo_d5_224', pretrained=pretrained, **model_args)
+        mlp_ratio=4, stem_hidden_dim=128, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d5_224', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -1385,8 +1395,8 @@     """
     model_args = dict(
         layers=(12, 12, 20, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16),
-        mlp_ratio=4, stem_hidden_dim=128, **kwargs)
-    model = _create_volo('volo_d5_448', pretrained=pretrained, **model_args)
+        mlp_ratio=4, stem_hidden_dim=128, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d5_448', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
 
 
@@ -1398,6 +1408,6 @@     """
     model_args = dict(
         layers=(12, 12, 20, 4), embed_dims=(384, 768, 768, 768), num_heads=(12, 16, 16, 16),
-        mlp_ratio=4, stem_hidden_dim=128, **kwargs)
-    model = _create_volo('volo_d5_512', pretrained=pretrained, **model_args)
+        mlp_ratio=4, stem_hidden_dim=128, **kwargs)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
+    model = _create_volo('volo_d5_512', pretrained=pretrained, **model_args)  # 存在 *args/**kwargs，未转换，需手动确认参数映射;
     return model
