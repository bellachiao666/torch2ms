--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ ADOPT PyTorch Optimizer
 
 ADOPT: Modified Adam Can Converge with Any β2 with the Optimal Rate: https://arxiv.org/abs/2411.02853
@@ -17,9 +22,9 @@ """
 from typing import cast, List, Optional, Tuple, Union
 
-import torch
-from torch import Tensor
-from torch.optim.optimizer import Optimizer
+# import torch
+# from torch import Tensor
+# from torch.optim.optimizer import Optimizer
 
 from ._types import ParamsT
 
@@ -28,22 +33,22 @@ def _view_as_real(params, *state_and_grads):
     for i, p in enumerate(params):
         if torch.is_complex(p):
-            params[i] = torch.view_as_real(params[i])
+            params[i] = torch.view_as_real(params[i])  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             for s in state_and_grads:
-                s[i] = torch.view_as_real(s[i])
+                s[i] = torch.view_as_real(s[i])  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
 def _get_scalar_dtype(is_fused=None):
     if is_fused:
-        return torch.float32
+        return ms.float32
     return (
-        torch.float64 if torch.get_default_dtype() == torch.float64 else torch.float32
-    )
+        ms.float64 if torch.get_default_dtype() == ms.float64 else ms.float32
+    )  # 'torch.get_default_dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
 def _is_compiling():
     if hasattr(torch, 'compiler') and hasattr(torch.compiler, 'is_compiling'):
-        return torch.compiler.is_compiling()
+        return torch.compiler.is_compiling()  # 'torch.compiler.is_compiling' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     else:
         return False
 
@@ -53,9 +58,10 @@     if not torch.jit.is_scripting() and _is_compiling():
         return x
     else:
-        return x.item() if isinstance(x, torch.Tensor) else x
-
-
+        return x.item() if isinstance(x, ms.Tensor) else x
+
+
+# 'torch.optim.optimizer.Optimizer' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 class Adopt(Optimizer):
     """
     ADOPT: Modified Adam Can Converge with Any β2 with the Optimal Rate: https://arxiv.org/abs/2411.02853
@@ -64,7 +70,7 @@     def __init__(
             self,
             params: ParamsT,
-            lr: Union[float, Tensor] = 1e-3,
+            lr: Union[float, ms.Tensor] = 1e-3,
             betas: Tuple[float, float] = (0.9, 0.9999),
             eps: float = 1e-6,
             clip_exp: Optional[float] = 0.333,
@@ -127,13 +133,13 @@                 if len(p_state) != 0 and not torch.is_tensor(p_state["step"]):
                     step_val = float(p_state["step"])
                     p_state["step"] = (
-                        torch.tensor(
+                        ms.Tensor(
                             step_val,
                             dtype=_get_scalar_dtype(),
                             device=p.device,
                         )
                         if group["capturable"]
-                        else torch.tensor(step_val, dtype=_get_scalar_dtype())
+                        else ms.Tensor(step_val, dtype=_get_scalar_dtype())
                     )
 
     def _init_group(
@@ -149,7 +155,7 @@         for p in group["params"]:
             if p.grad is None:
                 continue
-            has_complex |= torch.is_complex(p)
+            has_complex |= torch.is_complex(p)  # 'torch.is_complex' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             params_with_grad.append(p)
             if p.grad.is_sparse:
                 raise RuntimeError("ADOPT does not support sparse gradients")
@@ -162,14 +168,14 @@                 # Deliberately host `step` on CPU if both capturable and fused are off.
                 # This is because kernel launches are costly on CUDA and XLA.
                 state["step"] = (
-                    torch.zeros((), dtype=_get_scalar_dtype(), device=p.grad.device)
+                    mint.zeros((), dtype=_get_scalar_dtype(), device=p.grad.device)
                     if group["capturable"]
-                    else torch.tensor(0.0, dtype=_get_scalar_dtype())
+                    else ms.Tensor(0.0, dtype=_get_scalar_dtype())
                 )
                 # Exponential moving average of gradient values
-                state["exp_avg"] = torch.zeros_like(p.grad, memory_format=torch.preserve_format)
+                state["exp_avg"] = mint.zeros_like(p.grad, memory_format=torch.preserve_format)
                 # Exponential moving average of squared gradient values
-                state["exp_avg_sq"] = torch.zeros_like(p.grad, memory_format=torch.preserve_format)
+                state["exp_avg_sq"] = mint.zeros_like(p.grad, memory_format=torch.preserve_format)
 
             exp_avgs.append(state["exp_avg"])
             exp_avg_sqs.append(state["exp_avg_sq"])
@@ -185,7 +191,6 @@         return has_complex
 
     #@_use_grad_for_differentiable  # FIXME internal context mgr, can't use
-    @torch.no_grad()
     def step(self, closure=None):
         """Perform a single optimization step.
 
@@ -201,11 +206,11 @@                 loss = closure()
 
         for group in self.param_groups:
-            params_with_grad: List[Tensor] = []
-            grads: List[Tensor] = []
-            exp_avgs: List[Tensor] = []
-            exp_avg_sqs: List[Tensor] = []
-            state_steps: List[Tensor] = []
+            params_with_grad: List[ms.Tensor] = []
+            grads: List[ms.Tensor] = []
+            exp_avgs: List[ms.Tensor] = []
+            exp_avg_sqs: List[ms.Tensor] = []
+            state_steps: List[ms.Tensor] = []
             beta1, beta2 = group["betas"]
 
             has_complex = self._init_group(
@@ -245,18 +250,18 @@ 
 
 def _single_tensor_adopt(
-        params: List[Tensor],
-        grads: List[Tensor],
-        exp_avgs: List[Tensor],
-        exp_avg_sqs: List[Tensor],
-        state_steps: List[Tensor],
-        grad_scale: Optional[Tensor],
-        found_inf: Optional[Tensor],
+        params: List[ms.Tensor],
+        grads: List[ms.Tensor],
+        exp_avgs: List[ms.Tensor],
+        exp_avg_sqs: List[ms.Tensor],
+        state_steps: List[ms.Tensor],
+        grad_scale: Optional[ms.Tensor],
+        found_inf: Optional[ms.Tensor],
         *,
         has_complex: bool,
         beta1: float,
         beta2: float,
-        lr: Union[float, Tensor],
+        lr: Union[float, ms.Tensor],
         weight_decay: float,
         clip_exp: Optional[float],
         max_lr: Optional[float],
@@ -283,8 +288,8 @@ 
         # If compiling, the compiler will handle cudagraph checks, see note [torch.compile x capturable]
         if capturable and not _is_compiling():
-            from torch.optim.optimizer import _get_capturable_supported_devices
-            capturable_supported_devices = _get_capturable_supported_devices()
+            # from torch.optim.optimizer import _get_capturable_supported_devices
+            capturable_supported_devices = _get_capturable_supported_devices()  # 'torch.optim.optimizer._get_capturable_supported_devices' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             assert param.device.type == step_t.device.type and param.device.type in capturable_supported_devices,\
                 f"If capturable=True, params and state_steps must be on supported devices: {capturable_supported_devices}."
 
@@ -292,12 +297,12 @@         step_t += 1
 
         if torch.is_complex(param):
-            grad = torch.view_as_real(grad)
+            grad = torch.view_as_real(grad)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             if exp_avg is not None:
-                exp_avg = torch.view_as_real(exp_avg)
+                exp_avg = torch.view_as_real(exp_avg)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             if exp_avg_sq is not None:
-                exp_avg_sq = torch.view_as_real(exp_avg_sq)
-            param = torch.view_as_real(param)
+                exp_avg_sq = torch.view_as_real(exp_avg_sq)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            param = torch.view_as_real(param)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if weight_decay != 0 and not decoupled:
             grad = grad.add(param, alpha=weight_decay)
@@ -311,7 +316,7 @@             wd_scale = lr ** 2 / max_lr if max_lr is not None else lr
             param.add_(param, alpha=-wd_scale * weight_decay)
 
-        denom = torch.clamp(exp_avg_sq.sqrt(), eps)
+        denom = mint.clamp(exp_avg_sq.sqrt(), eps)
         normed_grad = grad.div(denom)
 
         if clip_exp is not None:
@@ -332,18 +337,18 @@ 
 
 def _multi_tensor_adopt(
-        params: List[Tensor],
-        grads: List[Tensor],
-        exp_avgs: List[Tensor],
-        exp_avg_sqs: List[Tensor],
-        state_steps: List[Tensor],
-        grad_scale: Optional[Tensor],
-        found_inf: Optional[Tensor],
+        params: List[ms.Tensor],
+        grads: List[ms.Tensor],
+        exp_avgs: List[ms.Tensor],
+        exp_avg_sqs: List[ms.Tensor],
+        state_steps: List[ms.Tensor],
+        grad_scale: Optional[ms.Tensor],
+        found_inf: Optional[ms.Tensor],
         *,
         has_complex: bool,
         beta1: float,
         beta2: float,
-        lr: Union[float, Tensor],
+        lr: Union[float, ms.Tensor],
         weight_decay: float,
         clip_exp: Optional[float],
         max_lr: Optional[float],
@@ -364,10 +369,10 @@ 
     # If compiling, the compiler will handle cudagraph checks, see note [torch.compile x capturable]
     if capturable and not _is_compiling():
-        from torch.optim.optimizer import _get_capturable_supported_devices
+        # from torch.optim.optimizer import _get_capturable_supported_devices
         capturable_supported_devices = _get_capturable_supported_devices(
             supports_xla=False
-        )
+        )  # 'torch.optim.optimizer._get_capturable_supported_devices' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         assert all(
             p.device.type == step.device.type and p.device.type in capturable_supported_devices
             for p, step in zip(params, state_steps)
@@ -379,7 +384,7 @@ 
     grouped_tensors = Optimizer._group_tensors_by_device_and_dtype(
         [params, grads, exp_avgs, exp_avg_sqs, state_steps]  # type: ignore[list-item]
-    )
+    )  # 'torch.optim.optimizer.Optimizer._group_tensors_by_device_and_dtype' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     for (
             device_params_,
             device_grads_,
@@ -398,78 +403,78 @@             _view_as_real(device_params, device_grads, device_exp_avgs, device_exp_avg_sqs)
 
         if maximize:
-            device_grads = torch._foreach_neg(device_grads)  # type: ignore[assignment]
+            device_grads = torch._foreach_neg(device_grads)  # type: ignore[assignment]; 'torch._foreach_neg' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         # Update steps
         # If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over
         # and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just
         # wrapped it once now. The alpha is required to assure we go to the right overload.
         if not _is_compiling() and device_state_steps[0].is_cpu:
-            torch._foreach_add_(device_state_steps, torch.tensor(1.0, device="cpu"), alpha=1.0)
+            torch._foreach_add_(device_state_steps, ms.Tensor(1.0, device="cpu"), alpha=1.0)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         else:
-            torch._foreach_add_(device_state_steps, 1)
+            torch._foreach_add_(device_state_steps, 1)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if weight_decay != 0 and not decoupled:
             # Re-use the intermediate memory (device_grads) already allocated for maximize
             if maximize:
-                torch._foreach_add_(device_grads, device_params, alpha=weight_decay)
+                torch._foreach_add_(device_grads, device_params, alpha=weight_decay)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             else:
-                device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)
+                device_grads = torch._foreach_add(device_grads, device_params, alpha=weight_decay)  # 'torch._foreach_add' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if device_state_steps[0] == 1:
-            torch._foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads)
+            torch._foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads)  # 'torch._foreach_addcmul_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             continue
 
         if weight_decay != 0 and decoupled:
             wd_scale = lr ** 2 / max_lr if max_lr is not None else lr
-            torch._foreach_add_(device_params, device_params, alpha=-wd_scale * weight_decay)
-
-        exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)
-        torch._foreach_maximum_(exp_avg_sq_sqrt, eps)
-
-        normed_grad = torch._foreach_div(device_grads, exp_avg_sq_sqrt)
+            torch._foreach_add_(device_params, device_params, alpha=-wd_scale * weight_decay)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)  # 'torch._foreach_sqrt' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        torch._foreach_maximum_(exp_avg_sq_sqrt, eps)  # 'torch._foreach_maximum_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        normed_grad = torch._foreach_div(device_grads, exp_avg_sq_sqrt)  # 'torch._foreach_div' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if clip_exp is not None:
             clip_val = (device_state_steps[0] - 1) ** clip_exp
-            torch._foreach_maximum_(normed_grad, -clip_val)
-            torch._foreach_minimum_(normed_grad, clip_val)
-
-        torch._foreach_lerp_(device_exp_avgs, normed_grad, 1 - beta1)
+            torch._foreach_maximum_(normed_grad, -clip_val)  # 'torch._foreach_maximum_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            torch._foreach_minimum_(normed_grad, clip_val)  # 'torch._foreach_minimum_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        torch._foreach_lerp_(device_exp_avgs, normed_grad, 1 - beta1)  # 'torch._foreach_lerp_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         if caution:
             # Apply caution as per 'Cautious Optimizers' - https://arxiv.org/abs/2411.16085
-            masks = torch._foreach_mul(device_exp_avgs, device_grads)
+            masks = torch._foreach_mul(device_exp_avgs, device_grads)  # 'torch._foreach_mul' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
             masks = [(m > 0).to(g.dtype) for m, g in zip(masks, device_grads)]
             mask_scale = [m.mean() for m in masks]
-            torch._foreach_maximum_(mask_scale, 1e-3)
-            torch._foreach_div_(masks, mask_scale)
-            device_exp_avgs = torch._foreach_mul(device_exp_avgs, masks)
-
-        torch._foreach_add_(device_params, device_exp_avgs, alpha=-lr)
-
-        torch._foreach_mul_(device_exp_avg_sqs, beta2)
-        torch._foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads, value=1 - beta2)
+            torch._foreach_maximum_(mask_scale, 1e-3)  # 'torch._foreach_maximum_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            torch._foreach_div_(masks, mask_scale)  # 'torch._foreach_div_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            device_exp_avgs = torch._foreach_mul(device_exp_avgs, masks)  # 'torch._foreach_mul' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        torch._foreach_add_(device_params, device_exp_avgs, alpha=-lr)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+        torch._foreach_mul_(device_exp_avg_sqs, beta2)  # 'torch._foreach_mul_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        torch._foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads, value=1 - beta2)  # 'torch._foreach_addcmul_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 
 #@_disable_dynamo_if_unsupported(single_tensor_fn=_single_tensor_adopt)  # FIXME internal context mgr, can't use
 def adopt(
-        params: List[Tensor],
-        grads: List[Tensor],
-        exp_avgs: List[Tensor],
-        exp_avg_sqs: List[Tensor],
-        state_steps: List[Tensor],
+        params: List[ms.Tensor],
+        grads: List[ms.Tensor],
+        exp_avgs: List[ms.Tensor],
+        exp_avg_sqs: List[ms.Tensor],
+        state_steps: List[ms.Tensor],
         # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627
         # setting this as kwarg for now as functional API is compiled by torch/distributed/optim
         foreach: Optional[bool] = None,
         capturable: bool = False,
         differentiable: bool = False,
-        grad_scale: Optional[Tensor] = None,
-        found_inf: Optional[Tensor] = None,
+        grad_scale: Optional[ms.Tensor] = None,
+        found_inf: Optional[ms.Tensor] = None,
         has_complex: bool = False,
         *,
         beta1: float,
         beta2: float,
-        lr: Union[float, Tensor],
+        lr: Union[float, ms.Tensor],
         weight_decay: float,
         clip_exp: Optional[float],
         max_lr: Optional[float],
@@ -486,7 +491,7 @@ 
     # this check is slow during compilation, so we skip it
     # if it's strictly needed we can add this check back in dynamo
-    if not _is_compiling() and not all(isinstance(t, torch.Tensor) for t in state_steps):
+    if not _is_compiling() and not all(isinstance(t, ms.Tensor) for t in state_steps):
         raise RuntimeError(
             "API has changed, `state_steps` argument must contain a list of singleton tensors"
         )
