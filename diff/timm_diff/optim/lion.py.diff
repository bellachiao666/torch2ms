--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Lion Optimizer
 Paper: `Symbolic Discovery of Optimization Algorithms` - https://arxiv.org/abs/2302.06675
 Original Impl: https://github.com/google/automl/tree/master/lion
@@ -22,12 +27,13 @@ # ==============================================================================
 from typing import List, Optional, Tuple
 
-import torch
-from torch.optim.optimizer import Optimizer
+# import torch
+# from torch.optim.optimizer import Optimizer
 
 from ._types import ParamsT
 
 
+# 'torch.optim.optimizer.Optimizer' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 class Lion(Optimizer):
     r"""Implements Lion algorithm."""
 
@@ -111,7 +117,7 @@ 
                 # State initialization
                 if len(state) == 0:
-                    state['exp_avg'] = torch.zeros_like(p, memory_format=torch.preserve_format)
+                    state['exp_avg'] = mint.zeros_like(p, memory_format=torch.preserve_format)
 
                 exp_avgs.append(state['exp_avg'])
 
@@ -133,9 +139,9 @@ 
 
 def lion(
-        params: List[torch.Tensor],
-        grads: List[torch.Tensor],
-        exp_avgs: List[torch.Tensor],
+        params: List[ms.Tensor],
+        grads: List[ms.Tensor],
+        exp_avgs: List[ms.Tensor],
         # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627
         # setting this as kwarg for now as functional API is compiled by torch/distributed/optim
         maximize: bool = False,
@@ -153,7 +159,7 @@     if foreach is None:
         try:
             # cannot do foreach if this overload doesn't exist when caution enabled
-            foreach = not caution or 'Scalar' in torch.ops.aten._foreach_maximum_.overloads()
+            foreach = not caution or 'Scalar' in torch.ops.aten._foreach_maximum_.overloads()  # 'torch.ops.aten._foreach_maximum_.overloads' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         except:
             foreach = False
 
@@ -180,9 +186,9 @@ 
 
 def _single_tensor_lion(
-        params: List[torch.Tensor],
-        grads: List[torch.Tensor],
-        exp_avgs: List[torch.Tensor],
+        params: List[ms.Tensor],
+        grads: List[ms.Tensor],
+        exp_avgs: List[ms.Tensor],
         *,
         beta1: float,
         beta2: float,
@@ -197,9 +203,9 @@         exp_avg = exp_avgs[i]
 
         if torch.is_complex(param):
-            grad = torch.view_as_real(grad)
-            exp_avg = torch.view_as_real(exp_avg)
-            param = torch.view_as_real(param)
+            grad = torch.view_as_real(grad)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            exp_avg = torch.view_as_real(exp_avg)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+            param = torch.view_as_real(param)  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         # Perform stepweight decay
         wd_scale = lr if max_lr is None else lr ** 2 / max_lr
@@ -221,9 +227,9 @@ 
 
 def _multi_tensor_lion(
-        params: List[torch.Tensor],
-        grads: List[torch.Tensor],
-        exp_avgs: List[torch.Tensor],
+        params: List[ms.Tensor],
+        grads: List[ms.Tensor],
+        exp_avgs: List[ms.Tensor],
         *,
         beta1: float,
         beta2: float,
@@ -237,32 +243,32 @@         return
 
     if maximize:
-        grads = torch._foreach_neg(tuple(grads))  # type: ignore[assignment]
-
-    grads = [torch.view_as_real(x) if torch.is_complex(x) else x for x in grads]
-    exp_avgs = [torch.view_as_real(x) if torch.is_complex(x) else x for x in exp_avgs]
-    params = [torch.view_as_real(x) if torch.is_complex(x) else x for x in params]
+        grads = torch._foreach_neg(tuple(grads))  # type: ignore[assignment]; 'torch._foreach_neg' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    grads = [torch.view_as_real(x) if torch.is_complex(x) else x for x in grads]  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.is_complex' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    exp_avgs = [torch.view_as_real(x) if torch.is_complex(x) else x for x in exp_avgs]  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.is_complex' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    params = [torch.view_as_real(x) if torch.is_complex(x) else x for x in params]  # 'torch.view_as_real' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.is_complex' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     # Perform stepweight decay
     wd_scale = lr if max_lr is None else lr ** 2 / max_lr
-    torch._foreach_mul_(params, 1 - wd_scale * weight_decay)
+    torch._foreach_mul_(params, 1 - wd_scale * weight_decay)  # 'torch._foreach_mul_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     # Weight update
-    updates = torch._foreach_mul(exp_avgs, beta1)
-    torch._foreach_add_(updates, grads, alpha=1 - beta1)
+    updates = torch._foreach_mul(exp_avgs, beta1)  # 'torch._foreach_mul' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    torch._foreach_add_(updates, grads, alpha=1 - beta1)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     updates = [u.sign_() for u in updates]
 
     if caution:
         # Apply caution as per 'Cautious Optimizers' - https://arxiv.org/abs/2411.16085
-        masks = torch._foreach_mul(updates, grads)
+        masks = torch._foreach_mul(updates, grads)  # 'torch._foreach_mul' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         masks = [(m > 0).to(g.dtype) for m, g in zip(masks, grads)]
         mask_scale = [m.mean() for m in masks]
-        torch._foreach_maximum_(mask_scale, 1e-3)
-        torch._foreach_div_(masks, mask_scale)
-        torch._foreach_mul_(updates, masks)
-
-    torch._foreach_add_(params, updates, alpha=-lr)
+        torch._foreach_maximum_(mask_scale, 1e-3)  # 'torch._foreach_maximum_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        torch._foreach_div_(masks, mask_scale)  # 'torch._foreach_div_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        torch._foreach_mul_(updates, masks)  # 'torch._foreach_mul_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+
+    torch._foreach_add_(params, updates, alpha=-lr)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     # Decay the momentum running average coefficient
-    torch._foreach_mul_(exp_avgs, beta2)
-    torch._foreach_add_(exp_avgs, grads, alpha=1 - beta2)
+    torch._foreach_mul_(exp_avgs, beta2)  # 'torch._foreach_mul_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+    torch._foreach_add_(exp_avgs, grads, alpha=1 - beta2)  # 'torch._foreach_add_' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
