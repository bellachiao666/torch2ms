--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ RMSProp modified to behave like Tensorflow impl
 
 Originally cut & paste from PyTorch RMSProp
@@ -11,12 +16,13 @@ Modifications Copyright 2021 Ross Wightman
 """
 
-import torch
-from torch.optim import Optimizer
+# import torch
+# from torch.optim import Optimizer
 
 from ._types import ParamsT
 
 
+# 'torch.optim.Optimizer' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 class RMSpropTF(Optimizer):
     """Implements RMSprop algorithm (TensorFlow style epsilon)
 
@@ -95,7 +101,6 @@             group.setdefault('caution', False)
             group.setdefault('corrected_weight_decay', False)
 
-    @torch.no_grad()
     def step(self, closure=None):
         """Performs a single optimization step.
 
@@ -120,11 +125,11 @@                 # State initialization
                 if len(state) == 0:
                     state['step'] = 0
-                    state['square_avg'] = torch.ones_like(p)  # PyTorch inits to zero
+                    state['square_avg'] = mint.ones_like(p)  # PyTorch inits to zero
                     if group['momentum'] > 0:
-                        state['momentum_buffer'] = torch.zeros_like(p)
+                        state['momentum_buffer'] = mint.zeros_like(p)
                     if group['centered']:
-                        state['grad_avg'] = torch.zeros_like(p)
+                        state['grad_avg'] = mint.zeros_like(p)
 
                 square_avg = state['square_avg']
                 one_minus_alpha = 1. - group['alpha']
