--- pytorch+++ mindspore@@ -1,3 +1,8 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 """ Distributed training/validation utils
 
 Hacked together by / Copyright 2020 Ross Wightman
@@ -6,8 +11,8 @@ import os
 from typing import Optional
 
-import torch
-from torch import distributed as dist
+# import torch
+# from torch import distributed as dist
 
 from .model import unwrap_model
 
@@ -16,7 +21,7 @@ 
 def reduce_tensor(tensor, n):
     rt = tensor.clone()
-    dist.all_reduce(rt, op=dist.ReduceOp.SUM)
+    mint.distributed.all_reduce(rt, op=dist.ReduceOp.SUM)
     rt /= n
     return rt
 
@@ -27,11 +32,11 @@         if ('running_mean' in bn_name) or ('running_var' in bn_name):
             if reduce:
                 # average bn stats across whole group
-                torch.distributed.all_reduce(bn_buf, op=dist.ReduceOp.SUM)
+                mint.distributed.all_reduce(bn_buf, op=dist.ReduceOp.SUM)
                 bn_buf /= float(world_size)
             else:
                 # broadcast bn stats from rank 0 to whole group
-                torch.distributed.broadcast(bn_buf, 0)
+                mint.distributed.broadcast(bn_buf, 0)
 
 
 def is_global_primary(args):
@@ -93,7 +98,7 @@     args.rank = result['global_rank']
     args.local_rank = result['local_rank']
     args.distributed = result['distributed']
-    device = torch.device(args.device)
+    device = torch.device(args.device)  # 'torch.device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     return device
 
 
@@ -141,7 +146,7 @@             os.environ['LOCAL_RANK'] = str(local_rank)
             os.environ['RANK'] = str(global_rank)
             os.environ['WORLD_SIZE'] = str(world_size)
-            torch.distributed.init_process_group(
+            mint.distributed.init_process_group(
                 backend=dist_backend,
                 init_method=dist_url,
                 world_size=world_size,
@@ -150,18 +155,18 @@         else:
             # DDP via torchrun, torch.distributed.launch
             local_rank, _, _ = world_info_from_env()
-            torch.distributed.init_process_group(
+            mint.distributed.init_process_group(
                 backend=dist_backend,
                 init_method=dist_url,
             )
-            world_size = torch.distributed.get_world_size()
-            global_rank = torch.distributed.get_rank()
+            world_size = mint.distributed.get_world_size()
+            global_rank = mint.distributed.get_rank()
         distributed = True
 
     if device_type == 'cuda':
-        assert torch.cuda.is_available(), f'CUDA is not available but {device} was specified.'
+        assert torch.cuda.is_available(), f'CUDA is not available but {device} was specified.'  # 'torch.cuda.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
     if device_type == 'npu':
-        assert torch.npu.is_available(), f'Ascend NPU is not available but {device} was specified.'
+        assert torch.npu.is_available(), f'Ascend NPU is not available but {device} was specified.'  # 'torch.npu.is_available' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     if distributed and device != 'cpu':
         # Ignore manually specified device index in distributed mode and
@@ -171,7 +176,7 @@         device = f'{device_type}:{local_rank}'
 
     if device.startswith('cuda:'):
-        torch.cuda.set_device(device)
+        torch.cuda.set_device(device)  # 'torch.cuda.set_device' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
     return dict(
         device=device,
