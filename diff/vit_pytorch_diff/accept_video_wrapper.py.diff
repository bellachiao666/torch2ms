--- pytorch+++ mindspore@@ -1,9 +1,14 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 from contextlib import nullcontext
 
-import torch
-from torch import is_tensor, randn
-from torch.nn import Module, Linear, Parameter
-from torch.utils._pytree import tree_flatten, tree_unflatten
+# import torch
+# from torch import is_tensor, randn
+# from torch.nn import Module, Linear, Parameter
+# from torch.utils._pytree import tree_flatten, tree_unflatten
 
 from einops import rearrange, repeat
 
@@ -17,7 +22,7 @@ 
 # classes
 
-class AcceptVideoWrapper(Module):
+class AcceptVideoWrapper(msnn.Cell):
     def __init__(
         self,
         image_net: Module,
@@ -42,7 +47,7 @@ 
         if exists(proj_embed_to_dim):
             assert exists(dim_emb), '`dim_emb` must be passed in'
-            self.embed_proj = Linear(dim_emb, proj_embed_to_dim)
+            self.embed_proj = nn.Linear(dim_emb, proj_embed_to_dim)
 
         # time positional embedding
 
@@ -52,11 +57,11 @@ 
             dim_pos_emb = default(proj_embed_to_dim, dim_emb)
 
-            self.pos_emb = Parameter(randn(time_seq_len, dim_pos_emb) * 1e-2)
+            self.pos_emb = ms.Parameter(mint.randn(size = (time_seq_len, dim_pos_emb)) * 1e-2)
 
         self.embed_is_channel_first = embed_is_channel_first
 
-    def forward(
+    def construct(
         self,
         video, # (b c t h w)
         eval_with_no_grad = False,
@@ -88,9 +93,9 @@ 
         # handle multiple outputs, say logits and embeddings returned from extractor - also handle some reduce aux loss being returned
 
-        outputs, tree_spec = tree_flatten(outputs)
+        outputs, tree_spec = tree_flatten(outputs)  # 'torch.utils._pytree.tree_flatten' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
-        outputs = tuple(rearrange(t, '(b t) ... -> b t ...', t = time) if is_tensor(t) and t.numel() > 1 else t for t in outputs)
+        outputs = tuple(rearrange(t, '(b t) ... -> b t ...', t = time) if is_tensor(t) and t.numel() > 1 else t for t in outputs)  # 'torch.is_tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         # maybe project embedding
 
@@ -127,12 +132,12 @@ 
             outputs[self.output_pos_add_pos_emb] = embed
 
-        return tree_unflatten(outputs, tree_spec)
+        return tree_unflatten(outputs, tree_spec)  # 'torch.utils._pytree.tree_unflatten' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
 # main
 
 if __name__ == '__main__':
-    from vit_pytorch import ViT
+    # from vit_pytorch import ViT
 
     v = ViT(
         image_size = 256,
@@ -146,11 +151,11 @@         emb_dropout = 0.1
     )
 
-    videos = torch.randn(1, 3, 7, 256, 256)
+    videos = mint.randn(size = (1, 3, 7, 256, 256))
 
     # step up the difficulty and return embeddings for robotics
 
-    from vit_pytorch.extractor import Extractor
+    # from vit_pytorch.extractor import Extractor
     v = Extractor(v)
 
     video_acceptor = AcceptVideoWrapper(v, add_time_pos_emb = True, output_pos_add_pos_emb = 1, time_seq_len = 12, dim_emb = 1024, proj_embed_to_dim = 512)
