--- pytorch+++ mindspore@@ -1,11 +1,15 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import copy
 import random
 from functools import wraps, partial
 
-import torch
-from torch import nn, einsum
-import torch.nn.functional as F
-from torchvision import transforms as T
+# import torch
+# from torch import nn, einsum
+# from torchvision import transforms as T
 
 from einops import rearrange, reduce, repeat
 
@@ -41,7 +45,7 @@ # tensor related helpers
 
 def log(t, eps = 1e-20):
-    return torch.log(t + eps)
+    return mint.log(t + eps)
 
 # loss function # (algorithm 1 in the paper)
 
@@ -72,7 +76,7 @@     student_probs = (student_logits / student_temp).softmax(dim = -1)
     teacher_probs = ((teacher_logits - centers) / teacher_temp).softmax(dim = -1)
 
-    sim_matrix = einsum('b i d, b j d -> b i j', student_latent, teacher_latent)
+    sim_matrix = mint.einsum('b i d, b j d -> b i j', student_latent, teacher_latent)
     sim_indices = sim_matrix.max(dim = -1).indices
     sim_indices = repeat(sim_indices, 'b n -> b n k', k = teacher_probs.shape[-1])
     max_sim_teacher_probs = teacher_probs.gather(1, sim_indices)
@@ -81,13 +85,13 @@ 
 # augmentation utils
 
-class RandomApply(nn.Module):
+class RandomApply(msnn.Cell):
     def __init__(self, fn, p):
         super().__init__()
         self.fn = fn
         self.p = p
 
-    def forward(self, x):
+    def construct(self, x):
         if random.random() > self.p:
             return x
         return self.fn(x)
@@ -111,11 +115,11 @@ 
 # MLP class for projector and predictor
 
-class L2Norm(nn.Module):
-    def forward(self, x, eps = 1e-6):
-        return F.normalize(x, dim = 1, eps = eps)
-
-class MLP(nn.Module):
+class L2Norm(msnn.Cell):
+    def construct(self, x, eps = 1e-6):
+        return nn.functional.normalize(x, dim = 1, eps = eps)
+
+class MLP(msnn.Cell):
     def __init__(self, dim, dim_out, num_layers, hidden_size = 256):
         super().__init__()
 
@@ -127,23 +131,24 @@ 
             layers.extend([
                 nn.Linear(layer_dim_in, layer_dim_out),
-                nn.GELU() if not is_last else nn.Identity()
+                nn.GELU() if not is_last else msnn.Identity()
             ])
 
-        self.net = nn.Sequential(
-            *layers,
+        self.net = msnn.SequentialCell(
+            [
+            layers,
             L2Norm(),
             nn.Linear(hidden_size, dim_out)
-        )
-
-    def forward(self, x):
+        ])
+
+    def construct(self, x):
         return self.net(x)
 
 # a wrapper class for the base neural network
 # will manage the interception of the hidden layer output
 # and pipe it into the projecter and predictor nets
 
-class NetWrapper(nn.Module):
+class NetWrapper(msnn.Cell):
     def __init__(self, net, output_dim, projection_hidden_size, projection_num_layers, layer = -2):
         super().__init__()
         self.net = net
@@ -204,7 +209,7 @@         assert hidden is not None, f'hidden layer {self.layer} never emitted an output'
         return hidden
 
-    def forward(self, x, return_projection = True):
+    def construct(self, x, return_projection = True):
         region_latents = self.get_embedding(x)
         global_latent = reduce(region_latents, 'b c h w -> b c', 'mean')
 
@@ -220,7 +225,7 @@ 
 # main class
 
-class EsViTTrainer(nn.Module):
+class EsViTTrainer(msnn.Cell):
     def __init__(
         self,
         net,
@@ -243,40 +248,41 @@ 
         # default BYOL augmentation
 
-        DEFAULT_AUG = torch.nn.Sequential(
+        DEFAULT_AUG = msnn.SequentialCell(
+            [
             RandomApply(
-                T.ColorJitter(0.8, 0.8, 0.8, 0.2),
+                ms.dataset.vision.RandomColorAdjust(0.8, 0.8, 0.8, 0.2),
                 p = 0.3
             ),
             T.RandomGrayscale(p=0.2),
             T.RandomHorizontalFlip(),
             RandomApply(
-                T.GaussianBlur((3, 3), (1.0, 2.0)),
+                ms.dataset.vision.GaussianBlur((3, 3), (1.0, 2.0)),
                 p = 0.2
             ),
             T.Normalize(
                 mean=torch.tensor([0.485, 0.456, 0.406]),
-                std=torch.tensor([0.229, 0.224, 0.225])),
-        )
+                std=torch.tensor([0.229, 0.224, 0.225]))
+        ])  # 'torchvision.transforms.RandomGrayscale' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.RandomHorizontalFlip' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torchvision.transforms.Normalize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         self.augment1 = default(augment_fn, DEFAULT_AUG)
         self.augment2 = default(augment_fn2, DEFAULT_AUG)
 
         # local and global crops
 
-        self.local_crop = T.RandomResizedCrop((image_size, image_size), scale = (0.05, local_upper_crop_scale))
-        self.global_crop = T.RandomResizedCrop((image_size, image_size), scale = (global_lower_crop_scale, 1.))
+        self.local_crop = T.RandomResizedCrop((image_size, image_size), scale = (0.05, local_upper_crop_scale))  # 'torchvision.transforms.RandomResizedCrop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.global_crop = T.RandomResizedCrop((image_size, image_size), scale = (global_lower_crop_scale, 1.))  # 'torchvision.transforms.RandomResizedCrop' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
         self.student_encoder = NetWrapper(net, num_classes_K, projection_hidden_size, projection_layers, layer = hidden_layer)
 
         self.teacher_encoder = None
         self.teacher_ema_updater = EMA(moving_average_decay)
 
-        self.register_buffer('teacher_view_centers', torch.zeros(1, num_classes_K))
-        self.register_buffer('last_teacher_view_centers',  torch.zeros(1, num_classes_K))
-
-        self.register_buffer('teacher_region_centers', torch.zeros(1, num_classes_K))
-        self.register_buffer('last_teacher_region_centers',  torch.zeros(1, num_classes_K))
+        self.register_buffer('teacher_view_centers', mint.zeros(size = (1, num_classes_K)))
+        self.register_buffer('last_teacher_view_centers',  mint.zeros(size = (1, num_classes_K)))
+
+        self.register_buffer('teacher_region_centers', mint.zeros(size = (1, num_classes_K)))
+        self.register_buffer('last_teacher_region_centers',  mint.zeros(size = (1, num_classes_K)))
 
         self.teacher_centering_ema_updater = EMA(center_moving_average_decay)
 
@@ -288,7 +294,7 @@         self.to(device)
 
         # send a mock image tensor to instantiate singleton parameters
-        self.forward(torch.randn(2, 3, image_size, image_size, device=device))
+        self.forward(mint.randn(size = (2, 3, image_size, image_size)))  # 'torch.randn':没有对应的mindspore参数 'device' (position 5);
 
     @singleton('teacher_encoder')
     def _get_teacher_encoder(self):
@@ -310,7 +316,7 @@         new_teacher_region_centers = self.teacher_centering_ema_updater.update_average(self.teacher_region_centers, self.last_teacher_region_centers)
         self.teacher_region_centers.copy_(new_teacher_region_centers)
 
-    def forward(
+    def construct(
         self,
         x,
         return_embedding = False,
@@ -350,10 +356,10 @@ 
         # calculate view-level loss
 
-        teacher_view_logits_avg = torch.cat((teacher_view_proj_one, teacher_view_proj_two)).mean(dim = 0)
+        teacher_view_logits_avg = mint.cat((teacher_view_proj_one, teacher_view_proj_two)).mean(dim = 0)
         self.last_teacher_view_centers.copy_(teacher_view_logits_avg)
 
-        teacher_region_logits_avg = torch.cat((teacher_region_proj_one, teacher_region_proj_two)).mean(dim = (0, 1))
+        teacher_region_logits_avg = mint.cat((teacher_region_proj_one, teacher_region_proj_two)).mean(dim = (0, 1))
         self.last_teacher_region_centers.copy_(teacher_region_logits_avg)
 
         view_loss = (view_loss_fn_(teacher_view_proj_one, student_view_proj_two) \
