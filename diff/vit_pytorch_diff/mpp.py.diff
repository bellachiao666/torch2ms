--- pytorch+++ mindspore@@ -1,8 +1,13 @@+import mindspore as ms
+import mindspore.nn as msnn
+import mindspore.ops as msops
+import mindspore.mint as mint
+from mindspore.mint import nn, ops
 import math
 
-import torch
-from torch import nn
-import torch.nn.functional as F
+# import torch
+# from torch import nn
+# import torch.nn.functional as F
 
 from einops import rearrange, repeat, reduce
 
@@ -13,16 +18,16 @@ 
 def prob_mask_like(t, prob):
     batch, seq_length, _ = t.shape
-    return torch.zeros((batch, seq_length)).float().uniform_(0, 1) < prob
+    return mint.zeros((batch, seq_length)).float().uniform_(0, 1) < prob
 
 def get_mask_subset_with_prob(patched_input, prob):
     batch, seq_len, _, device = *patched_input.shape, patched_input.device
     max_masked = math.ceil(prob * seq_len)
 
-    rand = torch.rand((batch, seq_len), device=device)
+    rand = mint.rand((batch, seq_len))  # 'torch.rand':没有对应的mindspore参数 'device' (position 5);
     _, sampled_indices = rand.topk(max_masked, dim=-1)
 
-    new_mask = torch.zeros((batch, seq_len), device=device)
+    new_mask = mint.zeros((batch, seq_len))  # 'torch.zeros':没有对应的mindspore参数 'device' (position 4);
     new_mask.scatter_(1, sampled_indices, 1)
     return new_mask.bool()
 
@@ -30,7 +35,7 @@ # mpp loss
 
 
-class MPPLoss(nn.Module):
+class MPPLoss(msnn.Cell):
     def __init__(
         self,
         patch_size,
@@ -46,10 +51,10 @@         self.output_channel_bits = output_channel_bits
         self.max_pixel_val = max_pixel_val
 
-        self.mean = torch.tensor(mean).view(-1, 1, 1) if mean else None
-        self.std = torch.tensor(std).view(-1, 1, 1) if std else None
+        self.mean = torch.tensor(mean).view(-1, 1, 1) if mean else None  # 'torch.tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.tensor.view' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
+        self.std = torch.tensor(std).view(-1, 1, 1) if std else None  # 'torch.tensor' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;; 'torch.tensor.view' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
-    def forward(self, predicted_patches, target, mask):
+    def construct(self, predicted_patches, target, mask):
         p, c, mpv, bits, device = self.patch_size, self.channels, self.max_pixel_val, self.output_channel_bits, target.device
         bin_size = mpv / (2 ** bits)
 
@@ -61,22 +66,22 @@         target = target.clamp(max = mpv) # clamp just in case
         avg_target = reduce(target, 'b c (h p1) (w p2) -> b (h w) c', 'mean', p1 = p, p2 = p).contiguous()
 
-        channel_bins = torch.arange(bin_size, mpv, bin_size, device = device)
-        discretized_target = torch.bucketize(avg_target, channel_bins)
+        channel_bins = mint.arange(bin_size, mpv, bin_size)  # 'torch.arange':没有对应的mindspore参数 'device' (position 6);
+        discretized_target = torch.bucketize(avg_target, channel_bins)  # 'torch.bucketize' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
 
-        bin_mask = (2 ** bits) ** torch.arange(0, c, device = device).long()
+        bin_mask = (2 ** bits) ** mint.arange(0, c).long()  # 'torch.arange':没有对应的mindspore参数 'device' (position 6);
         bin_mask = rearrange(bin_mask, 'c -> () () c')
 
-        target_label = torch.sum(bin_mask * discretized_target, dim = -1)
+        target_label = mint.sum(bin_mask * discretized_target)
 
-        loss = F.cross_entropy(predicted_patches[mask], target_label[mask])
+        loss = F.cross_entropy(predicted_patches[mask], target_label[mask])  # 'torch.nn.functional.cross_entropy' 未在映射表(api_mapping_out_excel.json)中找到，需手动确认;
         return loss
 
 
 # main class
 
 
-class MPP(nn.Module):
+class MPP(msnn.Cell):
     def __init__(
         self,
         transformer,
@@ -97,7 +102,9 @@                             max_pixel_val, mean, std)
 
         # extract patching function
-        self.patch_to_emb = nn.Sequential(transformer.to_patch_embedding[1:])
+        self.patch_to_emb = msnn.SequentialCell([
+            transformer.to_patch_embedding[1:]
+        ])
 
         # output transformation
         self.to_bits = nn.Linear(dim, 2**(output_channel_bits * channels))
@@ -111,9 +118,9 @@         self.random_patch_prob = random_patch_prob
 
         # token ids
-        self.mask_token = nn.Parameter(torch.randn(1, 1, channels * patch_size ** 2))
+        self.mask_token = ms.Parameter(mint.randn(size = (1, 1, channels * patch_size ** 2)))
 
-    def forward(self, input, **kwargs):
+    def construct(self, input, **kwargs):
         transformer = self.transformer
         # clone original image for loss
         img = input.clone().detach()
@@ -138,12 +145,9 @@                                                random_patch_sampling_prob).to(mask.device)
 
             bool_random_patch_prob = mask * (random_patch_prob == True)
-            random_patches = torch.randint(0,
-                                           input.shape[1],
-                                           (input.shape[0], input.shape[1]),
-                                           device=input.device)
+            random_patches = mint.randint(0, input.shape[1], (input.shape[0], input.shape[1]))  # 'torch.randint':没有对应的mindspore参数 'device' (position 7);
             randomized_input = masked_input[
-                torch.arange(masked_input.shape[0]).unsqueeze(-1),
+                mint.arange(masked_input.shape[0]).unsqueeze(-1),
                 random_patches]
             masked_input[bool_random_patch_prob] = randomized_input[
                 bool_random_patch_prob]
@@ -159,7 +163,7 @@         # add cls token to input sequence
         b, n, _ = masked_input.shape
         cls_tokens = repeat(transformer.cls_token, '() n d -> b n d', b=b)
-        masked_input = torch.cat((cls_tokens, masked_input), dim=1)
+        masked_input = mint.cat((cls_tokens, masked_input), dim = 1)
 
         # add positional embeddings to input
         masked_input += transformer.pos_embedding[:, :(n + 1)]
